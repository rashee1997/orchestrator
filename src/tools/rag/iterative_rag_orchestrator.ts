import { MemoryManager } from '../../database/memory_manager.js';
import { GeminiIntegrationService } from '../../database/services/GeminiIntegrationService.js';
import { RetrievedCodeContext } from '../../database/services/CodebaseContextRetrieverService.js';
import { ContextRetrievalOptions } from '../../database/services/CodebaseContextRetrieverService.js';
import {
    RAG_ANALYSIS_PROMPT,
    RAG_ANALYSIS_SYSTEM_INSTRUCTION,
    RAG_ANSWER_PROMPT,
    RAG_VERIFICATION_PROMPT
} from '../../database/services/gemini-integration-modules/GeminiPromptTemplates.js';
import { RagAnalysisResponse } from './rag_response_parser.js';
import { RagResponseParser } from './rag_response_parser.js';
import { DiverseQueryRewriterService } from './diverse_query_rewriter_service.js';
import { callTavilyApi, WebSearchResult } from '../../integrations/tavily.js';
import {
    formatRetrievedContextForPrompt as formatContextForGemini
} from '../../database/services/gemini-integration-modules/GeminiContextFormatter.js';
import { GeminiApiNotInitializedError } from '../../database/services/gemini-integration-modules/GeminiApiClient.js';
import { McpError, ErrorCode } from '@modelcontextprotocol/sdk/types.js';
import { deduplicateContexts } from '../../utils/context_utils.js';

/**
 * Result returned by the orchestrator after the whole iterative search finishes.
 */
export interface IterativeRagResult {
    /** All unique context items collected across every turn. */
    accumulatedContext: RetrievedCodeContext[];
    /** Web results (if any) that were added to the context. */
    webSearchSources: { title: string; url: string }[];
    /**  Final answer generated by Gemini (if an ANSWER decision was reached). */
    finalAnswer?: string;
    /** Full log of every RAG‑analysis response (useful for debugging). */
    decisionLog: RagAnalysisResponse[];
    /** Metrics that give insight into the search behaviour. */
    searchMetrics: {
        totalIterations: number;
        contextItemsAdded: number;
        webSearchesPerformed: number;
        hallucinationChecksPerformed: number;
        selfCorrectionLoops: number;
        terminationReason: string;
        dmqr: {
            enabled: boolean;
            queryCount?: number;
            generatedQueries?: string[];
            success: boolean;
            contextItemsGenerated: number;
            error?: string;
        };
        /** Timestamped record of each turn – handy for UI visualisation. */
        turnLog: {
            turn: number;
            query: string;
            newContextCount: number;
            decision: string;
            reasoning: string;
            type: 'initial' | 'iterative' | 'self-correction';
        }[];
    };
}


/**
 * Arguments accepted by the orchestrator.
 */
export interface IterativeRagArgs {
    agent_id: string;
    query: string;
    model?: string;
    systemInstruction?: string;

    context_options?: ContextRetrievalOptions;
    focus_area?: string;
    analysis_focus_points?: string[];
    enable_web_search?: boolean;
    max_iterations?: number;
    hallucination_check_threshold?: number;
    tavily_search_depth?: 'basic' | 'advanced';
    tavily_max_results?: number;
    tavily_include_raw_content?: boolean;
    tavily_include_images?: boolean;
    tavily_include_image_descriptions?: boolean;
    tavily_time_period?: string;
    tavily_topic?: string;
    thinkingConfig?: { thinkingBudget?: number; thinkingMode?: 'AUTO' | 'MODE_THINK' };
    enable_dmqr?: boolean;
    dmqr_query_count?: number;
}

/**
 * The orchestrator that drives the multi‑turn, intelligent RAG loop.
 */
export class IterativeRagOrchestrator {
    private memoryManagerInstance: MemoryManager;
    private geminiService: GeminiIntegrationService;
    private diverseQueryRewriterService: DiverseQueryRewriterService;

    constructor(
        memoryManagerInstance: MemoryManager,
        geminiService: GeminiIntegrationService,
        diverseQueryRewriterService: DiverseQueryRewriterService
    ) {
        this.memoryManagerInstance = memoryManagerInstance;
        this.geminiService = geminiService;
        this.diverseQueryRewriterService = diverseQueryRewriterService;
    }

    /**
     * Build the optional "focus" block that is injected into the RAG prompts.
     */
    private _generateFocusString(focusArea?: string, analysisFocusPoints?: string[]): string {
        let focusString = '';
        if (focusArea) {
            if (analysisFocusPoints && analysisFocusPoints.length) {
                focusString =
                    'Focus on the following aspects for your analysis and response:\n' +
                    analysisFocusPoints.map((p, i) => `${i + 1}. **${p}**`).join('\n');
            } else {
                switch (focusArea) {
                    case 'code_review':
                        focusString =
                            'Focus on all aspects including:\n' +
                            '1. **Potential Bugs & Errors**\n' +
                            '2. **Best Practices & Conventions**\n' +
                            '3. **Performance**\n' +
                            '4. **Security Vulnerabilities**\n' +
                            '5. **Readability & Maintainability**';
                        break;
                    case 'code_explanation':
                        focusString = 'Explain the code clearly and concisely.';
                        break;
                    case 'enhancement_suggestions':
                        focusString = 'Suggest improvements and enhancements.';
                        break;
                    case 'bug_fixing':
                        focusString = 'Identify and suggest fixes for bugs.';
                        break;
                    case 'refactoring':
                        focusString = 'Suggest refactoring opportunities.';
                        break;
                    case 'testing':
                        focusString = 'Provide testing strategies and test case generation.';
                        break;
                    case 'documentation':
                        focusString = 'Generate or improve documentation.';
                        break;
                    case 'code_modularization_orchestration':
                        focusString = 'Discuss modularity, architecture, and orchestration patterns.';
                        break;
                    default:
                        focusString = '';
                }
            }
            if (focusString) {
                focusString = `--- Focus Area ---\n${focusString}\n\n`;
            }
        }
        return focusString;
    }

    /**
     * Create an intelligent context flow that prioritizes recent and relevant information.
     * This addresses the "context rot" problem by organizing context logically.
     */
    private _createContextFlow(
        accumulatedContext: RetrievedCodeContext[],
        currentQuery: string,
        recentItemsCount: number
    ): RetrievedCodeContext[] {
        if (accumulatedContext.length === 0) return [];

        // Separate recent context from older context
        const recentContext = accumulatedContext.slice(-recentItemsCount);
        const olderContext = accumulatedContext.slice(0, -recentItemsCount);

        // Sort contexts by relevance and type priority
        const sortByPriority = (contexts: RetrievedCodeContext[]): RetrievedCodeContext[] => {
            const typePriority = {
                'function': 5,
                'method': 4,
                'class': 3,
                'file': 2,
                'documentation': 1
            };

            return contexts.sort((a, b) => {
                // Higher relevance score gets priority
                const aScore = a.relevanceScore || 0;
                const bScore = b.relevanceScore || 0;

                if (Math.abs(bScore - aScore) > 0.1) {
                    return bScore - aScore;
                }

                // Then by type priority
                const aPriority = typePriority[a.type as keyof typeof typePriority] || 0;
                const bPriority = typePriority[b.type as keyof typeof typePriority] || 0;

                return bPriority - aPriority;
            });
        };

        // Process recent context (highest priority)
        const prioritizedRecent = sortByPriority(recentContext);

        // Process older context with lower priority and potential summarization
        let processedOlder = olderContext;
        if (olderContext.length > 10) {
            // Keep only high-relevance older items
            processedOlder = olderContext.filter(ctx => (ctx.relevanceScore || 0) >= 0.8);
            if (processedOlder.length > 5) {
                processedOlder = processedOlder.slice(0, 5); // Limit older context
            }
        }

        // Combine with recent context first, then older context
        const contextFlow = [
            ...prioritizedRecent,
            ...processedOlder
        ];

        // Final deduplication
        const uniqueContexts = Array.from(
            new Map(contextFlow.map(item => [`${item.sourcePath}#${item.entityName}`, item])).values()
        );

        return uniqueContexts;
    }

    private async _selfCorrectQuery(
        originalGoal: string,
        failedQuery: string,
        accumulatedContext: RetrievedCodeContext[],
        model?: string
    ): Promise<string> {
        console.log(`[Self-Correction] Reformulating failed query: "${failedQuery}"`);
        const contextSummary = accumulatedContext
            .slice(-5) // Use most recent context
            .map(c => ` - [${c.type}] ${c.sourcePath} (Entity: ${c.entityName || 'N/A'})`)
            .join('\n');

        const correctionPrompt = `You are a search expert. A previous search query failed to find any new information. Your task is to reformulate the query to better achieve the original goal.
Consider the context found so far and try a different angle. Be more specific, more general, or use different keywords as appropriate.

Original Goal: "${originalGoal}"
Failed Query: "${failedQuery}"
Context Found So Far:
${contextSummary || "No context found yet."}

New, improved search query:`;

        try {
            const result = await this.geminiService.askGemini(correctionPrompt, model || 'gemini-2.5-flash');
            const newQuery = result.content[0].text?.trim();
            if (newQuery && newQuery !== failedQuery) {
                console.log(`[Self-Correction] New query: "${newQuery}"`);
                return newQuery;
            }
        } catch (error) {
            console.error("[Self-Correction] Failed to get corrected query from AI:", error);
        }
        // Fallback if AI fails or returns the same query
        return `${failedQuery} details`;
    }

    async performIterativeSearch(args: IterativeRagArgs): Promise<IterativeRagResult> {
        const {
            agent_id,
            query,
            model,
            max_iterations = 3,
            context_options,
            focus_area,
            analysis_focus_points,
            enable_web_search,
            hallucination_check_threshold = 0.8,
            tavily_search_depth = 'basic',
            tavily_max_results = 5,
            tavily_include_raw_content = false,
            thinkingConfig,
            enable_dmqr,
            dmqr_query_count
        } = args;

        const contextRetriever = this.memoryManagerInstance.getCodebaseContextRetrieverService();

        let accumulatedContext: RetrievedCodeContext[] = [];
        const webSearchSources: { title: string; url: string }[] = [];
        const decisionLog: RagAnalysisResponse[] = [];
        const queryHistory = new Set<string>();

        const searchMetrics = {
            totalIterations: 0,
            contextItemsAdded: 0,
            webSearchesPerformed: 0,
            hallucinationChecksPerformed: 0,
            selfCorrectionLoops: 0,
            terminationReason: "In progress",
            dmqr: {
                enabled: !!enable_dmqr,
                queryCount: dmqr_query_count,
                generatedQueries: [] as string[],
                success: false,
                contextItemsGenerated: 0,
                error: undefined as string | undefined
            },
            turnLog: [] as {
                turn: number;
                query: string;
                newContextCount: number;
                decision: string;
                reasoning: string;
                type: 'initial' | 'iterative' | 'self-correction';
            }[]
        };

        const focusString = this._generateFocusString(focus_area, analysis_focus_points);
        console.log(`[Iterative RAG] Starting search for query: "${query}"`);

        let baseQueries: string[] = [query];
        if (enable_dmqr) {
            console.log('[Iterative RAG] DMQR enabled – generating diverse queries...');
            try {
                const dmqrResult = await this.diverseQueryRewriterService.rewriteAndRetrieve(query, { queryCount: dmqr_query_count });
                baseQueries = dmqrResult.generatedQueries;
                searchMetrics.dmqr.generatedQueries = baseQueries;
                searchMetrics.dmqr.success = true;
                console.log(`[Iterative RAG] DMQR produced ${baseQueries.length} queries.`);
            } catch (e: any) {
                searchMetrics.dmqr.success = false;
                searchMetrics.dmqr.error = e.message ?? 'unknown';
                baseQueries = [query];
            }
        }

        let currentQueries = [...baseQueries];
        let turn = 0;
        let stabilityCounter = 0; // Counts consecutive turns with no new context

        while (turn < max_iterations) {
            turn++;
            searchMetrics.totalIterations = turn;

            const turnQuery = currentQueries.shift();
            if (!turnQuery) {
                searchMetrics.terminationReason = "Exhausted all queries.";
                break;
            }

            if (queryHistory.has(turnQuery)) {
                console.log(`[Iterative RAG] Skipping duplicate query: "${turnQuery}"`);
                continue;
            }
            queryHistory.add(turnQuery);

            const isInitialTurn = baseQueries.includes(turnQuery);
            console.log(`[Iterative RAG] Turn ${turn} – Query: "${turnQuery}" (${isInitialTurn ? 'initial' : 'iterative'})`);

            const contextBefore = accumulatedContext.length;
            const rawContext = await contextRetriever.retrieveContextForPrompt(agent_id, turnQuery, context_options || {});
            accumulatedContext = deduplicateContexts([...accumulatedContext, ...rawContext]);
            const addedNow = accumulatedContext.length - contextBefore;
            searchMetrics.contextItemsAdded += addedNow;

            // Self-correction logic
            if (addedNow === 0 && !isInitialTurn) {
                stabilityCounter++;
                if (stabilityCounter >= 2) {
                    searchMetrics.terminationReason = "Context stable, no new information found.";
                    console.log(`[Iterative RAG] Context has been stable for ${stabilityCounter} turns. Terminating search.`);
                    break;
                }

                searchMetrics.selfCorrectionLoops++;
                const correctedQuery = await this._selfCorrectQuery(query, turnQuery, accumulatedContext, model);
                // Add corrected query to the front of the queue
                if (correctedQuery) currentQueries.unshift(correctedQuery);

                searchMetrics.turnLog.push({ turn, query: turnQuery, newContextCount: 0, decision: "SELF_CORRECT", reasoning: "No new context found, reformulating query.", type: 'self-correction' });
                continue; // Skip analysis for this turn and proceed with corrected query
            } else {
                stabilityCounter = 0; // Reset stability counter if we find new context
            }

            // Create context flow: recent/relevant first, then summarized older context
            const contextFlow = this._createContextFlow(accumulatedContext, turnQuery, addedNow);
            const formattedContext = formatContextForGemini(contextFlow)[0].text || '';
            const analysisPrompt = RAG_ANALYSIS_PROMPT
                .replace('{originalQuery}', query)
                .replace('{currentTurn}', String(turn))
                .replace('{maxIterations}', String(max_iterations))
                .replace('{accumulatedContext}', formattedContext)
                .replace('{focusString}', focusString);

            let analysisResult;
            try {
                analysisResult = await this.geminiService.askGemini(analysisPrompt, model, RAG_ANALYSIS_SYSTEM_INSTRUCTION, thinkingConfig);
            } catch (e: any) {
                searchMetrics.terminationReason = `Gemini analysis error: ${e.message}`;
                break;
            }

            const parsed = RagResponseParser.parseAnalysisResponse(analysisResult.content[0].text ?? '');
            if (!parsed) {
                searchMetrics.terminationReason = 'Parsing failure';
                break;
            }
            decisionLog.push(parsed);
            searchMetrics.turnLog.push({ turn, query: turnQuery, newContextCount: addedNow, decision: parsed.decision, reasoning: parsed.reasoning, type: isInitialTurn ? 'initial' : 'iterative' });

            if (parsed.decision === 'ANSWER') {
                searchMetrics.terminationReason = "ANSWER decision reached.";
                console.log('[Iterative RAG] Decision: ANSWER – generating final answer.');
                const answerPrompt = RAG_ANSWER_PROMPT
                    .replace('{originalQuery}', query)
                    .replace('{contextString}', formattedContext)
                    .replace('{focusString}', focusString);
                const answerResult = await this.geminiService.askGemini(answerPrompt, model, 'You are a helpful AI assistant providing accurate answers based on the given context.');
                return { accumulatedContext, webSearchSources, finalAnswer: answerResult.content[0].text ?? '', decisionLog, searchMetrics };
            } else if (parsed.decision === 'SEARCH_AGAIN' && parsed.nextCodebaseQuery) {
                currentQueries.push(parsed.nextCodebaseQuery);
            } else if (parsed.decision === 'SEARCH_WEB' && enable_web_search && parsed.nextWebQuery) {
                searchMetrics.webSearchesPerformed++;
                try {
                    const webResults = await callTavilyApi(parsed.nextWebQuery, { search_depth: tavily_search_depth, max_results: tavily_max_results, include_raw_content: tavily_include_raw_content });
                    webResults.forEach((r: WebSearchResult) => {
                        webSearchSources.push({ title: r.title, url: r.url });
                        accumulatedContext.push({ type: 'documentation', sourcePath: r.url, entityName: r.title, content: r.content, relevanceScore: 0.95 });
                    });
                } catch (e: any) {
                    console.error('[Iterative RAG] Web search failed:', e);
                }
            }
        }

        if (searchMetrics.terminationReason === "In progress") {
            searchMetrics.terminationReason = "Max iterations reached.";
        }

        console.log('[Iterative RAG] Max iterations reached or terminated early. Generating final answer from accumulated context.');
        // Use the same context flow logic for final answer generation
        const finalContextFlow = this._createContextFlow(accumulatedContext, query, 0);
        const fallbackContext = formatContextForGemini(finalContextFlow)[0].text || '';
        const fallbackPrompt = RAG_ANSWER_PROMPT
            .replace('{originalQuery}', query)
            .replace('{contextString}', fallbackContext)
            .replace('{focusString}', focusString);
        const fallbackResult = await this.geminiService.askGemini(fallbackPrompt, model, 'You are a helpful AI assistant providing accurate answers based on the given context.');

        return { accumulatedContext, webSearchSources, finalAnswer: fallbackResult.content[0].text ?? 'Unable to formulate an answer.', decisionLog, searchMetrics };
    }
}
