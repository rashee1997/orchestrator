import { MemoryManager } from '../../database/memory_manager.js';
import { GeminiIntegrationService } from '../../database/services/GeminiIntegrationService.js';
import { RetrievedCodeContext } from '../../database/services/CodebaseContextRetrieverService.js';
import { ContextRetrievalOptions } from '../../database/services/CodebaseContextRetrieverService.js';
import {
    RAG_ANALYSIS_PROMPT,
    RAG_ANALYSIS_SYSTEM_INSTRUCTION,
    RAG_ANSWER_PROMPT,
    RAG_VERIFICATION_PROMPT,
    RAG_SELF_CORRECTION_PROMPT
} from '../../database/services/gemini-integration-modules/GeminiPromptTemplates.js';
import {
    AGENTIC_RAG_PLANNING_PROMPT,
    RAG_REFLECTION_PROMPT,
    CORRECTIVE_RAG_PROMPT,
    HYBRID_RAG_COORDINATION_PROMPT,
    LONG_RAG_CHUNKING_PROMPT,
    CITATION_ATTRIBUTION_PROMPT
} from './enhanced_rag_prompts.js';
import { RagAnalysisResponse } from './rag_response_parser.js';
import { RagResponseParser } from './rag_response_parser.js';
import { DiverseQueryRewriterService } from './diverse_query_rewriter_service.js';
import { callTavilyApi, WebSearchResult } from '../../integrations/tavily.js';
import {
    formatRetrievedContextForPrompt as formatContextForGemini
} from '../../database/services/gemini-integration-modules/GeminiContextFormatter.js';
import { GeminiApiNotInitializedError } from '../../database/services/gemini-integration-modules/GeminiApiClient.js';
import { McpError, ErrorCode } from '@modelcontextprotocol/sdk/types.js';
import { deduplicateContexts } from '../../utils/context_utils.js';
import { getCurrentModel } from '../../database/services/gemini-integration-modules/GeminiConfig.js';
import { globalPerformanceTracker } from '../../utils/performance_tracker.js';
import { KnowledgeGraphManager } from '../../database/managers/KnowledgeGraphManager.js';

export interface Citation {
    id: string;
    source: string;
    sourceType: 'code' | 'documentation' | 'web' | 'knowledge_graph';
    title: string;
    url?: string;
    filePath?: string;
    lineNumbers?: [number, number];
    confidence: number;
    relevanceScore: number;
    extractedText: string;
    context?: string;
}

export interface ReflectionResult {
    hasHallucinations: boolean;
    missingInfo: string[];
    qualityScore: number;
    suggestions: string[];
    corrections: string[];
    confidence: number;
}

export interface AgenticRagPlan {
    strategy: 'vector_search' | 'graph_traversal' | 'hybrid_search' | 'web_augmented' | 'corrective_search';
    steps: Array<{
        action: string;
        target: string;
        priority: number;
        reasoning: string;
    }>;
    expectedOutcome: string;
    fallbackStrategy?: string;
}

/**
 * Result returned by the orchestrator after the whole iterative search finishes.
 */
export interface IterativeRagResult {
    /** All unique context items collected across every turn. */
    accumulatedContext: RetrievedCodeContext[];
    /** Web results (if any) that were added to the context. */
    webSearchSources: { title: string; url: string }[];
    /**  Final answer generated by Gemini (if an ANSWER decision was reached). */
    finalAnswer?: string;
    /** Full log of every RAG‑analysis response (useful for debugging). */
    decisionLog: RagAnalysisResponse[];
    /** Source citations with detailed attribution */
    citations: Citation[];
    /** Reflection analysis results for quality control */
    reflectionResults: ReflectionResult[];
    /** Agentic planning results */
    agenticPlan?: AgenticRagPlan;
    /** Metrics that give insight into the search behaviour. */
    searchMetrics: {
        totalIterations: number;
        contextItemsAdded: number;
        webSearchesPerformed: number;
        hallucinationChecksPerformed: number;
        selfCorrectionLoops: number;
        terminationReason: string;
        graphTraversals: number;
        hybridSearches: number;
        citationAccuracy: number;
    citationCoverage: number;
    totalCitationsGenerated: number;
    totalCitationsUsed: number;
        dmqr: {
            enabled: boolean;
            queryCount?: number;
            generatedQueries?: string[];
            success: boolean;
            contextItemsGenerated: number;
            error?: string;
        };
        /** Timestamped record of each turn – handy for UI visualisation. */
        turnLog: Array<{
            turn: number;
            query: string;
            strategy: string;
            newContextCount: number;
            decision: string;
            reasoning: string;
            type: 'initial' | 'iterative' | 'self-correction' | 'agentic-plan' | 'reflection';
            quality: number;
            citations: number;
        }>;
    };
}


/**
 * Arguments accepted by the orchestrator.
 */
export interface IterativeRagArgs {
    agent_id: string;
    query: string;
    model?: string;
    systemInstruction?: string;

    context_options?: ContextRetrievalOptions;
    focus_area?: string;
    analysis_focus_points?: string[];
    enable_web_search?: boolean;
    google_search?: boolean;
    continue_session?: boolean;
    max_iterations?: number;
    hallucination_check_threshold?: number;
    tavily_search_depth?: 'basic' | 'advanced';
    tavily_max_results?: number;
    tavily_include_raw_content?: boolean;
    tavily_include_images?: boolean;
    tavily_include_image_descriptions?: boolean;
    tavily_time_period?: string;
    tavily_topic?: string;
    thinkingConfig?: { thinkingBudget?: number; thinkingMode?: 'AUTO' | 'MODE_THINK' };
    enable_dmqr?: boolean;
    dmqr_query_count?: number;
    enable_agentic_planning?: boolean;
    enable_reflection?: boolean;
    enable_hybrid_search?: boolean;
    enable_long_rag?: boolean;
    enable_corrective_rag?: boolean;
    citation_accuracy_threshold?: number;
    long_rag_chunk_size?: number;
    reflection_frequency?: number;
}

/**
 * The orchestrator that drives the multi‑turn, intelligent RAG loop.
 */
export class IterativeRagOrchestrator {
    private memoryManagerInstance: MemoryManager;
    private geminiService: GeminiIntegrationService;
    private diverseQueryRewriterService: DiverseQueryRewriterService;
    private knowledgeGraphManager?: KnowledgeGraphManager;

    // Performance optimization: Session-level context cache
    private sessionContextCache: Map<string, {
        context: RetrievedCodeContext[];
        timestamp: number;
        query: string;
        options: ContextRetrievalOptions;
    }>;
    private readonly CACHE_TTL = 10 * 60 * 1000; // 10 minutes for session cache
    private readonly MAX_SESSION_CACHE_SIZE = 50;
    private citationIdCounter = 0;
    
    // Enhanced search cache for hybrid results
    private hybridSearchCache: Map<string, {
        results: RetrievedCodeContext[];
        timestamp: number;
        searchStrategy: string;
    }>;
    private readonly HYBRID_CACHE_TTL = 15 * 60 * 1000; // 15 minutes

    constructor(
        memoryManagerInstance: MemoryManager,
        geminiService: GeminiIntegrationService,
        diverseQueryRewriterService: DiverseQueryRewriterService,
        knowledgeGraphManager?: KnowledgeGraphManager
    ) {
        this.memoryManagerInstance = memoryManagerInstance;
        this.geminiService = geminiService;
        this.diverseQueryRewriterService = diverseQueryRewriterService;
        this.knowledgeGraphManager = knowledgeGraphManager;
        this.sessionContextCache = new Map();
        this.hybridSearchCache = new Map();
    }

    /**
     * Generate cache key for session context cache.
     */
    private _generateSessionCacheKey(query: string, options: ContextRetrievalOptions): string {
        const optionsStr = JSON.stringify({
            topKEmbeddings: options.topKEmbeddings,
            kgQueryDepth: options.kgQueryDepth,
            topKKgResults: options.topKKgResults,
            targetFilePaths: options.targetFilePaths?.sort(),
            embeddingScoreThreshold: options.embeddingScoreThreshold,
            useHybridSearch: options.useHybridSearch,
            enableReranking: options.enableReranking
        });
        return `${query}:${optionsStr}`;
    }

    /**
     * Check if cached context is still valid.
     */
    private _isSessionCacheValid(timestamp: number): boolean {
        return (Date.now() - timestamp) < this.CACHE_TTL;
    }

    private _generateCitation(
        context: RetrievedCodeContext,
        extractedText: string,
        confidence: number = 0.8
    ): Citation {
        return {
            id: `cite_${++this.citationIdCounter}`,
            source: context.sourcePath,
            sourceType: context.type as Citation['sourceType'],
            title: context.entityName || context.sourcePath,
            filePath: context.sourcePath,
            lineNumbers: context.metadata?.startLine && context.metadata?.endLine ? [context.metadata.startLine, context.metadata.endLine] : undefined,
            confidence,
            relevanceScore: context.relevanceScore || 0.7,
            extractedText: extractedText.substring(0, 200),
            context: context.content.substring(0, 500)
        };
    }

    private async _performAgenticPlanning(
        originalQuery: string,
        currentQuery: string,
        currentContext: RetrievedCodeContext[],
        iteration: number,
        model?: string
    ): Promise<AgenticRagPlan> {
        const contextSummary = currentContext.slice(-3).map(c => 
            `- ${c.type}: ${c.entityName || 'Unknown'} (${c.sourcePath})`
        ).join('\n');
        
        const previousStrategy = iteration > 1 ? 'vector_search' : 'initial';
        const contextQuality = currentContext.length > 0 ? 0.7 : 0.3;
        const informationGaps = currentContext.length < 3 ? ['implementation details', 'usage examples'] : ['edge cases'];
        
        const planningPrompt = AGENTIC_RAG_PLANNING_PROMPT
            .replace('{originalQuery}', originalQuery)
            .replace('{currentQuery}', currentQuery)
            .replace('{currentIteration}', iteration.toString())
            .replace('{previousStrategy}', previousStrategy)
            .replace('{contextQuality}', contextQuality.toString())
            .replace('{informationGaps}', informationGaps.join(', '))
            .replace('{contextSummary}', contextSummary);

        const result = await this.geminiService.askGemini(planningPrompt, model || getCurrentModel());
        try {
            const parsed = JSON.parse(result.content[0].text?.trim() || '{}');
            return {
                strategy: parsed.recommended_strategy?.primary_modality || 'vector_search',
                steps: parsed.execution_plan?.immediate_actions?.map((action: string, idx: number) => ({
                    action,
                    target: currentQuery,
                    priority: idx + 1,
                    reasoning: `Step ${idx + 1} of agentic plan`
                })) || [{ action: 'search', target: currentQuery, priority: 1, reasoning: 'default action' }],
                expectedOutcome: parsed.execution_plan?.query_formulation || 'relevant context',
                fallbackStrategy: parsed.contingency_planning?.fallback_strategy || 'hybrid_search'
            };
        } catch (error) {
            console.warn('[Agentic Planning] Failed to parse response, using fallback:', error);
            return {
                strategy: 'vector_search',
                steps: [{ action: 'search', target: currentQuery, priority: 3, reasoning: 'fallback plan' }],
                expectedOutcome: 'relevant context',
                fallbackStrategy: 'hybrid_search'
            };
        }
    }

    private async _performReflection(
        originalQuery: string,
        context: RetrievedCodeContext[],
        currentAnswer: string,
        model?: string
    ): Promise<ReflectionResult> {
        const sourceContext = context.map(c => 
            `Source: ${c.sourcePath} | Entity: ${c.entityName || 'Unknown'} | Type: ${c.type}`
        ).join('\n');
        const searchStrategy = 'hybrid_search'; // This would come from the current strategy
        const iterationCount = 1; // This would be passed in
        
        const reflectionPrompt = RAG_REFLECTION_PROMPT
            .replace('{originalQuery}', originalQuery)
            .replace('{generatedResponse}', currentAnswer)
            .replace('{sourceContext}', sourceContext)
            .replace('{searchStrategy}', searchStrategy)
            .replace('{iterationCount}', iterationCount.toString());

        const result = await this.geminiService.askGemini(reflectionPrompt, model || getCurrentModel());
        try {
            const parsed = JSON.parse(result.content[0].text?.trim() || '{}');
            return {
                hasHallucinations: parsed.hallucination_analysis?.detected_hallucinations?.length > 0 || false,
                missingInfo: parsed.completeness_analysis?.missing_aspects || [],
                qualityScore: parsed.overall_assessment?.quality_score || 0.5,
                suggestions: parsed.improvement_recommendations?.enhancement_suggestions || [],
                corrections: parsed.improvement_recommendations?.immediate_fixes || [],
                confidence: parsed.overall_assessment?.overall_confidence || 0.5
            };
        } catch (error) {
            console.warn('[Reflection] Failed to parse response, using fallback:', error);
            return {
                hasHallucinations: false,
                missingInfo: [],
                qualityScore: 0.5,
                suggestions: [],
                corrections: [],
                confidence: 0.5
            };
        }
    }

    private async _performHybridSearch(
        agentId: string,
        query: string,
        options: ContextRetrievalOptions,
        plan?: AgenticRagPlan
    ): Promise<RetrievedCodeContext[]> {
        const results: RetrievedCodeContext[] = [];
        const hybridOptions = { ...options, useHybridSearch: true };

        // Enhanced Hybrid Search with Task Types
        console.log(`[Enhanced Hybrid Search] Starting hybrid search with Gemini task types for query: "${query}"`);

        // 1. Vector Search with RETRIEVAL_QUERY task type
        const vectorSearchPromise = this._retrieveContextWithCache(agentId, [query], {
            ...hybridOptions,
            taskType: 'RETRIEVAL_QUERY'
        });

        // 2. Keyword-based Search with CODE_RETRIEVAL_QUERY task type
        const keywordSearchPromise = this._performEnhancedKeywordSearch(agentId, query, {
            ...hybridOptions,
            taskType: 'CODE_RETRIEVAL_QUERY'
        });

        // 3. Knowledge Graph Search (if available)
        const kgSearchPromise = this.knowledgeGraphManager && plan?.strategy === 'hybrid_search'
            ? this._performKnowledgeGraphSearch(agentId, query, hybridOptions)
            : Promise.resolve([]);

        // Execute searches in parallel with Gemini batch processing
        try {
            const [vectorResults, keywordResults, kgResults] = await Promise.allSettled([
                vectorSearchPromise,
                keywordSearchPromise, 
                kgSearchPromise
            ]);

            // Process vector results
            if (vectorResults.status === 'fulfilled') {
                results.push(...vectorResults.value);
                console.log(`[Hybrid Search] Vector search yielded ${vectorResults.value.length} results`);
            } else {
                console.warn('[Hybrid Search] Vector search failed:', vectorResults.reason);
            }

            // Process keyword results
            if (keywordResults.status === 'fulfilled') {
                results.push(...keywordResults.value);
                console.log(`[Hybrid Search] Keyword search yielded ${keywordResults.value.length} results`);
            } else {
                console.warn('[Hybrid Search] Keyword search failed:', keywordResults.reason);
            }

            // Process KG results
            if (kgResults.status === 'fulfilled') {
                results.push(...kgResults.value);
                console.log(`[Hybrid Search] KG search yielded ${kgResults.value.length} results`);
            } else if (kgResults.status === 'rejected') {
                console.warn('[Hybrid Search] KG search failed:', kgResults.reason);
            }

            // Apply hybrid ranking using Reciprocal Rank Fusion
            const rankedResults = this._applyHybridRanking([
                vectorResults.status === 'fulfilled' ? vectorResults.value : [],
                keywordResults.status === 'fulfilled' ? keywordResults.value : [],
                kgResults.status === 'fulfilled' ? kgResults.value : []
            ]);

            console.log(`[Enhanced Hybrid Search] Combined and ranked ${rankedResults.length} results`);
            return deduplicateContexts(rankedResults);

        } catch (error) {
            console.error('[Hybrid Search] Error during parallel search execution:', error);
            // Fallback to sequential execution
            return await this._fallbackSequentialSearch(agentId, query, hybridOptions, plan);
        }
    }

    private async _performCorrectiveSearch(
        agentId: string,
        originalQuery: string,
        previousContext: RetrievedCodeContext[],
        reflectionResult: ReflectionResult,
        options: ContextRetrievalOptions,
        model?: string
    ): Promise<RetrievedCodeContext[]> {
        if (!reflectionResult.hasHallucinations && reflectionResult.missingInfo.length === 0) {
            return [];
        }

        const currentContext = previousContext.slice(-3).map(c => 
            `${c.sourcePath}: ${c.entityName || 'Unknown'}`
        ).join(', ');
        
        const correctionPrompt = CORRECTIVE_RAG_PROMPT
            .replace('{currentQuery}', originalQuery)
            .replace('{reflectionResults}', JSON.stringify(reflectionResult))
            .replace('{currentContext}', currentContext)
            .replace('{hasHallucinations}', reflectionResult.hasHallucinations.toString())
            .replace('{missingInfo}', reflectionResult.missingInfo.join(', '))
            .replace('{qualityScore}', reflectionResult.qualityScore.toString());
        
        try {
            const result = await this.geminiService.askGemini(correctionPrompt, model || getCurrentModel());
            const parsed = JSON.parse(result.content[0].text?.trim() || '{}');
            const correctedQueries = parsed.correctedQueries || [
                `${originalQuery} focusing on: ${reflectionResult.corrections.join(', ')} ${reflectionResult.missingInfo.join(', ')}`.trim()
            ];
            
            return await this._retrieveContextWithCache(agentId, correctedQueries, options);
        } catch (error) {
            console.warn('[Corrective Search] Failed to use enhanced prompt, using fallback:', error);
            const fallbackQuery = `${originalQuery} focusing on: ${reflectionResult.corrections.join(', ')} ${reflectionResult.missingInfo.join(', ')}`.trim();
            return await this._retrieveContextWithCache(agentId, [fallbackQuery], options);
        }
    }

        private async _performEnhancedKeywordSearch(
        agentId: string,
        query: string,
        options: ContextRetrievalOptions
    ): Promise<RetrievedCodeContext[]> {
        try {
            console.log(`[Enhanced Keyword Search] Performing keyword-based search for: "${query}"`);
            
            // Extract keywords using Gemini with CODE_RETRIEVAL_QUERY task type
            const keywordExtractionPrompt = `Extract the most important technical keywords, function names, class names, and file patterns from this query for code search. Focus on identifiers that would appear in code.

Query: "${query}"

Return a JSON object with "keywords" array containing the extracted terms.
Example: {"keywords": ["getUserData", "UserService", "authentication", "api"]}`;

            const keywordResult = await this.geminiService.askGemini(
                keywordExtractionPrompt,
                getCurrentModel(),
                'You are a code search expert. Extract precise technical keywords for effective code retrieval.'
            );

            let keywords: string[] = [];
            try {
                const parsed = JSON.parse(keywordResult.content[0].text || '{}');
                keywords = parsed.keywords || [];
            } catch {
                // Fallback keyword extraction
                keywords = query.split(/\s+/)
                    .filter(word => word.length > 2)
                    .filter(word => /[a-zA-Z_$][\w$]*/.test(word)); // Identifier-like words
            }

            if (keywords.length === 0) {
                console.log('[Enhanced Keyword Search] No keywords extracted, falling back to vector search');
                return [];
            }

            console.log(`[Enhanced Keyword Search] Using keywords: ${keywords.join(', ')}`);

            // Perform parallel keyword searches
            const keywordPromises = keywords.slice(0, 10).map(async (keyword) => {
                try {
                    // Search in multiple sources
                    const [embeddingResults, kgResults] = await Promise.allSettled([
                        // Vector search
                        this._retrieveContextWithCache(agentId, [`"${keyword}"`], options),
                        // Knowledge graph search if available
                        this.knowledgeGraphManager ? 
                            this.knowledgeGraphManager.searchNodes(agentId, keyword).catch(() => []) :
                            Promise.resolve([])
                    ]);

                    const results: RetrievedCodeContext[] = [];

                    // Process embedding results
                    if (embeddingResults.status === 'fulfilled') {
                        results.push(...embeddingResults.value);
                    }

                    // Process KG results
                    if (kgResults.status === 'fulfilled' && this.knowledgeGraphManager) {
                        const kgNodes = kgResults.value;
                        if (Array.isArray(kgNodes) && kgNodes.length > 0) {
                            const kgContexts = kgNodes.map(node => ({
                                type: 'kg_node_info' as const,
                                sourcePath: `kg://${node.name}`,
                                entityName: node.name,
                                content: JSON.stringify(node.observations || []),
                                relevanceScore: 0.7, // Default relevance for KG results
                                metadata: { nodeType: node.entityType }
                            }));
                            results.push(...kgContexts);
                        }
                    }

                    return results;
                } catch (error) {
                    console.warn(`[Enhanced Keyword Search] Failed to search for keyword "${keyword}":`, error);
                    return [];
                }
            });

            const allResults = await Promise.all(keywordPromises);
            const flattenedResults = allResults.flat();

            // Deduplicate and rank results
            const uniqueResults = deduplicateContexts(flattenedResults);
            uniqueResults.sort((a, b) => (b.relevanceScore || 0) - (a.relevanceScore || 0));

            console.log(`[Enhanced Keyword Search] Found ${uniqueResults.length} results for ${keywords.length} keywords`);
            return uniqueResults.slice(0, options.topKEmbeddings || 20);

        } catch (error) {
            console.error('[Enhanced Keyword Search] Error during keyword search:', error);
            return [];
        }
    }

    private async _performKnowledgeGraphSearch(
        agentId: string,
        query: string,
        options: ContextRetrievalOptions
    ): Promise<RetrievedCodeContext[]> {
        if (!this.knowledgeGraphManager) {
            return [];
        }

        try {
            console.log(`[KG Search] Performing knowledge graph search for: "${query}"`);
            const graphQuery = await this.knowledgeGraphManager.queryNaturalLanguage(agentId, query);
            const graphData = JSON.parse(graphQuery);
            
            if (graphData.results && Array.isArray(graphData.results.nodes)) {
                const kgResults = graphData.results.nodes.map((node: any) => ({
                    type: 'kg_node_info' as const,
                    sourcePath: `kg://${node.name}`,
                    entityName: node.name,
                    content: JSON.stringify(node.observations),
                    relevanceScore: 0.85,
                    metadata: { 
                        nodeType: node.entityType,
                        searchType: 'knowledge_graph'
                    }
                }));
                
                console.log(`[KG Search] Found ${kgResults.length} knowledge graph results`);
                return kgResults;
            }
        } catch (error) {
            console.warn('[KG Search] Knowledge graph query failed:', error);
        }

        return [];
    }

    private _applyHybridRanking(searchResults: RetrievedCodeContext[][]): RetrievedCodeContext[] {
        // Use Reciprocal Rank Fusion with different weights for different search types
        const weights = {
            vector: 1.0,
            keyword: 0.8,
            knowledge_graph: 0.9
        };

        const scores: Map<string, { score: number; context: RetrievedCodeContext }> = new Map();
        const k = 60; // RRF constant

        searchResults.forEach((results, searchTypeIndex) => {
            const searchTypes = ['vector', 'keyword', 'kg_node_info'];
            const currentWeight = weights[searchTypes[searchTypeIndex] as keyof typeof weights] || 1.0;

            results.forEach((context, rank) => {
                const key = `${context.sourcePath}:${context.entityName || 'default'}:${context.content.substring(0, 100)}`;
                const rrfScore = currentWeight * (1 / (k + rank + 1));
                
                if (scores.has(key)) {
                    const existing = scores.get(key)!;
                    existing.score += rrfScore;
                } else {
                    scores.set(key, {
                        score: rrfScore,
                        context: {
                            ...context,
                            relevanceScore: rrfScore
                        }
                    });
                }
            });
        });

        // Sort by combined score
        return Array.from(scores.values())
            .sort((a, b) => b.score - a.score)
            .map(item => item.context);
    }

    private async _fallbackSequentialSearch(
        agentId: string,
        query: string,
        options: ContextRetrievalOptions,
        plan?: AgenticRagPlan
    ): Promise<RetrievedCodeContext[]> {
        console.log('[Hybrid Search] Executing fallback sequential search');
        const results: RetrievedCodeContext[] = [];

        try {
            // Sequential vector search
            const vectorResults = await this._retrieveContextWithCache(agentId, [query], options);
            results.push(...vectorResults);

            // Sequential keyword search
            const keywordResults = await this._performEnhancedKeywordSearch(agentId, query, options);
            results.push(...keywordResults);

            return deduplicateContexts(results);
        } catch (error) {
            console.error('[Hybrid Search] Fallback search also failed:', error);
            return [];
        }
    }

    private _processLongContexts(contexts: RetrievedCodeContext[], maxChunkSize: number = 2000): RetrievedCodeContext[] {
        return contexts.flatMap(context => {
            if (context.content.length <= maxChunkSize) {
                return [context];
            }

            const chunks: RetrievedCodeContext[] = [];
            const content = context.content;
            let startIndex = 0;

            while (startIndex < content.length) {
                let endIndex = startIndex + maxChunkSize;
                
                // Try to break at natural boundaries (sentences, paragraphs)
                if (endIndex < content.length) {
                    const lastPeriod = content.lastIndexOf('.', endIndex);
                    const lastNewline = content.lastIndexOf('\n', endIndex);
                    const breakPoint = Math.max(lastPeriod, lastNewline);
                    
                    if (breakPoint > startIndex + maxChunkSize * 0.5) {
                        endIndex = breakPoint + 1;
                    }
                }

                const chunkContent = content.slice(startIndex, endIndex);
                chunks.push({
                    ...context,
                    content: chunkContent,
                    entityName: `${context.entityName || 'chunk'}_${chunks.length + 1}`,
                    metadata: {
                        ...context.metadata,
                        isChunk: true,
                        chunkIndex: chunks.length,
                        originalLength: content.length
                    }
                });

                startIndex = endIndex;
            }

            return chunks;
        });
    }

    /**
     * Clean up expired session cache entries.
     */
    private _cleanupSessionCache(): void {
        if (this.sessionContextCache.size > this.MAX_SESSION_CACHE_SIZE) {
            const entries = Array.from(this.sessionContextCache.entries());
            entries.sort((a, b) => a[1].timestamp - b[1].timestamp);
            const toRemove = entries.slice(0, Math.floor(this.MAX_SESSION_CACHE_SIZE * 0.3));
            toRemove.forEach(([key]) => this.sessionContextCache.delete(key));
            console.log(`[IterativeRagOrchestrator] Cleaned up ${toRemove.length} expired session cache entries`);
        }
    }

    /**
     * Retrieve context with session-level caching and parallel processing.
     */
    private async _retrieveContextWithCache(
        agentId: string,
        queries: string[],
        options: ContextRetrievalOptions
    ): Promise<RetrievedCodeContext[]> {
        const operationId = globalPerformanceTracker.startOperation('retrieveContextWithCache', {
            queryCount: queries.length,
            agentId
        });

        try {
            const contextRetriever = this.memoryManagerInstance.getCodebaseContextRetrieverService();
            const allContexts: RetrievedCodeContext[] = [];
            const uncachedQueries: string[] = [];
            const cachedContexts: RetrievedCodeContext[] = [];

        // Check cache for each query
        for (const query of queries) {
            const cacheKey = this._generateSessionCacheKey(query, options);
            const cached = this.sessionContextCache.get(cacheKey);

            if (cached && this._isSessionCacheValid(cached.timestamp)) {
                console.log(`[Session Cache HIT] Using cached context for query: "${query.substring(0, 50)}..."`);
                cachedContexts.push(...cached.context);
            } else {
                uncachedQueries.push(query);
            }
        }

        // Parallel retrieval for uncached queries
        if (uncachedQueries.length > 0) {
            console.log(`[Parallel Retrieval] Processing ${uncachedQueries.length} uncached queries`);

            const retrievalPromises = uncachedQueries.map(async (query) => {
                try {
                    const context = await contextRetriever.retrieveContextForPrompt(agentId, query, options);
                    // Cache the result
                    const cacheKey = this._generateSessionCacheKey(query, options);
                    this.sessionContextCache.set(cacheKey, {
                        context,
                        timestamp: Date.now(),
                        query,
                        options
                    });
                    return context;
                } catch (error) {
                    console.error(`[Parallel Retrieval] Failed to retrieve context for query "${query}":`, error);
                    return [];
                }
            });

            try {
                const retrievedContexts = await Promise.allSettled(retrievalPromises);
                retrievedContexts.forEach((result) => {
                    if (result.status === 'fulfilled') {
                        allContexts.push(...result.value);
                    }
                });
            } catch (error) {
                console.error('[Parallel Retrieval] Error in parallel context retrieval:', error);
            }

            this._cleanupSessionCache();
        }

        // Combine cached and newly retrieved contexts
        allContexts.push(...cachedContexts);

        globalPerformanceTracker.endOperation(operationId, true);
        return allContexts;
        } catch (error: any) {
            globalPerformanceTracker.endOperation(operationId, false, error.message);
            throw error;
        }
    }

    /**
     * Build the optional "focus" block that is injected into the RAG prompts.
     */
    private _generateFocusString(focusArea?: string, analysisFocusPoints?: string[]): string {
        let focusString = '';
        if (focusArea) {
            if (analysisFocusPoints && analysisFocusPoints.length) {
                focusString =
                    'Focus on the following aspects for your analysis and response:\n' +
                    analysisFocusPoints.map((p, i) => `${i + 1}. **${p}**`).join('\n');
            } else {
                switch (focusArea) {
                    case 'code_review':
                        focusString =
                            'Focus on all aspects including:\n' +
                            '1. **Potential Bugs & Errors**\n' +
                            '2. **Best Practices & Conventions**\n' +
                            '3. **Performance**\n' +
                            '4. **Security Vulnerabilities**\n' +
                            '5. **Readability & Maintainability**';
                        break;
                    case 'code_explanation':
                        focusString = 'Explain the code clearly and concisely.';
                        break;
                    case 'enhancement_suggestions':
                        focusString = 'Suggest improvements and enhancements.';
                        break;
                    case 'bug_fixing':
                        focusString = 'Identify and suggest fixes for bugs.';
                        break;
                    case 'refactoring':
                        focusString = 'Suggest refactoring opportunities.';
                        break;
                    case 'testing':
                        focusString = 'Provide testing strategies and test case generation.';
                        break;
                    case 'documentation':
                        focusString = 'Generate or improve documentation.';
                        break;
                    case 'code_modularization_orchestration':
                        focusString = 'Discuss modularity, architecture, and orchestration patterns.';
                        break;
                    default:
                        focusString = '';
                }
            }
            if (focusString) {
                focusString = `--- Focus Area ---
${focusString}

`;
            }
        }
        return focusString;
    }

    /**
     * Create an enhanced context flow that prioritizes recent and relevant information with Long RAG support.
     * This addresses the "context rot" problem by organizing context logically.
     */
    private _createContextFlow(
        accumulatedContext: RetrievedCodeContext[],
        currentQuery: string,
        recentItemsCount: number,
        enableLongRag: boolean = false,
        longRagChunkSize: number = 2000
    ): RetrievedCodeContext[] {
        if (accumulatedContext.length === 0) return [];

        let processedContexts = accumulatedContext;

        // Apply Long RAG processing if enabled
        if (enableLongRag) {
            processedContexts = this._processLongContexts(processedContexts, longRagChunkSize);
        }

        // Separate recent context from older context
        const recentContext = processedContexts.slice(-recentItemsCount);
        const olderContext = processedContexts.slice(0, -recentItemsCount);

        // Sort contexts by relevance and type priority
        const sortByPriority = (contexts: RetrievedCodeContext[]): RetrievedCodeContext[] => {
            const typePriority = {
                'function': 5,
                'method': 4,
                'class': 3,
                'file': 2,
                'documentation': 1,
                'kg_node_info': 6
            };

            return contexts.sort((a, b) => {
                // Higher relevance score gets priority
                const aScore = a.relevanceScore || 0;
                const bScore = b.relevanceScore || 0;

                if (Math.abs(bScore - aScore) > 0.1) {
                    return bScore - aScore;
                }

                // Then by type priority
                const aPriority = typePriority[a.type as keyof typeof typePriority] || 0;
                const bPriority = typePriority[b.type as keyof typeof typePriority] || 0;

                return bPriority - aPriority;
            });
        };

        // Process recent context (highest priority)
        const prioritizedRecent = sortByPriority(recentContext);

        // Process older context with lower priority and potential summarization
        let processedOlder = olderContext;
        if (olderContext.length > 10) {
            // Keep only high-relevance older items
            processedOlder = olderContext.filter(ctx => (ctx.relevanceScore || 0) >= 0.8);
            if (processedOlder.length > 5) {
                processedOlder = processedOlder.slice(0, 5); // Limit older context
            }
        }

        // Combine with recent context first, then older context
        const contextFlow = [
            ...prioritizedRecent,
            ...processedOlder
        ];

        // Final deduplication
        const uniqueContexts = Array.from(
            new Map(contextFlow.map(item => [`${item.sourcePath}#${item.entityName}`, item])).values()
        );

        return uniqueContexts;
    }


    /**
     * Process contexts in batches of three using Gemini task types
     */
    private async _processBatchContextAnalysis(
        contexts: RetrievedCodeContext[],
        originalQuery: string,
        model?: string
    ): Promise<{ analyzedContexts: RetrievedCodeContext[]; batchAnalysis: string[] }> {
        const batchSize = 3;
        const batches: RetrievedCodeContext[][] = [];
        const batchAnalysis: string[] = [];

        // Split contexts into batches of 3
        for (let i = 0; i < contexts.length; i += batchSize) {
            batches.push(contexts.slice(i, i + batchSize));
        }

        console.log(`[Batch Processing] Processing ${contexts.length} contexts in ${batches.length} batches of ${batchSize}`);

        const processedBatches = await Promise.allSettled(
            batches.map(async (batch, batchIndex) => {
                const batchAnalysisPrompt = `Analyze the following ${batch.length} code contexts for relevance to the query "${originalQuery}". \nFor each context, provide:\n1. Relevance score (0.0-1.0)\n2. Key insights\n3. How it relates to the query\n\nContexts:\n${batch.map((ctx, idx) => `Context ${idx + 1}:\nFile: ${ctx.sourcePath}\nEntity: ${ctx.entityName || 'N/A'}\nContent: ${ctx.content.substring(0, 300)}...\n`).join('\n')}\n\nReturn JSON: {"analyses": [{"contextIndex": 0, "relevanceScore": 0.0, "insights": "", "relationship": ""}, ...]}`;

                try {
                    const result = await this.geminiService.askGemini(
                        batchAnalysisPrompt,
                        model || getCurrentModel(),
                        'You are a code analysis expert. Analyze code contexts for query relevance with precision.'
                    );

                    const analysisText = result.content[0].text || '{"analyses": []}';
                    batchAnalysis.push(`Batch ${batchIndex + 1}: ${analysisText}`);

                    // Parse analysis and update context relevance scores
                    let analyses: any[] = [];
                    try {
                        const parsed = JSON.parse(analysisText);
                        analyses = parsed.analyses || [];
                    } catch {
                        console.warn(`[Batch Processing] Failed to parse batch ${batchIndex + 1} analysis`);
                    }

                    // Update contexts with analysis results
                    return batch.map((context, idx) => {
                        const analysis = analyses.find(a => a.contextIndex === idx);
                        if (analysis) {
                            return {
                                ...context,
                                relevanceScore: Math.max(context.relevanceScore || 0.5, analysis.relevanceScore || 0.5),
                                metadata: {
                                    ...context.metadata,
                                    batchAnalysis: {
                                        insights: analysis.insights,
                                        relationship: analysis.relationship,
                                        batchIndex: batchIndex + 1
                                    }
                                }
                            };
                        }
                        return context;
                    });
                } catch (error) {
                    console.error(`[Batch Processing] Error processing batch ${batchIndex + 1}:`, error);
                    return batch; // Return original batch on error
                }
            })
        );

        // Combine all processed batches
        const analyzedContexts: RetrievedCodeContext[] = [];
        processedBatches.forEach((result) => {
            if (result.status === 'fulfilled') {
                analyzedContexts.push(...result.value);
            }
        });

        console.log(`[Batch Processing] Successfully analyzed ${analyzedContexts.length} contexts`);
        return { analyzedContexts, batchAnalysis };
    }

    /**
     * Enhanced batch processing with Gemini task type capabilities
     */
    private async _performGeminiBatchAnalysis(
        queries: string[],
        contexts: RetrievedCodeContext[],
        taskType: 'QUESTION_ANSWERING' | 'FACT_VERIFICATION' | 'CLASSIFICATION' = 'QUESTION_ANSWERING',
        model?: string
    ): Promise<{ results: string[]; confidence: number[] }> {
        if (queries.length === 0 || contexts.length === 0) {
            return { results: [], confidence: [] };
        }

        console.log(`[Gemini Batch Analysis] Processing ${queries.length} queries with ${contexts.length} contexts using task type: ${taskType}`);

        const contextSummary = contexts.map((ctx, idx) => 
            `Context ${idx + 1}: ${ctx.sourcePath} - ${ctx.content.substring(0, 200)}...`
        ).join('\n\n');

        const batchPrompts = queries.map(query => 
            `Task Type: ${taskType}\n\nQuery: ${query}\n\nRelevant Contexts:\n${contextSummary}\n\nProvide a comprehensive answer based on the provided contexts.`
        );

        try {
            const batchResults = await this.geminiService.batchAskGemini(
                batchPrompts,
                model || getCurrentModel(),
                `You are an expert code assistant. Use the ${taskType} task type to provide accurate responses based on the given contexts.`
            );

            const results = batchResults.map(result => result.content[0].text || 'No response generated');
            const confidence = batchResults.map(() => 0.85); // Placeholder confidence

            console.log(`[Gemini Batch Analysis] Successfully processed ${results.length} queries`);
            return { results, confidence };
        } catch (error) {
            console.error('[Gemini Batch Analysis] Batch processing failed:', error);
            return { results: queries.map(() => 'Analysis failed'), confidence: queries.map(() => 0.1) };
        }
    }

    async performIterativeSearch(args: IterativeRagArgs): Promise<IterativeRagResult> {
        const operationId = globalPerformanceTracker.startOperation('performIterativeSearch', { query: args.query });

        try {
            const {
                agent_id,
                query,
                model,
                max_iterations = 5,
                context_options,
                focus_area,
                analysis_focus_points,
                enable_web_search,
                google_search,
                continue_session,
                hallucination_check_threshold = 0.8,
                tavily_search_depth = 'basic',
                tavily_max_results = 5,
                tavily_include_raw_content = false,
                thinkingConfig,
                enable_dmqr,
                dmqr_query_count,
                enable_agentic_planning = true,
                enable_reflection = true,
                enable_hybrid_search = true,
                enable_long_rag = true,
                enable_corrective_rag = true,
                citation_accuracy_threshold = 0.9,
                long_rag_chunk_size = 2000,
                reflection_frequency = 2
            } = args;

            const contextRetriever = this.memoryManagerInstance.getCodebaseContextRetrieverService();

        let accumulatedContext: RetrievedCodeContext[] = [];
        const webSearchSources: { title: string; url: string }[] = [];
        const decisionLog: RagAnalysisResponse[] = [];
        const citations: Citation[] = [];
        const reflectionResults: ReflectionResult[] = [];
        const queryHistory = new Set<string>();
        let agenticPlan: AgenticRagPlan | undefined;

        const searchMetrics = {
            totalIterations: 0,
            contextItemsAdded: 0,
            webSearchesPerformed: 0,
            hallucinationChecksPerformed: 0,
            selfCorrectionLoops: 0,
            graphTraversals: 0,
            hybridSearches: 0,
            citationAccuracy: 0,
            citationCoverage: 0,
            totalCitationsGenerated: 0,
            totalCitationsUsed: 0,
            terminationReason: "In progress",
            dmqr: {
                enabled: !!enable_dmqr,
                queryCount: dmqr_query_count,
                generatedQueries: [] as string[],
                success: false,
                contextItemsGenerated: 0,
                error: undefined as string | undefined
            },
            turnLog: [] as Array<{
                turn: number;
                query: string;
                strategy: string;
                newContextCount: number;
                decision: string;
                reasoning: string;
                type: 'initial' | 'iterative' | 'self-correction' | 'agentic-plan' | 'reflection';
                quality: number;
                citations: number;
            }>
        };

        const focusString = this._generateFocusString(focus_area, analysis_focus_points);
        console.log(`[Enhanced RAG] Starting enhanced search for query: "${query}"`);

        let baseQueries: string[] = [query];
        if (enable_dmqr) {
            console.log('[Enhanced RAG] DMQR enabled – generating diverse queries for both embeddings and KG...');
            try {
                const dmqrResult = await this.diverseQueryRewriterService.rewriteAndRetrieve(query, { 
                    queryCount: dmqr_query_count,
                    kgQueryCount: Math.max(2, Math.floor((dmqr_query_count || 3) / 2))
                });
                
                baseQueries = dmqrResult.generatedQueries;
                searchMetrics.dmqr.generatedQueries = baseQueries;
                searchMetrics.dmqr.success = true;
                
                console.log(`[Enhanced RAG] DMQR produced ${baseQueries.length} embedding queries and ${dmqrResult.knowledgeGraphQueries?.length || 0} KG queries.`);

                // Pre-fetch context for all DMQR embedding queries to warm up the cache
                if (baseQueries.length > 1) {
                    console.log('[Enhanced RAG] Pre-fetching context for DMQR embedding queries...');
                    try {
                        const dmqrContexts = await this._retrieveContextWithCache(agent_id, baseQueries, context_options || {});
                        searchMetrics.dmqr.contextItemsGenerated = dmqrContexts.length;
                        console.log(`[Enhanced RAG] DMQR embedding context pre-fetching completed. Generated ${dmqrContexts.length} context items.`);
                    } catch (error) {
                        console.warn('[Enhanced RAG] DMQR embedding context pre-fetching failed:', error);
                        searchMetrics.dmqr.contextItemsGenerated = 0;
                    }
                }
                
                // Process KG queries if available and KG manager exists
                if (dmqrResult.knowledgeGraphQueries && dmqrResult.knowledgeGraphQueries.length > 0 && this.knowledgeGraphManager) {
                    console.log(`[Enhanced RAG] Processing ${dmqrResult.knowledgeGraphQueries.length} DMQR KG queries...`);
                    try {
                        const kgContexts: RetrievedCodeContext[] = [];
                        
                        for (const kgQuery of dmqrResult.knowledgeGraphQueries) {
                            try {
                                const graphResult = await this.knowledgeGraphManager.queryNaturalLanguage(agent_id, kgQuery.query);
                                const graphData = JSON.parse(graphResult);
                                
                                if (graphData.results && Array.isArray(graphData.results.nodes)) {
                                    const kgNodes = graphData.results.nodes.map((node: any) => ({
                                        type: 'kg_node_info' as const,
                                        sourcePath: `kg://${node.name}`,
                                        entityName: node.name,
                                        content: JSON.stringify(node.observations),
                                        relevanceScore: kgQuery.confidence || 0.85,
                                        metadata: { 
                                            nodeType: node.entityType,
                                            kgQueryType: kgQuery.searchStrategy,
                                            focusAreas: kgQuery.focusAreas
                                        }
                                    }));
                                    kgContexts.push(...kgNodes);
                                }
                            } catch (kgError) {
                                console.warn(`[Enhanced RAG] KG query failed for "${kgQuery.query}":`, kgError);
                            }
                        }
                        
                        if (kgContexts.length > 0) {
                            accumulatedContext = deduplicateContexts([...accumulatedContext, ...kgContexts]);
                            searchMetrics.dmqr.contextItemsGenerated += kgContexts.length;
                            searchMetrics.graphTraversals += dmqrResult.knowledgeGraphQueries.length;
                            console.log(`[Enhanced RAG] DMQR KG processing completed. Generated ${kgContexts.length} additional context items.`);
                        }
                    } catch (error) {
                        console.warn('[Enhanced RAG] DMQR KG processing failed:', error);
                    }
                }
            } catch (e: any) {
                searchMetrics.dmqr.success = false;
                searchMetrics.dmqr.error = e.message ?? 'unknown';
                baseQueries = [query];
            }
        }

        let currentQueries = [...baseQueries];
        let turn = 0;
        let stabilityCounter = 0; // Counts consecutive turns with no new context

        // Safety measures for infinite loop prevention
        let noNewContextCounter = 0;
        const maxNoNewContextIterations = 2;
        
        while (turn < max_iterations) {
            turn++;
            searchMetrics.totalIterations = turn;

            const turnQuery = currentQueries.shift();
            if (!turnQuery) {
                searchMetrics.terminationReason = "Exhausted all queries.";
                break;
            }

            // Safety check: Prevent infinite loops with duplicate queries
            if (queryHistory.has(turnQuery)) {
                console.log(`[Enhanced RAG] Skipping duplicate query: "${turnQuery}"`);
                noNewContextCounter++;
                if (noNewContextCounter >= maxNoNewContextIterations) {
                    searchMetrics.terminationReason = "No new context found in recent iterations - preventing infinite loop.";
                    console.log('[Enhanced RAG] Safety termination: No new context in recent iterations.');
                    break;
                }
                continue;
            }
            queryHistory.add(turnQuery);
            
            // Early termination for exceptional quality
            if (turn > 1 && accumulatedContext.length >= 15) {
                const estimatedCoverage = Math.min(accumulatedContext.length / 20, 1.0);
                if (estimatedCoverage > 0.9 && searchMetrics.citationAccuracy > 0.9) {
                    searchMetrics.terminationReason = "Exceptional quality achieved - early termination.";
                    console.log('[Enhanced RAG] Early termination: Exceptional quality and coverage achieved.');
                    break;
                }
            }

            const isInitialTurn = baseQueries.includes(turnQuery);
            console.log(`[Enhanced RAG] Turn ${turn} – Query: "${turnQuery}" (${isInitialTurn ? 'initial' : 'iterative'})`);

            // Agentic Planning Phase
            if (enable_agentic_planning && turn > 1) {
                agenticPlan = await this._performAgenticPlanning(query, turnQuery, accumulatedContext, turn, model);
                console.log(`[Enhanced RAG] Agentic plan: ${agenticPlan.strategy}`);
            }

            const contextBefore = accumulatedContext.length;
            let rawContext: RetrievedCodeContext[] = [];

            // Execute search based on agentic plan or default to hybrid
            if (enable_hybrid_search && agenticPlan?.strategy === 'hybrid_search') {
                rawContext = await this._performHybridSearch(agent_id, turnQuery, context_options || {}, agenticPlan);
                searchMetrics.hybridSearches++;
            } else if (agenticPlan?.strategy === 'graph_traversal' && this.knowledgeGraphManager) {
                try {
                    const graphResult = await this.knowledgeGraphManager.queryNaturalLanguage(agent_id, turnQuery);
                    const graphData = JSON.parse(graphResult);
                    if (graphData.results && Array.isArray(graphData.results.nodes)) {
                        rawContext = graphData.results.nodes.map((node: any) => ({
                            type: 'kg_node_info' as const,
                            sourcePath: `kg://${node.name}`,
                            entityName: node.name,
                            content: JSON.stringify(node.observations),
                            relevanceScore: 0.85
                        }));
                    }
                    searchMetrics.graphTraversals++;
                } catch (error) {
                    console.warn('[Enhanced RAG] Graph traversal failed, falling back to vector search');
                    rawContext = await this._retrieveContextWithCache(agent_id, [turnQuery], context_options || {});
                }
            } else {
                rawContext = await this._retrieveContextWithCache(agent_id, [turnQuery], context_options || {});
            }

            accumulatedContext = deduplicateContexts([...accumulatedContext, ...rawContext]);
            const addedNow = accumulatedContext.length - contextBefore;
            searchMetrics.contextItemsAdded += addedNow;

            // Generate citations for new context
            rawContext.forEach(context => {
                const citation = this._generateCitation(
                    context,
                    context.content.substring(0, 200),
                    context.relevanceScore || 0.8
                );
                citations.push(citation);
            });

            // Continuation mode with web search: Automatically perform web search when enabled
            if (continue_session && (google_search || enable_web_search) && turn === 1) {
                console.log('[Enhanced RAG] Continuation mode with web search enabled - performing web search');
                searchMetrics.webSearchesPerformed++;
                try {
                    const webResults = await callTavilyApi(query, { 
                        search_depth: tavily_search_depth, 
                        max_results: tavily_max_results, 
                        include_raw_content: tavily_include_raw_content 
                    });
                    
                    webResults.forEach((r: WebSearchResult) => {
                        webSearchSources.push({ title: r.title, url: r.url });
                        accumulatedContext.push({ 
                            type: 'documentation', 
                            sourcePath: r.url, 
                            entityName: r.title, 
                            content: r.content, 
                            relevanceScore: 0.95 
                        });
                        
                        const webCitation = this._generateCitation({
                            type: 'documentation',
                            sourcePath: r.url,
                            entityName: r.title,
                            content: r.content,
                            relevanceScore: 0.95
                        }, r.content.substring(0, 200), 0.9);
                        webCitation.sourceType = 'web';
                        webCitation.url = r.url;
                        citations.push(webCitation);
                    });
                    
                    console.log(`[Enhanced RAG] Web search completed: added ${webResults.length} web sources to context`);
                } catch (e: any) {
                    console.error('[Enhanced RAG] Web search failed in continuation mode:', e);
                }
            }

            // Enhanced Corrective RAG: Self-correction logic with reflection and safety measures
            if (addedNow === 0 && !isInitialTurn && enable_corrective_rag) {
                stabilityCounter++;
                noNewContextCounter++; // Track no new context for safety
                
                if (stabilityCounter >= 2) {
                    searchMetrics.terminationReason = "Context stable, no new information found.";
                    console.log(`[Enhanced RAG] Context has been stable for ${stabilityCounter} turns. Terminating search.`);
                    break;
                }
                
                // Apply corrective search after no context found
                if (stabilityCounter === 1) {
                    const correctiveQuery = `Broaden search for: ${query}. Look for related concepts, alternative implementations, or background information.`;
                    currentQueries.push(correctiveQuery);
                    searchMetrics.selfCorrectionLoops++;
                    console.log('[Enhanced RAG] Applied corrective search due to no new context.');
                }
            } else {
                stabilityCounter = 0;
                noNewContextCounter = 0; // Reset safety counter when context is found
            }

            // Create enhanced context flow with Long RAG support
            const contextFlow = this._createContextFlow(
                accumulatedContext, 
                turnQuery, 
                addedNow,
                enable_long_rag,
                long_rag_chunk_size
            );

            // Apply batch processing for context analysis (process 3 files at a time)
            let analyzedContextFlow = contextFlow;
            let batchAnalysisResults: string[] = [];
            
            if (contextFlow.length > 3) {
                console.log(`[Enhanced RAG] Applying batch context analysis to ${contextFlow.length} contexts`);
                const batchResult = await this._processBatchContextAnalysis(
                    contextFlow,
                    query, // Use original query for consistency
                    model
                );
                analyzedContextFlow = batchResult.analyzedContexts;
                batchAnalysisResults = batchResult.batchAnalysis;
                
                // Sort by updated relevance scores
                analyzedContextFlow.sort((a, b) => (b.relevanceScore || 0) - (a.relevanceScore || 0));
                console.log(`[Enhanced RAG] Batch analysis completed, reordered ${analyzedContextFlow.length} contexts by relevance`);
            }

            const formattedContext = formatContextForGemini(analyzedContextFlow)[0].text || '';
            const analysisPrompt = RAG_ANALYSIS_PROMPT
                .replace('{originalQuery}', query)
                .replace('{currentTurn}', String(turn))
                .replace('{maxIterations}', String(max_iterations))
                .replace('{accumulatedContext}', formattedContext)
                .replace('{focusString}', focusString);

            let analysisResult;
            try {
                analysisResult = await this.geminiService.askGemini(analysisPrompt, model, RAG_ANALYSIS_SYSTEM_INSTRUCTION, thinkingConfig);
            } catch (e: any) {
                searchMetrics.terminationReason = `Gemini analysis error: ${e.message}`;
                break;
            }

            const parsed = RagResponseParser.parseAnalysisResponse(analysisResult.content[0].text ?? '');
            if (!parsed) {
                searchMetrics.terminationReason = 'Parsing failure';
                break;
            }
            decisionLog.push(parsed);

            // Reflection Phase (periodic)
            if (enable_reflection && turn % reflection_frequency === 0) {
                const tempAnswer = analysisResult.content[0].text || '';
                const reflection = await this._performReflection(query, contextFlow, tempAnswer, model);
                reflectionResults.push(reflection);
                searchMetrics.hallucinationChecksPerformed++;

                if (reflection.missingInfo.length > 0 || reflection.hasHallucinations) {
                    const correctiveContext = await this._performCorrectiveSearch(
                        agent_id, query, accumulatedContext, reflection, context_options || {}, model
                    );

                    if (correctiveContext.length > 0) {
                        accumulatedContext = deduplicateContexts([...accumulatedContext, ...correctiveContext]);
                        searchMetrics.selfCorrectionLoops++;
                        
                        searchMetrics.turnLog.push({
                            turn,
                            query: turnQuery,
                            strategy: 'corrective_search',
                            newContextCount: correctiveContext.length,
                            decision: "CORRECTIVE_SEARCH",
                            reasoning: `Applied corrective search based on reflection: ${reflection.suggestions.join(', ')}`,
                            type: 'self-correction',
                            quality: reflection.qualityScore,
                            citations: correctiveContext.length
                        });
                    }
                }
            }

            const strategy = agenticPlan?.strategy || 'vector_search';
            const quality = reflectionResults.length > 0 ? 
                reflectionResults[reflectionResults.length - 1].qualityScore : 0.7;

            searchMetrics.turnLog.push({
                turn,
                query: turnQuery,
                strategy,
                newContextCount: addedNow,
                decision: parsed.decision,
                reasoning: parsed.reasoning,
                type: isInitialTurn ? 'initial' : 'iterative',
                quality,
                citations: addedNow
            });

            if (parsed.decision === 'ANSWER') {
                // Quality Gate: Check if we meet minimum quality thresholds before allowing ANSWER
                const estimatedQuality = parsed.qualityScore || 0.7;
                const contextSufficiency = Math.min(accumulatedContext.length / 10, 1.0); // Rough quality estimate
                const iterationProgress = turn / max_iterations;
                
                console.log(`[Enhanced RAG] Quality Gate Check: quality=${estimatedQuality}, context=${contextSufficiency}, iteration=${iterationProgress}`);
                
                // Apply quality gates unless we're at maximum iterations
                if (turn < max_iterations && (estimatedQuality < 0.8 || contextSufficiency < 0.6)) {
                    console.log(`[Enhanced RAG] Quality gate failed: quality=${estimatedQuality} < 0.8 or context=${contextSufficiency} < 0.6. Continuing search.`);
                    
                    // Force another search iteration with corrective query
                    const correctiveQuery = `Find additional comprehensive information about: ${query}. Focus on areas not yet covered in detail.`;
                    currentQueries.push(correctiveQuery);
                    searchMetrics.selfCorrectionLoops++;
                    
                    // Add to decision log
                    decisionLog.push({
                        decision: 'CORRECTIVE_SEARCH' as any,
                        reasoning: `Quality gate failed: quality=${estimatedQuality}, context=${contextSufficiency}. Continuing search.`,
                        nextCodebaseQuery: correctiveQuery,
                        qualityScore: estimatedQuality,
                        confidenceScore: 0.6,
                        contextUsed: formattedContext.substring(0, 500) + '...',
                        promptSent: analysisPrompt.substring(0, 200) + '...',
                        rawGeminiResponse: analysisResult.content[0].text?.substring(0, 300) + '...'
                    });
                    continue;
                }
                
                searchMetrics.terminationReason = turn >= max_iterations 
                    ? "Max iterations reached with forced answer" 
                    : "ANSWER decision reached with quality gates passed";
                console.log('[Enhanced RAG] Decision: ANSWER – generating final answer with citations.');
                
                const enhancedAnswerPrompt = RAG_ANSWER_PROMPT
                    .replace('{originalQuery}', query)
                    .replace('{contextString}', formattedContext)
                    .replace('{focusString}', focusString)
                    .replace('{totalSources}', analyzedContextFlow.length.toString())
                    .replace('{searchStrategy}', 'enhanced_hybrid_search')
                    .replace('{contextQuality}', '0.85')
                    .replace('{web_search_flags}', `Web Search: ${(google_search || enable_web_search) ? 'ENABLED' : 'DISABLED'}`)
                    .replace('{continuation_mode}', `Continuation Mode: ${continue_session ? 'ACTIVE - Building on conversation history' : 'DISABLED'}`) +
                    `\n\nIMPORTANT: You have ${analyzedContextFlow.length} context sources available. Include proper citations in your answer using the format [cite_N] where N is the citation number. Strive to utilize multiple sources and provide comprehensive coverage. Each claim should be supported by specific source references.`;
                
                const answerResult = await this.geminiService.askGemini(
                    enhancedAnswerPrompt, 
                    model, 
                    'You are a helpful AI assistant providing accurate answers with proper citations based on the given context.'
                );
                
                // Calculate citation accuracy (actual usage vs availability)
                const finalAnswer = answerResult.content[0].text ?? '';
                const citationMatches = finalAnswer.match(/\[cite_\d+\]/g) || [];
                
                // Calculate actual citation accuracy: unique citations used / total citations in answer
                const uniqueCitationNumbers = new Set(
                    citationMatches.map(match => {
                        const num = match.match(/\d+/)?.[0];
                        return num ? parseInt(num) : null;
                    }).filter(num => num !== null)
                );
                
                // Citation accuracy is the ratio of valid citations to total citation attempts
                searchMetrics.citationAccuracy = citationMatches.length > 0 
                    ? uniqueCitationNumbers.size / citationMatches.length 
                    : (citations.length > 0 ? 0.0 : 1.0);
                
                // Calculate citation coverage: what percentage of available sources were cited
                const citationCoverage = citations.length > 0 
                    ? uniqueCitationNumbers.size / citations.length 
                    : 1.0;
                
                // Store additional metrics
                searchMetrics.citationCoverage = citationCoverage;
                searchMetrics.totalCitationsGenerated = citations.length;
                searchMetrics.totalCitationsUsed = uniqueCitationNumbers.size;
                
                console.log(`[Enhanced RAG] Citation metrics: accuracy=${(searchMetrics.citationAccuracy * 100).toFixed(1)}%, coverage=${(citationCoverage * 100).toFixed(1)}%, used=${uniqueCitationNumbers.size}/${citations.length}`);
                
                // Final quality gate: Check citation accuracy threshold
                if (searchMetrics.citationAccuracy < citation_accuracy_threshold && citationCoverage < 0.8) {
                    console.warn(`[Enhanced RAG] Quality warning: Citation accuracy ${(searchMetrics.citationAccuracy * 100).toFixed(1)}% and coverage ${(citationCoverage * 100).toFixed(1)}% below thresholds.`);
                    searchMetrics.terminationReason += " (Quality warning: Low citation accuracy/coverage)";
                }
                
                return { 
                    accumulatedContext, 
                    webSearchSources, 
                    finalAnswer, 
                    decisionLog, 
                    citations,
                    reflectionResults,
                    agenticPlan,
                    searchMetrics 
                };
            } else if (parsed.decision === 'SEARCH_AGAIN' && parsed.nextCodebaseQuery) {
                currentQueries.push(parsed.nextCodebaseQuery);
            } else if (parsed.decision === 'SEARCH_WEB' && enable_web_search && parsed.nextWebQuery) {
                searchMetrics.webSearchesPerformed++;
                try {
                    const webResults = await callTavilyApi(parsed.nextWebQuery, { search_depth: tavily_search_depth, max_results: tavily_max_results, include_raw_content: tavily_include_raw_content });
                    webResults.forEach((r: WebSearchResult) => {
                        webSearchSources.push({ title: r.title, url: r.url });
                        accumulatedContext.push({ type: 'documentation', sourcePath: r.url, entityName: r.title, content: r.content, relevanceScore: 0.95 });
                        
                        const webCitation = this._generateCitation({
                            type: 'documentation',
                            sourcePath: r.url,
                            entityName: r.title,
                            content: r.content,
                            relevanceScore: 0.95
                        }, r.content.substring(0, 200), 0.9);
                        webCitation.sourceType = 'web';
                        webCitation.url = r.url;
                        citations.push(webCitation);
                    });
                } catch (e: any) {
                    console.error('[Enhanced RAG] Web search failed:', e);
                }
            }
        }

        if (searchMetrics.terminationReason === "In progress") {
            searchMetrics.terminationReason = "Max iterations reached.";
        }

        console.log('[Enhanced RAG] Generating final answer from accumulated context with citations.');
        
        const finalContextFlow = this._createContextFlow(
            accumulatedContext, 
            query, 
            0, 
            enable_long_rag, 
            long_rag_chunk_size
        );
        const fallbackContext = formatContextForGemini(finalContextFlow)[0].text || '';
        const fallbackPrompt = RAG_ANSWER_PROMPT
            .replace('{originalQuery}', query)
            .replace('{contextString}', fallbackContext)
            .replace('{focusString}', focusString)
            .replace('{totalSources}', finalContextFlow.length.toString())
            .replace('{searchStrategy}', 'fallback_search')
            .replace('{contextQuality}', '0.70')
            .replace('{web_search_flags}', `Web Search: ${(google_search || enable_web_search) ? 'ENABLED' : 'DISABLED'}`)
            .replace('{continuation_mode}', `Continuation Mode: ${continue_session ? 'ACTIVE - Building on conversation history' : 'DISABLED'}`) +
            `\n\nIMPORTANT: You have ${finalContextFlow.length} context sources available. Include proper citations in your answer using the format [cite_N] where N is the citation number. Utilize multiple sources when possible for comprehensive coverage.`;
        
        const fallbackResult = await this.geminiService.askGemini(
            fallbackPrompt, 
            model, 
            'You are a helpful AI assistant providing accurate answers with citations based on the given context.'
        );

        const finalAnswer = fallbackResult.content[0].text ?? 'Unable to formulate an answer.';
        const citationMatches = finalAnswer.match(/\[cite_\d+\]/g) || [];
        
        // Apply same citation accuracy calculation as in main flow
        const uniqueCitationNumbers = new Set(
            citationMatches.map(match => {
                const num = match.match(/\d+/)?.[0];
                return num ? parseInt(num) : null;
            }).filter(num => num !== null)
        );
        
        searchMetrics.citationAccuracy = citationMatches.length > 0 
            ? uniqueCitationNumbers.size / citationMatches.length 
            : (citations.length > 0 ? 0.0 : 1.0);
        searchMetrics.citationCoverage = citations.length > 0 
            ? uniqueCitationNumbers.size / citations.length 
            : 1.0;
        searchMetrics.totalCitationsGenerated = citations.length;
        searchMetrics.totalCitationsUsed = uniqueCitationNumbers.size;

        return { 
            accumulatedContext, 
            webSearchSources, 
            finalAnswer, 
            decisionLog, 
            citations,
            reflectionResults,
            agenticPlan,
            searchMetrics 
        };
        } catch (error: any) {
            globalPerformanceTracker.endOperation(operationId, false, error.message);
            throw error;
        }
    }

    /**
     * Get performance metrics summary for monitoring and optimization.
     */
    getPerformanceMetrics(): any {
        return globalPerformanceTracker.getSummary();
    }

    /**
     * Clear performance metrics (useful for testing or resetting metrics).
     */
    clearPerformanceMetrics(): void {
        globalPerformanceTracker.clear();
    }
}
