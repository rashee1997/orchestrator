import { MemoryManager } from '../../database/memory_manager.js';
import { GeminiIntegrationService } from '../../database/services/GeminiIntegrationService.js';
import { RetrievedCodeContext } from '../../database/services/CodebaseContextRetrieverService.js';
import { ContextRetrievalOptions } from '../../database/services/CodebaseContextRetrieverService.js';
import {
    RAG_ANALYSIS_PROMPT,
    RAG_ANALYSIS_SYSTEM_INSTRUCTION,
    RAG_ANSWER_PROMPT,
    RAG_VERIFICATION_PROMPT,
    RAG_SELF_CORRECTION_PROMPT
} from '../../database/services/gemini-integration-modules/GeminiPromptTemplates.js';
import {
    AGENTIC_RAG_PLANNING_PROMPT,
    RAG_REFLECTION_PROMPT,
    CORRECTIVE_RAG_PROMPT,
    HYBRID_RAG_COORDINATION_PROMPT,
    LONG_RAG_CHUNKING_PROMPT,
    CITATION_ATTRIBUTION_PROMPT
} from './enhanced_rag_prompts.js';
import { RagAnalysisResponse } from './rag_response_parser.js';
import { RagResponseParser } from './rag_response_parser.js';
import { DiverseQueryRewriterService } from './diverse_query_rewriter_service.js';
import { callTavilyApi, WebSearchResult } from '../../integrations/tavily.js';
import {
    formatRetrievedContextForPrompt as formatContextForGemini
} from '../../database/services/gemini-integration-modules/GeminiContextFormatter.js';
import { GeminiApiNotInitializedError } from '../../database/services/gemini-integration-modules/GeminiApiClient.js';
import { McpError, ErrorCode } from '@modelcontextprotocol/sdk/types.js';
import { deduplicateContexts } from '../../utils/context_utils.js';
import { getCurrentModel } from '../../database/services/gemini-integration-modules/GeminiConfig.js';
import { globalPerformanceTracker } from '../../utils/performance_tracker.js';
import { KnowledgeGraphManager } from '../../database/managers/KnowledgeGraphManager.js';

export interface Citation {
    id: string;
    source: string;
    sourceType: 'code' | 'documentation' | 'web' | 'knowledge_graph';
    title: string;
    url?: string;
    filePath?: string;
    lineNumbers?: [number, number];
    confidence: number;
    relevanceScore: number;
    extractedText: string;
    context?: string;
}

export interface ReflectionResult {
    hasHallucinations: boolean;
    missingInfo: string[];
    qualityScore: number;
    suggestions: string[];
    corrections: string[];
    confidence: number;
}

export interface AgenticRagPlan {
    strategy: 'vector_search' | 'graph_traversal' | 'hybrid_search' | 'web_augmented' | 'corrective_search';
    steps: Array<{
        action: string;
        target: string;
        priority: number;
        reasoning: string;
    }>;
    expectedOutcome: string;
    fallbackStrategy?: string;
}

/**
 * Result returned by the orchestrator after the whole iterative search finishes.
 */
export interface IterativeRagResult {
    /** All unique context items collected across every turn. */
    accumulatedContext: RetrievedCodeContext[];
    /** Web results (if any) that were added to the context. */
    webSearchSources: { title: string; url: string }[];
    /**  Final answer generated by Gemini (if an ANSWER decision was reached). */
    finalAnswer?: string;
    /** Full log of every RAG‑analysis response (useful for debugging). */
    decisionLog: RagAnalysisResponse[];
    /** Source citations with detailed attribution */
    citations: Citation[];
    /** Reflection analysis results for quality control */
    reflectionResults: ReflectionResult[];
    /** Agentic planning results */
    agenticPlan?: AgenticRagPlan;
    /** Metrics that give insight into the search behaviour. */
    searchMetrics: {
        totalIterations: number;
        contextItemsAdded: number;
        webSearchesPerformed: number;
        hallucinationChecksPerformed: number;
        selfCorrectionLoops: number;
        terminationReason: string;
        graphTraversals: number;
        hybridSearches: number;
        citationAccuracy: number;
        dmqr: {
            enabled: boolean;
            queryCount?: number;
            generatedQueries?: string[];
            success: boolean;
            contextItemsGenerated: number;
            error?: string;
        };
        /** Timestamped record of each turn – handy for UI visualisation. */
        turnLog: Array<{
            turn: number;
            query: string;
            strategy: string;
            newContextCount: number;
            decision: string;
            reasoning: string;
            type: 'initial' | 'iterative' | 'self-correction' | 'agentic-plan' | 'reflection';
            quality: number;
            citations: number;
        }>;
    };
}


/**
 * Arguments accepted by the orchestrator.
 */
export interface IterativeRagArgs {
    agent_id: string;
    query: string;
    model?: string;
    systemInstruction?: string;

    context_options?: ContextRetrievalOptions;
    focus_area?: string;
    analysis_focus_points?: string[];
    enable_web_search?: boolean;
    max_iterations?: number;
    hallucination_check_threshold?: number;
    tavily_search_depth?: 'basic' | 'advanced';
    tavily_max_results?: number;
    tavily_include_raw_content?: boolean;
    tavily_include_images?: boolean;
    tavily_include_image_descriptions?: boolean;
    tavily_time_period?: string;
    tavily_topic?: string;
    thinkingConfig?: { thinkingBudget?: number; thinkingMode?: 'AUTO' | 'MODE_THINK' };
    enable_dmqr?: boolean;
    dmqr_query_count?: number;
    enable_agentic_planning?: boolean;
    enable_reflection?: boolean;
    enable_hybrid_search?: boolean;
    enable_long_rag?: boolean;
    enable_corrective_rag?: boolean;
    citation_accuracy_threshold?: number;
    long_rag_chunk_size?: number;
    reflection_frequency?: number;
}

/**
 * The orchestrator that drives the multi‑turn, intelligent RAG loop.
 */
export class IterativeRagOrchestrator {
    private memoryManagerInstance: MemoryManager;
    private geminiService: GeminiIntegrationService;
    private diverseQueryRewriterService: DiverseQueryRewriterService;
    private knowledgeGraphManager?: KnowledgeGraphManager;

    // Performance optimization: Session-level context cache
    private sessionContextCache: Map<string, {
        context: RetrievedCodeContext[];
        timestamp: number;
        query: string;
        options: ContextRetrievalOptions;
    }>;
    private readonly CACHE_TTL = 10 * 60 * 1000; // 10 minutes for session cache
    private readonly MAX_SESSION_CACHE_SIZE = 50;
    private citationIdCounter = 0;

    constructor(
        memoryManagerInstance: MemoryManager,
        geminiService: GeminiIntegrationService,
        diverseQueryRewriterService: DiverseQueryRewriterService,
        knowledgeGraphManager?: KnowledgeGraphManager
    ) {
        this.memoryManagerInstance = memoryManagerInstance;
        this.geminiService = geminiService;
        this.diverseQueryRewriterService = diverseQueryRewriterService;
        this.knowledgeGraphManager = knowledgeGraphManager;
        this.sessionContextCache = new Map();
    }

    /**
     * Generate cache key for session context cache.
     */
    private _generateSessionCacheKey(query: string, options: ContextRetrievalOptions): string {
        const optionsStr = JSON.stringify({
            topKEmbeddings: options.topKEmbeddings,
            kgQueryDepth: options.kgQueryDepth,
            topKKgResults: options.topKKgResults,
            targetFilePaths: options.targetFilePaths?.sort(),
            embeddingScoreThreshold: options.embeddingScoreThreshold,
            useHybridSearch: options.useHybridSearch,
            enableReranking: options.enableReranking
        });
        return `${query}:${optionsStr}`;
    }

    /**
     * Check if cached context is still valid.
     */
    private _isSessionCacheValid(timestamp: number): boolean {
        return (Date.now() - timestamp) < this.CACHE_TTL;
    }

    private _generateCitation(
        context: RetrievedCodeContext,
        extractedText: string,
        confidence: number = 0.8
    ): Citation {
        return {
            id: `cite_${++this.citationIdCounter}`,
            source: context.sourcePath,
            sourceType: context.type as Citation['sourceType'],
            title: context.entityName || context.sourcePath,
            filePath: context.sourcePath,
            lineNumbers: context.metadata?.startLine && context.metadata?.endLine ? [context.metadata.startLine, context.metadata.endLine] : undefined,
            confidence,
            relevanceScore: context.relevanceScore || 0.7,
            extractedText: extractedText.substring(0, 200),
            context: context.content.substring(0, 500)
        };
    }

    private async _performAgenticPlanning(
        originalQuery: string,
        currentQuery: string,
        currentContext: RetrievedCodeContext[],
        iteration: number,
        model?: string
    ): Promise<AgenticRagPlan> {
        const contextSummary = currentContext.slice(-3).map(c => 
            `- ${c.type}: ${c.entityName || 'Unknown'} (${c.sourcePath})`
        ).join('\n');
        
        const previousStrategy = iteration > 1 ? 'vector_search' : 'initial';
        const contextQuality = currentContext.length > 0 ? 0.7 : 0.3;
        const informationGaps = currentContext.length < 3 ? ['implementation details', 'usage examples'] : ['edge cases'];
        
        const planningPrompt = AGENTIC_RAG_PLANNING_PROMPT
            .replace('{originalQuery}', originalQuery)
            .replace('{currentQuery}', currentQuery)
            .replace('{currentIteration}', iteration.toString())
            .replace('{previousStrategy}', previousStrategy)
            .replace('{contextQuality}', contextQuality.toString())
            .replace('{informationGaps}', informationGaps.join(', '))
            .replace('{contextSummary}', contextSummary);

        const result = await this.geminiService.askGemini(planningPrompt, model || getCurrentModel());
        try {
            const parsed = JSON.parse(result.content[0].text?.trim() || '{}');
            return {
                strategy: parsed.recommended_strategy?.primary_modality || 'vector_search',
                steps: parsed.execution_plan?.immediate_actions?.map((action: string, idx: number) => ({
                    action,
                    target: currentQuery,
                    priority: idx + 1,
                    reasoning: `Step ${idx + 1} of agentic plan`
                })) || [{ action: 'search', target: currentQuery, priority: 1, reasoning: 'default action' }],
                expectedOutcome: parsed.execution_plan?.query_formulation || 'relevant context',
                fallbackStrategy: parsed.contingency_planning?.fallback_strategy || 'hybrid_search'
            };
        } catch (error) {
            console.warn('[Agentic Planning] Failed to parse response, using fallback:', error);
            return {
                strategy: 'vector_search',
                steps: [{ action: 'search', target: currentQuery, priority: 3, reasoning: 'fallback plan' }],
                expectedOutcome: 'relevant context',
                fallbackStrategy: 'hybrid_search'
            };
        }
    }

    private async _performReflection(
        originalQuery: string,
        context: RetrievedCodeContext[],
        currentAnswer: string,
        model?: string
    ): Promise<ReflectionResult> {
        const sourceContext = context.map(c => 
            `Source: ${c.sourcePath} | Entity: ${c.entityName || 'Unknown'} | Type: ${c.type}`
        ).join('\n');
        const searchStrategy = 'hybrid_search'; // This would come from the current strategy
        const iterationCount = 1; // This would be passed in
        
        const reflectionPrompt = RAG_REFLECTION_PROMPT
            .replace('{originalQuery}', originalQuery)
            .replace('{generatedResponse}', currentAnswer)
            .replace('{sourceContext}', sourceContext)
            .replace('{searchStrategy}', searchStrategy)
            .replace('{iterationCount}', iterationCount.toString());

        const result = await this.geminiService.askGemini(reflectionPrompt, model || getCurrentModel());
        try {
            const parsed = JSON.parse(result.content[0].text?.trim() || '{}');
            return {
                hasHallucinations: parsed.hallucination_analysis?.detected_hallucinations?.length > 0 || false,
                missingInfo: parsed.completeness_analysis?.missing_aspects || [],
                qualityScore: parsed.overall_assessment?.quality_score || 0.5,
                suggestions: parsed.improvement_recommendations?.enhancement_suggestions || [],
                corrections: parsed.improvement_recommendations?.immediate_fixes || [],
                confidence: parsed.overall_assessment?.overall_confidence || 0.5
            };
        } catch (error) {
            console.warn('[Reflection] Failed to parse response, using fallback:', error);
            return {
                hasHallucinations: false,
                missingInfo: [],
                qualityScore: 0.5,
                suggestions: [],
                corrections: [],
                confidence: 0.5
            };
        }
    }

    private async _performHybridSearch(
        agentId: string,
        query: string,
        options: ContextRetrievalOptions,
        plan?: AgenticRagPlan
    ): Promise<RetrievedCodeContext[]> {
        const results: RetrievedCodeContext[] = [];

        // Vector search
        const vectorResults = await this._retrieveContextWithCache(agentId, [query], options);
        results.push(...vectorResults);

        // Knowledge graph search (if available)
        if (this.knowledgeGraphManager && plan?.strategy === 'hybrid_search') {
            try {
                const graphQuery = await this.knowledgeGraphManager.queryNaturalLanguage(agentId, query);
                const graphData = JSON.parse(graphQuery);
                
                if (graphData.results && Array.isArray(graphData.results.nodes)) {
                    graphData.results.nodes.forEach((node: any) => {
                        results.push({
                            type: 'kg_node_info',
                            sourcePath: `kg://${node.name}`,
                            entityName: node.name,
                            content: JSON.stringify(node.observations),
                            relevanceScore: 0.85,
                            metadata: { nodeType: node.entityType }
                        });
                    });
                }
            } catch (error) {
                console.warn('[Hybrid Search] Knowledge graph query failed:', error);
            }
        }

        return deduplicateContexts(results);
    }

    private async _performCorrectiveSearch(
        agentId: string,
        originalQuery: string,
        previousContext: RetrievedCodeContext[],
        reflectionResult: ReflectionResult,
        options: ContextRetrievalOptions,
        model?: string
    ): Promise<RetrievedCodeContext[]> {
        if (!reflectionResult.hasHallucinations && reflectionResult.missingInfo.length === 0) {
            return [];
        }

        const currentContext = previousContext.slice(-3).map(c => 
            `${c.sourcePath}: ${c.entityName || 'Unknown'}`
        ).join(', ');
        
        const correctionPrompt = CORRECTIVE_RAG_PROMPT
            .replace('{currentQuery}', originalQuery)
            .replace('{reflectionResults}', JSON.stringify(reflectionResult))
            .replace('{currentContext}', currentContext)
            .replace('{hasHallucinations}', reflectionResult.hasHallucinations.toString())
            .replace('{missingInfo}', reflectionResult.missingInfo.join(', '))
            .replace('{qualityScore}', reflectionResult.qualityScore.toString());
        
        try {
            const result = await this.geminiService.askGemini(correctionPrompt, model || getCurrentModel());
            const parsed = JSON.parse(result.content[0].text?.trim() || '{}');
            const correctedQueries = parsed.correctedQueries || [
                `${originalQuery} focusing on: ${reflectionResult.corrections.join(', ')} ${reflectionResult.missingInfo.join(', ')}`.trim()
            ];
            
            return await this._retrieveContextWithCache(agentId, correctedQueries, options);
        } catch (error) {
            console.warn('[Corrective Search] Failed to use enhanced prompt, using fallback:', error);
            const fallbackQuery = `${originalQuery} focusing on: ${reflectionResult.corrections.join(', ')} ${reflectionResult.missingInfo.join(', ')}`.trim();
            return await this._retrieveContextWithCache(agentId, [fallbackQuery], options);
        }
    }

    private _processLongContexts(contexts: RetrievedCodeContext[], maxChunkSize: number = 2000): RetrievedCodeContext[] {
        return contexts.flatMap(context => {
            if (context.content.length <= maxChunkSize) {
                return [context];
            }

            const chunks: RetrievedCodeContext[] = [];
            const content = context.content;
            let startIndex = 0;

            while (startIndex < content.length) {
                let endIndex = startIndex + maxChunkSize;
                
                // Try to break at natural boundaries (sentences, paragraphs)
                if (endIndex < content.length) {
                    const lastPeriod = content.lastIndexOf('.', endIndex);
                    const lastNewline = content.lastIndexOf('\n', endIndex);
                    const breakPoint = Math.max(lastPeriod, lastNewline);
                    
                    if (breakPoint > startIndex + maxChunkSize * 0.5) {
                        endIndex = breakPoint + 1;
                    }
                }

                const chunkContent = content.slice(startIndex, endIndex);
                chunks.push({
                    ...context,
                    content: chunkContent,
                    entityName: `${context.entityName || 'chunk'}_${chunks.length + 1}`,
                    metadata: {
                        ...context.metadata,
                        isChunk: true,
                        chunkIndex: chunks.length,
                        originalLength: content.length
                    }
                });

                startIndex = endIndex;
            }

            return chunks;
        });
    }

    /**
     * Clean up expired session cache entries.
     */
    private _cleanupSessionCache(): void {
        if (this.sessionContextCache.size > this.MAX_SESSION_CACHE_SIZE) {
            const entries = Array.from(this.sessionContextCache.entries());
            entries.sort((a, b) => a[1].timestamp - b[1].timestamp);
            const toRemove = entries.slice(0, Math.floor(this.MAX_SESSION_CACHE_SIZE * 0.3));
            toRemove.forEach(([key]) => this.sessionContextCache.delete(key));
            console.log(`[IterativeRagOrchestrator] Cleaned up ${toRemove.length} expired session cache entries`);
        }
    }

    /**
     * Retrieve context with session-level caching and parallel processing.
     */
    private async _retrieveContextWithCache(
        agentId: string,
        queries: string[],
        options: ContextRetrievalOptions
    ): Promise<RetrievedCodeContext[]> {
        const operationId = globalPerformanceTracker.startOperation('retrieveContextWithCache', {
            queryCount: queries.length,
            agentId
        });

        try {
            const contextRetriever = this.memoryManagerInstance.getCodebaseContextRetrieverService();
            const allContexts: RetrievedCodeContext[] = [];
            const uncachedQueries: string[] = [];
            const cachedContexts: RetrievedCodeContext[] = [];

        // Check cache for each query
        for (const query of queries) {
            const cacheKey = this._generateSessionCacheKey(query, options);
            const cached = this.sessionContextCache.get(cacheKey);

            if (cached && this._isSessionCacheValid(cached.timestamp)) {
                console.log(`[Session Cache HIT] Using cached context for query: "${query.substring(0, 50)}..."`);
                cachedContexts.push(...cached.context);
            } else {
                uncachedQueries.push(query);
            }
        }

        // Parallel retrieval for uncached queries
        if (uncachedQueries.length > 0) {
            console.log(`[Parallel Retrieval] Processing ${uncachedQueries.length} uncached queries`);

            const retrievalPromises = uncachedQueries.map(async (query) => {
                try {
                    const context = await contextRetriever.retrieveContextForPrompt(agentId, query, options);
                    // Cache the result
                    const cacheKey = this._generateSessionCacheKey(query, options);
                    this.sessionContextCache.set(cacheKey, {
                        context,
                        timestamp: Date.now(),
                        query,
                        options
                    });
                    return context;
                } catch (error) {
                    console.error(`[Parallel Retrieval] Failed to retrieve context for query "${query}":`, error);
                    return [];
                }
            });

            try {
                const retrievedContexts = await Promise.allSettled(retrievalPromises);
                retrievedContexts.forEach((result) => {
                    if (result.status === 'fulfilled') {
                        allContexts.push(...result.value);
                    }
                });
            } catch (error) {
                console.error('[Parallel Retrieval] Error in parallel context retrieval:', error);
            }

            this._cleanupSessionCache();
        }

        // Combine cached and newly retrieved contexts
        allContexts.push(...cachedContexts);

        globalPerformanceTracker.endOperation(operationId, true);
        return allContexts;
        } catch (error: any) {
            globalPerformanceTracker.endOperation(operationId, false, error.message);
            throw error;
        }
    }

    /**
     * Build the optional "focus" block that is injected into the RAG prompts.
     */
    private _generateFocusString(focusArea?: string, analysisFocusPoints?: string[]): string {
        let focusString = '';
        if (focusArea) {
            if (analysisFocusPoints && analysisFocusPoints.length) {
                focusString =
                    'Focus on the following aspects for your analysis and response:\n' +
                    analysisFocusPoints.map((p, i) => `${i + 1}. **${p}**`).join('\n');
            } else {
                switch (focusArea) {
                    case 'code_review':
                        focusString =
                            'Focus on all aspects including:\n' +
                            '1. **Potential Bugs & Errors**\n' +
                            '2. **Best Practices & Conventions**\n' +
                            '3. **Performance**\n' +
                            '4. **Security Vulnerabilities**\n' +
                            '5. **Readability & Maintainability**';
                        break;
                    case 'code_explanation':
                        focusString = 'Explain the code clearly and concisely.';
                        break;
                    case 'enhancement_suggestions':
                        focusString = 'Suggest improvements and enhancements.';
                        break;
                    case 'bug_fixing':
                        focusString = 'Identify and suggest fixes for bugs.';
                        break;
                    case 'refactoring':
                        focusString = 'Suggest refactoring opportunities.';
                        break;
                    case 'testing':
                        focusString = 'Provide testing strategies and test case generation.';
                        break;
                    case 'documentation':
                        focusString = 'Generate or improve documentation.';
                        break;
                    case 'code_modularization_orchestration':
                        focusString = 'Discuss modularity, architecture, and orchestration patterns.';
                        break;
                    default:
                        focusString = '';
                }
            }
            if (focusString) {
                focusString = `--- Focus Area ---\n${focusString}\n\n`;
            }
        }
        return focusString;
    }

    /**
     * Create an enhanced context flow that prioritizes recent and relevant information with Long RAG support.
     * This addresses the "context rot" problem by organizing context logically.
     */
    private _createContextFlow(
        accumulatedContext: RetrievedCodeContext[],
        currentQuery: string,
        recentItemsCount: number,
        enableLongRag: boolean = false,
        longRagChunkSize: number = 2000
    ): RetrievedCodeContext[] {
        if (accumulatedContext.length === 0) return [];

        let processedContexts = accumulatedContext;

        // Apply Long RAG processing if enabled
        if (enableLongRag) {
            processedContexts = this._processLongContexts(processedContexts, longRagChunkSize);
        }

        // Separate recent context from older context
        const recentContext = processedContexts.slice(-recentItemsCount);
        const olderContext = processedContexts.slice(0, -recentItemsCount);

        // Sort contexts by relevance and type priority
        const sortByPriority = (contexts: RetrievedCodeContext[]): RetrievedCodeContext[] => {
            const typePriority = {
                'function': 5,
                'method': 4,
                'class': 3,
                'file': 2,
                'documentation': 1,
                'knowledge_graph': 6
            };

            return contexts.sort((a, b) => {
                // Higher relevance score gets priority
                const aScore = a.relevanceScore || 0;
                const bScore = b.relevanceScore || 0;

                if (Math.abs(bScore - aScore) > 0.1) {
                    return bScore - aScore;
                }

                // Then by type priority
                const aPriority = typePriority[a.type as keyof typeof typePriority] || 0;
                const bPriority = typePriority[b.type as keyof typeof typePriority] || 0;

                return bPriority - aPriority;
            });
        };

        // Process recent context (highest priority)
        const prioritizedRecent = sortByPriority(recentContext);

        // Process older context with lower priority and potential summarization
        let processedOlder = olderContext;
        if (olderContext.length > 10) {
            // Keep only high-relevance older items
            processedOlder = olderContext.filter(ctx => (ctx.relevanceScore || 0) >= 0.8);
            if (processedOlder.length > 5) {
                processedOlder = processedOlder.slice(0, 5); // Limit older context
            }
        }

        // Combine with recent context first, then older context
        const contextFlow = [
            ...prioritizedRecent,
            ...processedOlder
        ];

        // Final deduplication
        const uniqueContexts = Array.from(
            new Map(contextFlow.map(item => [`${item.sourcePath}#${item.entityName}`, item])).values()
        );

        return uniqueContexts;
    }


    async performIterativeSearch(args: IterativeRagArgs): Promise<IterativeRagResult> {
        const operationId = globalPerformanceTracker.startOperation('performIterativeSearch', { query: args.query });

        try {
            const {
                agent_id,
                query,
                model,
                max_iterations = 3,
                context_options,
                focus_area,
                analysis_focus_points,
                enable_web_search,
                hallucination_check_threshold = 0.8,
                tavily_search_depth = 'basic',
                tavily_max_results = 5,
                tavily_include_raw_content = false,
                thinkingConfig,
                enable_dmqr,
                dmqr_query_count,
                enable_agentic_planning = true,
                enable_reflection = true,
                enable_hybrid_search = true,
                enable_long_rag = true,
                enable_corrective_rag = true,
                citation_accuracy_threshold = 0.9,
                long_rag_chunk_size = 2000,
                reflection_frequency = 2
            } = args;

            const contextRetriever = this.memoryManagerInstance.getCodebaseContextRetrieverService();

        let accumulatedContext: RetrievedCodeContext[] = [];
        const webSearchSources: { title: string; url: string }[] = [];
        const decisionLog: RagAnalysisResponse[] = [];
        const citations: Citation[] = [];
        const reflectionResults: ReflectionResult[] = [];
        const queryHistory = new Set<string>();
        let agenticPlan: AgenticRagPlan | undefined;

        const searchMetrics = {
            totalIterations: 0,
            contextItemsAdded: 0,
            webSearchesPerformed: 0,
            hallucinationChecksPerformed: 0,
            selfCorrectionLoops: 0,
            graphTraversals: 0,
            hybridSearches: 0,
            citationAccuracy: 0,
            terminationReason: "In progress",
            dmqr: {
                enabled: !!enable_dmqr,
                queryCount: dmqr_query_count,
                generatedQueries: [] as string[],
                success: false,
                contextItemsGenerated: 0,
                error: undefined as string | undefined
            },
            turnLog: [] as Array<{
                turn: number;
                query: string;
                strategy: string;
                newContextCount: number;
                decision: string;
                reasoning: string;
                type: 'initial' | 'iterative' | 'self-correction' | 'agentic-plan' | 'reflection';
                quality: number;
                citations: number;
            }>
        };

        const focusString = this._generateFocusString(focus_area, analysis_focus_points);
        console.log(`[Enhanced RAG] Starting enhanced search for query: "${query}"`);

        let baseQueries: string[] = [query];
        if (enable_dmqr) {
            console.log('[Enhanced RAG] DMQR enabled – generating diverse queries...');
            try {
                const dmqrResult = await this.diverseQueryRewriterService.rewriteAndRetrieve(query, { queryCount: dmqr_query_count });
                baseQueries = dmqrResult.generatedQueries;
                searchMetrics.dmqr.generatedQueries = baseQueries;
                searchMetrics.dmqr.success = true;
                console.log(`[Enhanced RAG] DMQR produced ${baseQueries.length} queries.`);

        // Pre-fetch context for all DMQR queries to warm up the cache
        if (baseQueries.length > 1) {
            console.log('[Enhanced RAG] Pre-fetching context for DMQR queries...');
            try {
                const dmqrContexts = await this._retrieveContextWithCache(agent_id, baseQueries, context_options || {});
                searchMetrics.dmqr.contextItemsGenerated = dmqrContexts.length;
                console.log(`[Enhanced RAG] DMQR context pre-fetching completed. Generated ${dmqrContexts.length} context items.`);
            } catch (error) {
                console.warn('[Enhanced RAG] DMQR context pre-fetching failed:', error);
                searchMetrics.dmqr.contextItemsGenerated = 0;
            }
        }
            } catch (e: any) {
                searchMetrics.dmqr.success = false;
                searchMetrics.dmqr.error = e.message ?? 'unknown';
                baseQueries = [query];
            }
        }

        let currentQueries = [...baseQueries];
        let turn = 0;
        let stabilityCounter = 0; // Counts consecutive turns with no new context

        while (turn < max_iterations) {
            turn++;
            searchMetrics.totalIterations = turn;

            const turnQuery = currentQueries.shift();
            if (!turnQuery) {
                searchMetrics.terminationReason = "Exhausted all queries.";
                break;
            }

            if (queryHistory.has(turnQuery)) {
                console.log(`[Enhanced RAG] Skipping duplicate query: "${turnQuery}"`);
                continue;
            }
            queryHistory.add(turnQuery);

            const isInitialTurn = baseQueries.includes(turnQuery);
            console.log(`[Enhanced RAG] Turn ${turn} – Query: "${turnQuery}" (${isInitialTurn ? 'initial' : 'iterative'})`);

            // Agentic Planning Phase
            if (enable_agentic_planning && turn > 1) {
                agenticPlan = await this._performAgenticPlanning(query, turnQuery, accumulatedContext, turn, model);
                console.log(`[Enhanced RAG] Agentic plan: ${agenticPlan.strategy}`);
            }

            const contextBefore = accumulatedContext.length;
            let rawContext: RetrievedCodeContext[] = [];

            // Execute search based on agentic plan or default to hybrid
            if (enable_hybrid_search && agenticPlan?.strategy === 'hybrid_search') {
                rawContext = await this._performHybridSearch(agent_id, turnQuery, context_options || {}, agenticPlan);
                searchMetrics.hybridSearches++;
            } else if (agenticPlan?.strategy === 'graph_traversal' && this.knowledgeGraphManager) {
                try {
                    const graphResult = await this.knowledgeGraphManager.queryNaturalLanguage(agent_id, turnQuery);
                    const graphData = JSON.parse(graphResult);
                    if (graphData.results && Array.isArray(graphData.results.nodes)) {
                        rawContext = graphData.results.nodes.map((node: any) => ({
                            type: 'knowledge_graph',
                            sourcePath: `kg://${node.name}`,
                            entityName: node.name,
                            content: JSON.stringify(node.observations),
                            relevanceScore: 0.85
                        }));
                    }
                    searchMetrics.graphTraversals++;
                } catch (error) {
                    console.warn('[Enhanced RAG] Graph traversal failed, falling back to vector search');
                    rawContext = await this._retrieveContextWithCache(agent_id, [turnQuery], context_options || {});
                }
            } else {
                rawContext = await this._retrieveContextWithCache(agent_id, [turnQuery], context_options || {});
            }

            accumulatedContext = deduplicateContexts([...accumulatedContext, ...rawContext]);
            const addedNow = accumulatedContext.length - contextBefore;
            searchMetrics.contextItemsAdded += addedNow;

            // Generate citations for new context
            rawContext.forEach(context => {
                const citation = this._generateCitation(
                    context,
                    context.content.substring(0, 200),
                    context.relevanceScore || 0.8
                );
                citations.push(citation);
            });

            // Corrective RAG: Self-correction logic with reflection
            if (addedNow === 0 && !isInitialTurn && enable_corrective_rag) {
                stabilityCounter++;
                if (stabilityCounter >= 2) {
                    searchMetrics.terminationReason = "Context stable, no new information found.";
                    console.log(`[Enhanced RAG] Context has been stable for ${stabilityCounter} turns. Terminating search.`);
                    break;
                }
            } else {
                stabilityCounter = 0;
            }

            // Create enhanced context flow with Long RAG support
            const contextFlow = this._createContextFlow(
                accumulatedContext, 
                turnQuery, 
                addedNow,
                enable_long_rag,
                long_rag_chunk_size
            );
            const formattedContext = formatContextForGemini(contextFlow)[0].text || '';
            const analysisPrompt = RAG_ANALYSIS_PROMPT
                .replace('{originalQuery}', query)
                .replace('{currentTurn}', String(turn))
                .replace('{maxIterations}', String(max_iterations))
                .replace('{accumulatedContext}', formattedContext)
                .replace('{focusString}', focusString);

            let analysisResult;
            try {
                analysisResult = await this.geminiService.askGemini(analysisPrompt, model, RAG_ANALYSIS_SYSTEM_INSTRUCTION, thinkingConfig);
            } catch (e: any) {
                searchMetrics.terminationReason = `Gemini analysis error: ${e.message}`;
                break;
            }

            const parsed = RagResponseParser.parseAnalysisResponse(analysisResult.content[0].text ?? '');
            if (!parsed) {
                searchMetrics.terminationReason = 'Parsing failure';
                break;
            }
            decisionLog.push(parsed);

            // Reflection Phase (periodic)
            if (enable_reflection && turn % reflection_frequency === 0) {
                const tempAnswer = analysisResult.content[0].text || '';
                const reflection = await this._performReflection(query, contextFlow, tempAnswer, model);
                reflectionResults.push(reflection);
                searchMetrics.hallucinationChecksPerformed++;

                if (reflection.missingInfo.length > 0 || reflection.hasHallucinations) {
                    const correctiveContext = await this._performCorrectiveSearch(
                        agent_id, query, accumulatedContext, reflection, context_options || {}, model
                    );

                    if (correctiveContext.length > 0) {
                        accumulatedContext = deduplicateContexts([...accumulatedContext, ...correctiveContext]);
                        searchMetrics.selfCorrectionLoops++;
                        
                        searchMetrics.turnLog.push({
                            turn,
                            query: turnQuery,
                            strategy: 'corrective_search',
                            newContextCount: correctiveContext.length,
                            decision: "CORRECTIVE_SEARCH",
                            reasoning: `Applied corrective search based on reflection: ${reflection.suggestions.join(', ')}`,
                            type: 'self-correction',
                            quality: reflection.qualityScore,
                            citations: correctiveContext.length
                        });
                    }
                }
            }

            const strategy = agenticPlan?.strategy || 'vector_search';
            const quality = reflectionResults.length > 0 ? 
                reflectionResults[reflectionResults.length - 1].qualityScore : 0.7;

            searchMetrics.turnLog.push({
                turn,
                query: turnQuery,
                strategy,
                newContextCount: addedNow,
                decision: parsed.decision,
                reasoning: parsed.reasoning,
                type: isInitialTurn ? 'initial' : 'iterative',
                quality,
                citations: addedNow
            });

            if (parsed.decision === 'ANSWER') {
                searchMetrics.terminationReason = "ANSWER decision reached.";
                console.log('[Enhanced RAG] Decision: ANSWER – generating final answer with citations.');
                
                const enhancedAnswerPrompt = RAG_ANSWER_PROMPT
                    .replace('{originalQuery}', query)
                    .replace('{contextString}', formattedContext)
                    .replace('{focusString}', focusString) +
                    `\n\nIMPORTANT: Include proper citations in your answer using the format [cite_N] where N is the citation number. Each claim should be supported by specific source references.`;
                
                const answerResult = await this.geminiService.askGemini(
                    enhancedAnswerPrompt, 
                    model, 
                    'You are a helpful AI assistant providing accurate answers with proper citations based on the given context.'
                );
                
                // Calculate citation accuracy
                const finalAnswer = answerResult.content[0].text ?? '';
                const citationMatches = finalAnswer.match(/\[cite_\d+\]/g) || [];
                searchMetrics.citationAccuracy = Math.min(citationMatches.length / citations.length, 1.0);
                
                return { 
                    accumulatedContext, 
                    webSearchSources, 
                    finalAnswer, 
                    decisionLog, 
                    citations,
                    reflectionResults,
                    agenticPlan,
                    searchMetrics 
                };
            } else if (parsed.decision === 'SEARCH_AGAIN' && parsed.nextCodebaseQuery) {
                currentQueries.push(parsed.nextCodebaseQuery);
            } else if (parsed.decision === 'SEARCH_WEB' && enable_web_search && parsed.nextWebQuery) {
                searchMetrics.webSearchesPerformed++;
                try {
                    const webResults = await callTavilyApi(parsed.nextWebQuery, { search_depth: tavily_search_depth, max_results: tavily_max_results, include_raw_content: tavily_include_raw_content });
                    webResults.forEach((r: WebSearchResult) => {
                        webSearchSources.push({ title: r.title, url: r.url });
                        accumulatedContext.push({ type: 'documentation', sourcePath: r.url, entityName: r.title, content: r.content, relevanceScore: 0.95 });
                        
                        const webCitation = this._generateCitation({
                            type: 'documentation',
                            sourcePath: r.url,
                            entityName: r.title,
                            content: r.content,
                            relevanceScore: 0.95
                        }, r.content.substring(0, 200), 0.9);
                        webCitation.sourceType = 'web';
                        webCitation.url = r.url;
                        citations.push(webCitation);
                    });
                } catch (e: any) {
                    console.error('[Enhanced RAG] Web search failed:', e);
                }
            }
        }

        if (searchMetrics.terminationReason === "In progress") {
            searchMetrics.terminationReason = "Max iterations reached.";
        }

        console.log('[Enhanced RAG] Generating final answer from accumulated context with citations.');
        
        const finalContextFlow = this._createContextFlow(
            accumulatedContext, 
            query, 
            0, 
            enable_long_rag, 
            long_rag_chunk_size
        );
        const fallbackContext = formatContextForGemini(finalContextFlow)[0].text || '';
        const fallbackPrompt = RAG_ANSWER_PROMPT
            .replace('{originalQuery}', query)
            .replace('{contextString}', fallbackContext)
            .replace('{focusString}', focusString) +
            `\n\nIMPORTANT: Include proper citations in your answer using the format [cite_N] where N is the citation number.`;
        
        const fallbackResult = await this.geminiService.askGemini(
            fallbackPrompt, 
            model, 
            'You are a helpful AI assistant providing accurate answers with citations based on the given context.'
        );

        const finalAnswer = fallbackResult.content[0].text ?? 'Unable to formulate an answer.';
        const citationMatches = finalAnswer.match(/\[cite_\d+\]/g) || [];
        searchMetrics.citationAccuracy = citations.length > 0 ? 
            Math.min(citationMatches.length / citations.length, 1.0) : 0;

        return { 
            accumulatedContext, 
            webSearchSources, 
            finalAnswer, 
            decisionLog, 
            citations,
            reflectionResults,
            agenticPlan,
            searchMetrics 
        };
        } catch (error: any) {
            globalPerformanceTracker.endOperation(operationId, false, error.message);
            throw error;
        }
    }

    /**
     * Get performance metrics summary for monitoring and optimization.
     */
    getPerformanceMetrics(): any {
        return globalPerformanceTracker.getSummary();
    }

    /**
     * Clear performance metrics (useful for testing or resetting metrics).
     */
    clearPerformanceMetrics(): void {
        globalPerformanceTracker.clear();
    }
}
