import { MemoryManager } from '../../database/memory_manager.js';
import { GeminiIntegrationService } from '../../database/services/GeminiIntegrationService.js';
import { RetrievedCodeContext } from '../../database/services/CodebaseContextRetrieverService.js';
import { ContextRetrievalOptions } from '../../database/services/CodebaseContextRetrieverService.js';
import {
    RAG_ANALYSIS_PROMPT,
    RAG_ANALYSIS_SYSTEM_INSTRUCTION,
    RAG_ANSWER_PROMPT,
    RAG_VERIFICATION_PROMPT,
    RAG_SELF_CORRECTION_PROMPT
} from '../../database/services/gemini-integration-modules/GeminiPromptTemplates.js';
import {
    AGENTIC_RAG_PLANNING_PROMPT,
    RAG_REFLECTION_PROMPT,
    CORRECTIVE_RAG_PROMPT,
    HYBRID_RAG_COORDINATION_PROMPT,
    LONG_RAG_CHUNKING_PROMPT,
    CITATION_ATTRIBUTION_PROMPT
} from './enhanced_rag_prompts.js';
import { RagAnalysisResponse } from './rag_response_parser.js';
import { RagResponseParser } from './rag_response_parser.js';
import { DiverseQueryRewriterService } from './diverse_query_rewriter_service.js';
import { callTavilyApi, WebSearchResult } from '../../integrations/tavily.js';
import {
    formatRetrievedContextForPrompt as formatContextForGemini
} from '../../database/services/gemini-integration-modules/GeminiContextFormatter.js';
import { GeminiApiNotInitializedError } from '../../database/services/gemini-integration-modules/GeminiApiClient.js';
import { McpError, ErrorCode } from '@modelcontextprotocol/sdk/types.js';
import { deduplicateContexts } from '../../utils/context_utils.js';
import { getCurrentModel } from '../../database/services/gemini-integration-modules/GeminiConfig.js';
import { globalPerformanceTracker } from '../../utils/performance_tracker.js';
import { KnowledgeGraphManager } from '../../database/managers/KnowledgeGraphManager.js';
import { MultiModelOrchestrator, RagTaskType } from './multi_model_orchestrator.js';
import { parseGeminiJsonResponse, parseGeminiJsonResponseSync } from '../../database/services/gemini-integration-modules/GeminiResponseParsers.js';

export interface Citation {
    id: string;
    source: string;
    sourceType: 'code' | 'documentation' | 'web' | 'knowledge_graph';
    title: string;
    url?: string;
    filePath?: string;
    lineNumbers?: [number, number];
    confidence: number;
    relevanceScore: number;
    extractedText: string;
    context?: string;
}

export interface ReflectionResult {
    hasHallucinations: boolean;
    missingInfo: string[];
    qualityScore: number;
    suggestions: string[];
    corrections: string[];
    confidence: number;
}

export interface AgenticRagPlan {
    strategy: 'vector_search' | 'graph_traversal' | 'hybrid_search' | 'web_augmented' | 'corrective_search';
    steps: Array<{
        action: string;
        target: string;
        priority: number;
        reasoning: string;
    }>;
    expectedOutcome: string;
    fallbackStrategy?: string;
}
    
    /**
     * Result returned by the orchestrator after the whole iterative search finishes.
     */
export interface IterativeRagResult {
    /** All unique context items collected across every turn. */
    accumulatedContext: RetrievedCodeContext[];
    /** Web results (if any) that were added to the context. */
    webSearchSources: { title: string; url: string }[];
    /**  Final answer generated by Gemini (if an ANSWER decision was reached). */
    finalAnswer?: string;
    /** Full log of every RAG‑analysis response (useful for debugging). */
    decisionLog: RagAnalysisResponse[];
    /** Source citations with detailed attribution */
    citations: Citation[];
    /** Reflection analysis results for quality control */
    reflectionResults: ReflectionResult[];
    /** Agentic planning results */
    agenticPlan?: AgenticRagPlan;
    /** Metrics that give insight into the search behaviour. */
    searchMetrics: {
        totalIterations: number;
        contextItemsAdded: number;
        webSearchesPerformed: number;
        hallucinationChecksPerformed: number;
        selfCorrectionLoops: number;
        terminationReason: string;
        graphTraversals: number;
        hybridSearches: number;
        citationAccuracy: number;
    citationCoverage: number;
    totalCitationsGenerated: number;
    totalCitationsUsed: number;
        dmqr: {
            enabled: boolean;
            queryCount?: number;
            generatedQueries?: string[];
            success: boolean;
            contextItemsGenerated: number;
            error?: string;
        };
        /** Timestamped record of each turn – handy for UI visualisation. */
        turnLog: Array<{
            turn: number;
            query: string;
            strategy: string;
            newContextCount: number;
            decision: string;
            reasoning: string;
            type: 'initial' | 'iterative' | 'self-correction' | 'agentic-plan' | 'reflection';
            quality: number;
            citations: number;
        }>;
    };
}


/**
 * Arguments accepted by the orchestrator.
 */
export interface IterativeRagArgs {
    agent_id: string;
    query: string;
    model?: string;
    systemInstruction?: string;

    context_options?: ContextRetrievalOptions;
    focus_area?: string;
    analysis_focus_points?: string[];
    enable_web_search?: boolean;
    google_search?: boolean;
    continue_session?: boolean;
    max_iterations?: number;
    hallucination_check_threshold?: number;
    tavily_search_depth?: 'basic' | 'advanced';
    tavily_max_results?: number;
    tavily_include_raw_content?: boolean;
    tavily_include_images?: boolean;
    tavily_include_image_descriptions?: boolean;
    tavily_time_period?: string;
    tavily_topic?: string;
    thinkingConfig?: { thinkingBudget?: number; thinkingMode?: 'AUTO' | 'MODE_THINK' };
    enable_dmqr?: boolean;
    dmqr_query_count?: number;
    enable_agentic_planning?: boolean;
    enable_reflection?: boolean;
    enable_hybrid_search?: boolean;
    enable_long_rag?: boolean;
    enable_corrective_rag?: boolean;
    citation_accuracy_threshold?: number;
    long_rag_chunk_size?: number;
    reflection_frequency?: number;
}

/**
 * The orchestrator that drives the multi‑turn, intelligent RAG loop.
 */
export class IterativeRagOrchestrator {
    private memoryManagerInstance: MemoryManager;
    private geminiService: GeminiIntegrationService;
    private diverseQueryRewriterService: DiverseQueryRewriterService;
    private knowledgeGraphManager?: KnowledgeGraphManager;
    private multiModelOrchestrator: MultiModelOrchestrator;

    // Performance optimization: Session-level context cache
    private sessionContextCache: Map<string, {
        context: RetrievedCodeContext[];
        timestamp: number;
        query: string;
        options: ContextRetrievalOptions;
    }>;
    private readonly CACHE_TTL = 10 * 60 * 1000; // 10 minutes for session cache
    private readonly MAX_SESSION_CACHE_SIZE = 50;
    private citationIdCounter = 0;
    
    // Enhanced search cache for hybrid results
    private hybridSearchCache: Map<string, {
        results: RetrievedCodeContext[];
        timestamp: number;
        searchStrategy: string;
    }>;
    private readonly HYBRID_CACHE_TTL = 15 * 60 * 1000; // 15 minutes

    constructor(
        memoryManagerInstance: MemoryManager,
        geminiService: GeminiIntegrationService,
        diverseQueryRewriterService: DiverseQueryRewriterService,
        knowledgeGraphManager?: KnowledgeGraphManager
    ) {
        this.memoryManagerInstance = memoryManagerInstance;
        this.geminiService = geminiService;
        this.diverseQueryRewriterService = diverseQueryRewriterService;
        this.knowledgeGraphManager = knowledgeGraphManager;
        this.multiModelOrchestrator = new MultiModelOrchestrator(memoryManagerInstance, geminiService);
        this.sessionContextCache = new Map();
        this.hybridSearchCache = new Map();
    }

    /**
     * Generate cache key for session context cache.
     */
    private _generateSessionCacheKey(query: string, options: ContextRetrievalOptions): string {
        const optionsStr = JSON.stringify({
            topKEmbeddings: options.topKEmbeddings,
            kgQueryDepth: options.kgQueryDepth,
            topKKgResults: options.topKKgResults,
            targetFilePaths: options.targetFilePaths?.sort(),
            embeddingScoreThreshold: options.embeddingScoreThreshold,
            useHybridSearch: options.useHybridSearch,
            enableReranking: options.enableReranking
        });
        return `${query}:${optionsStr}`;
    }

    /**
     * Check if cached context is still valid.
     */
    private _isSessionCacheValid(timestamp: number): boolean {
        return (Date.now() - timestamp) < this.CACHE_TTL;
    }

    /**
     * Retrieve context using the query_codebase_embeddings tool directly.
     * This bypasses the CodebaseContextRetrieverService and uses the proven embedding tool.
     */
    private async _retrieveContextViaEmbeddingTool(
        agentId: string,
        query: string,
        options: ContextRetrievalOptions
    ): Promise<RetrievedCodeContext[]> {
        console.log(`[Iterative RAG] Using direct embedding tool for query: "${query}"`);

        try {
            // Import embedding tools to get the handler
            const { getEmbeddingToolHandlers } = await import('../embedding_tools.js');
            const embeddingHandlers = getEmbeddingToolHandlers(this.memoryManagerInstance);

            // Prepare arguments for query_codebase_embeddings
            const queryArgs = {
                agent_id: agentId,
                query_text: query,
                top_k: options.topKEmbeddings || 8,
                target_file_paths: options.targetFilePaths,
                exclude_chunk_types: ['summary'], // Prioritize actual code chunks
                enable_dmqr: false, // We'll handle query diversity at the orchestrator level
                dmqr_query_count: 3
            };

            // Call the embedding tool directly
            const result = await embeddingHandlers['query_codebase_embeddings'](queryArgs, agentId);

            // Parse the markdown result to extract code chunks
            // The result is markdown formatted, so we need to extract the actual data
            console.log(`[Iterative RAG] Raw embedding tool result type:`, typeof result);

            // The embedding tool returns structured data, let's access it directly
            const embeddingService = this.memoryManagerInstance.getCodebaseEmbeddingService();
            const codeChunks = await embeddingService.retrieveSimilarCodeChunks(
                agentId,
                query,
                options.topKEmbeddings || 8,
                options.targetFilePaths,
                ['summary'] // Exclude summaries to get actual code
            );

            // Convert to RetrievedCodeContext format
            const contexts: RetrievedCodeContext[] = codeChunks.map((chunk, index) => ({
                type: 'generic_code_chunk',
                sourcePath: chunk.file_path_relative,
                entityName: chunk.entity_name || undefined,
                content: chunk.chunk_text,
                relevanceScore: chunk.score,
                metadata: {
                    ...chunk.metadata,
                    searchType: 'direct_embedding',
                    rank: index + 1,
                    hasActualCode: true
                }
            }));

            console.log(`[Iterative RAG] Retrieved ${contexts.length} code chunks via embedding tool`);

            // Log sample of what was retrieved
            if (contexts.length > 0) {
                const sample = contexts[0];
                console.log(`[Iterative RAG] Sample chunk: ${sample.entityName} from ${sample.sourcePath} (${sample.content.substring(0, 100)}...)`);
            }

            return contexts;

        } catch (error) {
            console.error('[Iterative RAG] Error using embedding tool, falling back to context retriever:', error);

            // Fallback to original context retriever
            const contextRetriever = this.memoryManagerInstance.getCodebaseContextRetrieverService();
            return await contextRetriever.retrieveContextForPrompt(agentId, query, options);
        }
    }

    private _generateCitation(
        context: RetrievedCodeContext,
        extractedText: string,
        confidence: number = 0.8
    ): Citation {
        return {
            id: `cite_${++this.citationIdCounter}`,
            source: context.sourcePath,
            sourceType: context.type as Citation['sourceType'],
            title: context.entityName || context.sourcePath,
            filePath: context.sourcePath,
            lineNumbers: context.metadata?.startLine && context.metadata?.endLine ? [context.metadata.startLine, context.metadata.endLine] : undefined,
            confidence,
            relevanceScore: context.relevanceScore || 0.7,
            extractedText: extractedText.substring(0, 200),
            context: context.content.substring(0, 500)
        };
    }

    private async _performAgenticPlanning(
        originalQuery: string,
        currentQuery: string,
        currentContext: RetrievedCodeContext[],
        iteration: number,
        model?: string
    ): Promise<AgenticRagPlan> {
        const contextSummary = currentContext.slice(-3).map(c => 
            `- ${c.type}: ${c.entityName || 'Unknown'} (${c.sourcePath})`
        ).join('\n');
        
        const previousStrategy = iteration > 1 ? 'vector_search' : 'initial';
        const contextQuality = currentContext.length > 0 ? 0.7 : 0.3;
        const informationGaps = currentContext.length < 3 ? ['implementation details', 'usage examples'] : ['edge cases'];
        
        const planningPrompt = AGENTIC_RAG_PLANNING_PROMPT
            .replace('{originalQuery}', originalQuery)
            .replace('{currentQuery}', currentQuery)
            .replace('{currentIteration}', iteration.toString())
            .replace('{previousStrategy}', previousStrategy)
            .replace('{contextQuality}', contextQuality.toString())
            .replace('{informationGaps}', informationGaps.join(', '))
            .replace('{contextSummary}', contextSummary);

        const result = await this.multiModelOrchestrator.executeTask(
            'planning',
            planningPrompt,
            undefined,
            { contextLength: planningPrompt.length }
        );
        try {
            const parsed = await parseGeminiJsonResponse(result.content?.trim() || '{}', {
                expectedStructure: 'Agentic planning response with strategy and execution plan',
                contextDescription: 'RAG agentic planning analysis',
                memoryManager: this.memoryManagerInstance,
                geminiService: this.geminiService,
                enableAIRepair: true
            });
            return {
                strategy: parsed.recommended_strategy?.primary_modality || 'vector_search',
                steps: parsed.execution_plan?.immediate_actions?.map((action: string, idx: number) => ({
                    action,
                    target: currentQuery,
                    priority: idx + 1,
                    reasoning: `Step ${idx + 1} of agentic plan`
                })) || [{ action: 'search', target: currentQuery, priority: 1, reasoning: 'default action' }],
                expectedOutcome: parsed.execution_plan?.query_formulation || 'relevant context',
                fallbackStrategy: parsed.contingency_planning?.fallback_strategy || 'hybrid_search'
            };
        } catch (error) {
            console.warn('[Agentic Planning] Enhanced parsing failed, using fallback:', error);
            return {
                strategy: 'vector_search',
                steps: [{ action: 'search', target: currentQuery, priority: 3, reasoning: 'fallback plan' }],
                expectedOutcome: 'relevant context',
                fallbackStrategy: 'hybrid_search'
            };
        }
    }

    private async _performReflection(
        originalQuery: string,
        context: RetrievedCodeContext[],
        currentAnswer: string,
        model?: string
    ): Promise<ReflectionResult> {
        const sourceContext = context.map(c => 
            `Source: ${c.sourcePath} | Entity: ${c.entityName || 'Unknown'} | Type: ${c.type}`
        ).join('\n');
        const searchStrategy = 'hybrid_search'; // This would come from the current strategy
        const iterationCount = 1; // This would be passed in
        
        const reflectionPrompt = RAG_REFLECTION_PROMPT
            .replace('{originalQuery}', originalQuery)
            .replace('{generatedResponse}', currentAnswer)
            .replace('{sourceContext}', sourceContext)
            .replace('{searchStrategy}', searchStrategy)
            .replace('{iterationCount}', iterationCount.toString());

        const result = await this.multiModelOrchestrator.executeTask(
            'reflection',
            reflectionPrompt,
            undefined,
            { contextLength: reflectionPrompt.length }
        );
        try {
            const parsed = await parseGeminiJsonResponse(result.content?.trim() || '{}', {
                expectedStructure: 'Reflection analysis with hallucination detection and quality assessment',
                contextDescription: 'RAG reflection and quality control analysis',
                memoryManager: this.memoryManagerInstance,
                geminiService: this.geminiService,
                enableAIRepair: true
            });
            return {
                hasHallucinations: parsed.hallucination_analysis?.detected_hallucinations?.length > 0 || false,
                missingInfo: parsed.completeness_analysis?.missing_aspects || [],
                qualityScore: parsed.overall_assessment?.quality_score || 0.5,
                suggestions: parsed.improvement_recommendations?.enhancement_suggestions || [],
                corrections: parsed.improvement_recommendations?.immediate_fixes || [],
                confidence: parsed.overall_assessment?.overall_confidence || 0.5
            };
        } catch (error) {
            console.warn('[Reflection] Enhanced parsing failed, using fallback:', error);
            return {
                hasHallucinations: false,
                missingInfo: [],
                qualityScore: 0.5,
                suggestions: [],
                corrections: [],
                confidence: 0.5
            };
        }
    }

    private async _performHybridSearch(
        agentId: string,
        query: string,
        options: ContextRetrievalOptions,
        plan?: AgenticRagPlan
    ): Promise<RetrievedCodeContext[]> {
        const results: RetrievedCodeContext[] = [];
        const hybridOptions = { ...options, useHybridSearch: true };

        // Enhanced Hybrid Search with Task Types
        console.log(`[Enhanced Hybrid Search] Starting hybrid search with Gemini task types for query: "${query}"`);

        // 1. Vector Search - simplified without task type
        const vectorSearchPromise = this._retrieveContextWithCache(agentId, [query], hybridOptions);

        // 2. Keyword-based Search - simplified without task type
        const keywordSearchPromise = this._performEnhancedKeywordSearch(agentId, query, hybridOptions);

        // 3. Knowledge Graph Search (if available)
        const kgSearchPromise = this.knowledgeGraphManager && plan?.strategy === 'hybrid_search'
            ? this._performKnowledgeGraphSearch(agentId, query, hybridOptions)
            : Promise.resolve([]);

        // Execute searches in parallel with Gemini batch processing
        try {
            const [vectorResults, keywordResults, kgResults] = await Promise.allSettled([
                vectorSearchPromise,
                keywordSearchPromise, 
                kgSearchPromise
            ]);

            // Process vector results
            if (vectorResults.status === 'fulfilled') {
                results.push(...vectorResults.value);
                console.log(`[Hybrid Search] Vector search yielded ${vectorResults.value.length} results`);
            } else {
                console.warn('[Hybrid Search] Vector search failed:', vectorResults.reason);
            }

            // Process keyword results
            if (keywordResults.status === 'fulfilled') {
                results.push(...keywordResults.value);
                console.log(`[Hybrid Search] Keyword search yielded ${keywordResults.value.length} results`);
            } else {
                console.warn('[Hybrid Search] Keyword search failed:', keywordResults.reason);
            }

            // Process KG results
            if (kgResults.status === 'fulfilled') {
                results.push(...kgResults.value);
                console.log(`[Hybrid Search] KG search yielded ${kgResults.value.length} results`);
            } else if (kgResults.status === 'rejected') {
                console.warn('[Hybrid Search] KG search failed:', kgResults.reason);
            }

            // Apply hybrid ranking using Reciprocal Rank Fusion
            const rankedResults = this._applyHybridRanking([
                vectorResults.status === 'fulfilled' ? vectorResults.value : [],
                keywordResults.status === 'fulfilled' ? keywordResults.value : [],
                kgResults.status === 'fulfilled' ? kgResults.value : []
            ]);

            console.log(`[Enhanced Hybrid Search] Combined and ranked ${rankedResults.length} results`);
            return deduplicateContexts(rankedResults);

        } catch (error) {
            console.error('[Hybrid Search] Error during parallel search execution:', error);
            // Fallback to sequential execution
            return await this._fallbackSequentialSearch(agentId, query, hybridOptions, plan);
        }
    }

    private async _performCorrectiveSearch(
        agentId: string,
        originalQuery: string,
        previousContext: RetrievedCodeContext[],
        reflectionResult: ReflectionResult,
        options: ContextRetrievalOptions,
        model?: string
    ): Promise<RetrievedCodeContext[]> {
        if (!reflectionResult.hasHallucinations && reflectionResult.missingInfo.length === 0) {
            return [];
        }

        const currentContext = previousContext.slice(-3).map(c => 
            `${c.sourcePath}: ${c.entityName || 'Unknown'}`
        ).join(', ');
        
        const correctionPrompt = CORRECTIVE_RAG_PROMPT
            .replace('{currentQuery}', originalQuery)
            .replace('{reflectionResults}', JSON.stringify(reflectionResult))
            .replace('{currentContext}', currentContext)
            .replace('{hasHallucinations}', reflectionResult.hasHallucinations.toString())
            .replace('{missingInfo}', reflectionResult.missingInfo.join(', '))
            .replace('{qualityScore}', reflectionResult.qualityScore.toString());
        
        try {
            const result = await this.multiModelOrchestrator.executeTask(
                'simple_analysis',
                correctionPrompt,
                undefined,
                { contextLength: correctionPrompt.length }
            );
            const parsed = JSON.parse(result.content?.trim() || '{}');
            const firstImprovedQuery = parsed.improved_queries?.[0];

            let correctedQueries: string[];
            let targetFilePaths: string[] | undefined;
            let targetEntityNames: string[] | undefined;

            if (firstImprovedQuery && firstImprovedQuery.query) {
                correctedQueries = [firstImprovedQuery.query];
                targetFilePaths = firstImprovedQuery.target_file_paths;
                targetEntityNames = firstImprovedQuery.target_entity_names;
            } else {
                // Fallback logic if parsing fails or improved_queries is not as expected
                console.warn('[Corrective Search] No improved_queries found or parsed incorrectly. Using fallback query.');
                correctedQueries = [`${originalQuery} focusing on: ${reflectionResult.corrections.join(', ')} ${reflectionResult.missingInfo.join(', ')}`.trim()];
            }

            const updatedOptions: ContextRetrievalOptions = {
                ...options,
                targetFilePaths: targetFilePaths || options.targetFilePaths,
                targetEntityNames: targetEntityNames || options.targetEntityNames
            };
            
            return await this._retrieveContextWithCache(agentId, correctedQueries, updatedOptions);
        } catch (error) {
            console.warn('[Corrective Search] Failed to use enhanced prompt or parse response, using fallback:', error);
            const fallbackQuery = `${originalQuery} focusing on: ${reflectionResult.corrections.join(', ')} ${reflectionResult.missingInfo.join(', ')}`.trim();
            
            // For fallback, we don't have explicit target_file_paths or entity_names from Gemini,
            // so we stick with the original options
            return await this._retrieveContextWithCache(agentId, [fallbackQuery], options);
        }
    }

        private async _performEnhancedKeywordSearch(
        agentId: string,
        query: string,
        options: ContextRetrievalOptions
    ): Promise<RetrievedCodeContext[]> {
        try {
            console.log(`[Enhanced Keyword Search] Performing keyword-based search for: "${query}"`);
            
            // Extract keywords using Gemini with CODE_RETRIEVAL_QUERY task type
            const keywordExtractionPrompt = `Extract the most important technical keywords, function names, class names, and file patterns from this query for code search. Focus on identifiers that would appear in code.

Query: "${query}"

Return a JSON object with "keywords" array containing the extracted terms.
Example: {"keywords": ["getUserData", "UserService", "authentication", "api"]}`;

            const keywordResult = await this.multiModelOrchestrator.executeTask(
                'json_extraction',
                keywordExtractionPrompt,
                undefined,
                { contextLength: keywordExtractionPrompt.length }
            );

            let keywords: string[] = [];
            try {
                const parsed = JSON.parse(keywordResult.content || '{}');
                keywords = parsed.keywords || [];
            } catch {
                // Fallback keyword extraction
                keywords = query.split(/\s+/)
                    .filter(word => word.length > 2)
                    .filter(word => /[a-zA-Z_$][\w$]*/.test(word)); // Identifier-like words
            }

            if (keywords.length === 0) {
                console.log('[Enhanced Keyword Search] No keywords extracted, falling back to vector search');
                return [];
            }

            console.log(`[Enhanced Keyword Search] Using keywords: ${keywords.join(', ')}`);

            // Perform parallel keyword searches
            const keywordPromises = keywords.slice(0, 10).map(async (keyword) => {
                try {
                    // Search in multiple sources
                    const [embeddingResults, kgResults] = await Promise.allSettled([
                        // Vector search
                        this._retrieveContextWithCache(agentId, [`"${keyword}"`], options),
                        // Knowledge graph search if available
                        this.knowledgeGraphManager ? 
                            this.knowledgeGraphManager.searchNodes(agentId, keyword).catch(() => []) :
                            Promise.resolve([])
                    ]);

                    const results: RetrievedCodeContext[] = [];

                    // Process embedding results
                    if (embeddingResults.status === 'fulfilled') {
                        results.push(...embeddingResults.value);
                    }

                    // Process KG results
                    if (kgResults.status === 'fulfilled' && this.knowledgeGraphManager) {
                        const kgNodes = kgResults.value;
                        if (Array.isArray(kgNodes) && kgNodes.length > 0) {
                            const kgContexts = kgNodes.map(node => ({
                                type: 'kg_node_info' as const,
                                sourcePath: `kg://${node.name}`,
                                entityName: node.name,
                                content: JSON.stringify(node.observations || []),
                                relevanceScore: 0.7, // Default relevance for KG results
                                metadata: { nodeType: node.entityType }
                            }));
                            results.push(...kgContexts);
                        }
                    }

                    return results;
                } catch (error) {
                    console.warn(`[Enhanced Keyword Search] Failed to search for keyword "${keyword}":`, error);
                    return [];
                }
            });

            const allResults = await Promise.all(keywordPromises);
            const flattenedResults = allResults.flat();

            // Deduplicate and rank results
            const uniqueResults = deduplicateContexts(flattenedResults);
            uniqueResults.sort((a, b) => (b.relevanceScore || 0) - (a.relevanceScore || 0));

            console.log(`[Enhanced Keyword Search] Found ${uniqueResults.length} results for ${keywords.length} keywords`);
            return uniqueResults.slice(0, options.topKEmbeddings || 20);

        } catch (error) {
            console.error('[Enhanced Keyword Search] Error during keyword search:', error);
            return [];
        }
    }

    private async _performKnowledgeGraphSearch(
        agentId: string,
        query: string,
        options: ContextRetrievalOptions
    ): Promise<RetrievedCodeContext[]> {
        if (!this.knowledgeGraphManager) {
            return [];
        }

        try {
            console.log(`[KG Search] Performing knowledge graph search for: "${query}"`);
            const graphQuery = await this.knowledgeGraphManager.queryNaturalLanguage(agentId, query);
            const graphData = JSON.parse(graphQuery);
            
            if (graphData.results && Array.isArray(graphData.results.nodes)) {
                const kgResults = graphData.results.nodes.map((node: any) => ({
                    type: 'kg_node_info' as const,
                    sourcePath: `kg://${node.name}`,
                    entityName: node.name,
                    content: JSON.stringify(node.observations),
                    relevanceScore: 0.85,
                    metadata: { 
                        nodeType: node.entityType,
                        searchType: 'knowledge_graph'
                    }
                }));
                
                console.log(`[KG Search] Found ${kgResults.length} knowledge graph results`);
                return kgResults;
            }
        } catch (error) {
            console.warn('[KG Search] Knowledge graph query failed:', error);
        }

        return [];
    }

    private _applyHybridRanking(searchResults: RetrievedCodeContext[][]): RetrievedCodeContext[] {
        // Use Reciprocal Rank Fusion with different weights for different search types
        const weights = {
            vector: 1.0,
            keyword: 0.8,
            knowledge_graph: 0.9
        };

        const scores: Map<string, { score: number; context: RetrievedCodeContext }> = new Map();
        const k = 60; // RRF constant

        searchResults.forEach((results, searchTypeIndex) => {
            const searchTypes = ['vector', 'keyword', 'kg_node_info'];
            const currentWeight = weights[searchTypes[searchTypeIndex] as keyof typeof weights] || 1.0;

            results.forEach((context, rank) => {
                const key = `${context.sourcePath}:${context.entityName || 'default'}:${context.content.substring(0, 100)}`;
                const rrfScore = currentWeight * (1 / (k + rank + 1));
                
                if (scores.has(key)) {
                    const existing = scores.get(key)!;
                    existing.score += rrfScore;
                } else {
                    scores.set(key, {
                        score: rrfScore,
                        context: {
                            ...context,
                            relevanceScore: rrfScore
                        }
                    });
                }
            });
        });

        // Sort by combined score
        return Array.from(scores.values())
            .sort((a, b) => b.score - a.score)
            .map(item => item.context);
    }

    private async _fallbackSequentialSearch(
        agentId: string,
        query: string,
        options: ContextRetrievalOptions,
        plan?: AgenticRagPlan
    ): Promise<RetrievedCodeContext[]> {
        console.log('[Hybrid Search] Executing fallback sequential search');
        const results: RetrievedCodeContext[] = [];

        try {
            // Sequential vector search
            const vectorResults = await this._retrieveContextWithCache(agentId, [query], options);
            results.push(...vectorResults);

            // Sequential keyword search
            const keywordResults = await this._performEnhancedKeywordSearch(agentId, query, options);
            results.push(...keywordResults);

            return deduplicateContexts(results);
        } catch (error) {
            console.error('[Hybrid Search] Fallback search also failed:', error);
            return [];
        }
    }

    private _processLongContexts(contexts: RetrievedCodeContext[], maxChunkSize: number = 2000): RetrievedCodeContext[] {
        return contexts.flatMap(context => {
            if (context.content.length <= maxChunkSize) {
                return [context];
            }

            const chunks: RetrievedCodeContext[] = [];
            const content = context.content;
            let startIndex = 0;

            while (startIndex < content.length) {
                let endIndex = startIndex + maxChunkSize;
                
                // Try to break at natural boundaries (sentences, paragraphs)
                if (endIndex < content.length) {
                    const lastPeriod = content.lastIndexOf('.', endIndex);
                    const lastNewline = content.lastIndexOf('\n', endIndex);
                    const breakPoint = Math.max(lastPeriod, lastNewline);
                    
                    if (breakPoint > startIndex + maxChunkSize * 0.5) {
                        endIndex = breakPoint + 1;
                    }
                }

                const chunkContent = content.slice(startIndex, endIndex);
                chunks.push({
                    ...context,
                    content: chunkContent,
                    entityName: `${context.entityName || 'chunk'}_${chunks.length + 1}`,
                    metadata: {
                        ...context.metadata,
                        isChunk: true,
                        chunkIndex: chunks.length,
                        originalLength: content.length
                    }
                });

                startIndex = endIndex;
            }

            return chunks;
        });
    }

    /**
     * Clean up expired session cache entries.
     */
    private _cleanupSessionCache(): void {
        if (this.sessionContextCache.size > this.MAX_SESSION_CACHE_SIZE) {
            const entries = Array.from(this.sessionContextCache.entries());
            entries.sort((a, b) => a[1].timestamp - b[1].timestamp);
            const toRemove = entries.slice(0, Math.floor(this.MAX_SESSION_CACHE_SIZE * 0.3));
            toRemove.forEach(([key]) => this.sessionContextCache.delete(key));
            console.log(`[IterativeRagOrchestrator] Cleaned up ${toRemove.length} expired session cache entries`);
        }
    }

    /**
     * Retrieve context with session-level caching and parallel processing.
     */
    private async _retrieveContextWithCache(
        agentId: string,
        queries: string[],
        options: ContextRetrievalOptions
    ): Promise<RetrievedCodeContext[]> {
        const operationId = globalPerformanceTracker.startOperation('retrieveContextWithCache', {
            queryCount: queries.length,
            agentId
        });

        try {
            const contextRetriever = this.memoryManagerInstance.getCodebaseContextRetrieverService();
            const allContexts: RetrievedCodeContext[] = [];
            const uncachedQueries: string[] = [];
            const cachedContexts: RetrievedCodeContext[] = [];

        // Check cache for each query
        for (const query of queries) {
            const cacheKey = this._generateSessionCacheKey(query, options);
            const cached = this.sessionContextCache.get(cacheKey);

            if (cached && this._isSessionCacheValid(cached.timestamp)) {
                console.log(`[Session Cache HIT] Using cached context for query: "${query.substring(0, 50)}..."`);
                cachedContexts.push(...cached.context);
            } else {
                uncachedQueries.push(query);
            }
        }

        // Parallel retrieval for uncached queries
        if (uncachedQueries.length > 0) {
            console.log(`[Parallel Retrieval] Processing ${uncachedQueries.length} uncached queries`);

            const retrievalPromises = uncachedQueries.map(async (query) => {
                try {
                    const context = await this._retrieveContextViaEmbeddingTool(agentId, query, options);
                    // Cache the result
                    const cacheKey = this._generateSessionCacheKey(query, options);
                    this.sessionContextCache.set(cacheKey, {
                        context,
                        timestamp: Date.now(),
                        query,
                        options
                    });
                    return context;
                } catch (error) {
                    console.error(`[Parallel Retrieval] Failed to retrieve context for query "${query}":`, error);
                    return [];
                }
            });

            try {
                const retrievedContexts = await Promise.allSettled(retrievalPromises);
                retrievedContexts.forEach((result) => {
                    if (result.status === 'fulfilled') {
                        allContexts.push(...result.value);
                    }
                });
            } catch (error) {
                console.error('[Parallel Retrieval] Error in parallel context retrieval:', error);
            }

            this._cleanupSessionCache();
        }

        // Combine cached and newly retrieved contexts
        allContexts.push(...cachedContexts);

        globalPerformanceTracker.endOperation(operationId, true);
        return allContexts;
        } catch (error: any) {
            globalPerformanceTracker.endOperation(operationId, false, error.message);
            throw error;
        }
    }

    /**
     * Build the optional "focus" block that is injected into the RAG prompts.
     */
    private _generateFocusString(focusArea?: string, analysisFocusPoints?: string[]): string {
        let focusString = '';
        if (focusArea) {
            if (analysisFocusPoints && analysisFocusPoints.length) {
                focusString =
                    'Focus on the following aspects for your analysis and response:\n' +
                    analysisFocusPoints.map((p, i) => `${i + 1}. **${p}**`).join('\n');
            } else {
                switch (focusArea) {
                    case 'code_review':
                        focusString =
                            'Focus on all aspects including:\n' +
                            '1. **Potential Bugs & Errors**\n' +
                            '2. **Best Practices & Conventions**\n' +
                            '3. **Performance**\n' +
                            '4. **Security Vulnerabilities**\n' +
                            '5. **Readability & Maintainability**';
                        break;
                    case 'code_explanation':
                        focusString = 'Explain the code clearly and concisely.';
                        break;
                    case 'enhancement_suggestions':
                        focusString = 'Suggest improvements and enhancements.';
                        break;
                    case 'bug_fixing':
                        focusString = 'Identify and suggest fixes for bugs.';
                        break;
                    case 'refactoring':
                        focusString = 'Suggest refactoring opportunities.';
                        break;
                    case 'testing':
                        focusString = 'Provide testing strategies and test case generation.';
                        break;
                    case 'documentation':
                        focusString = 'Generate or improve documentation.';
                        break;
                    case 'code_modularization_orchestration':
                        focusString = 'Discuss modularity, architecture, and orchestration patterns.';
                        break;
                    default:
                        focusString = '';
                }
            }
            if (focusString) {
                focusString = `--- Focus Area ---
${focusString}

`;
            }
        }
        return focusString;
    }

    /**
     * Create an enhanced context flow that prioritizes recent and relevant information with Long RAG support.
     * This addresses the "context rot" problem by organizing context logically.
     */
    private _createContextFlow(
        accumulatedContext: RetrievedCodeContext[],
        currentQuery: string,
        recentItemsCount: number,
        enableLongRag: boolean = false,
        longRagChunkSize: number = 2000
    ): RetrievedCodeContext[] {
        if (accumulatedContext.length === 0) return [];

        let processedContexts = accumulatedContext;

        // Apply Long RAG processing if enabled
        if (enableLongRag) {
            processedContexts = this._processLongContexts(processedContexts, longRagChunkSize);
        }

        // Separate recent context from older context
        const recentContext = processedContexts.slice(-recentItemsCount);
        const olderContext = processedContexts.slice(0, -recentItemsCount);

        // Sort contexts by relevance and type priority
        const sortByPriority = (contexts: RetrievedCodeContext[]): RetrievedCodeContext[] => {
            const typePriority = {
                'function': 5,
                'method': 4,
                'class': 3,
                'file': 2,
                'documentation': 1,
                'kg_node_info': 6
            };

            return contexts.sort((a, b) => {
                // Higher relevance score gets priority
                const aScore = a.relevanceScore || 0;
                const bScore = b.relevanceScore || 0;

                if (Math.abs(bScore - aScore) > 0.1) {
                    return bScore - aScore;
                }

                // Then by type priority
                const aPriority = typePriority[a.type as keyof typeof typePriority] || 0;
                const bPriority = typePriority[b.type as keyof typeof typePriority] || 0;

                return bPriority - aPriority;
            });
        };

        // Process recent context (highest priority)
        const prioritizedRecent = sortByPriority(recentContext);

        // Process older context with lower priority and potential summarization
        let processedOlder = olderContext;
        if (olderContext.length > 10) {
            // Keep only high-relevance older items
            processedOlder = olderContext.filter(ctx => (ctx.relevanceScore || 0) >= 0.8);
            if (processedOlder.length > 5) {
                processedOlder = processedOlder.slice(0, 5); // Limit older context
            }
        }

        // Combine with recent context first, then older context
        const contextFlow = [
            ...prioritizedRecent,
            ...processedOlder
        ];

        // Final deduplication
        const uniqueContexts = Array.from(
            new Map(contextFlow.map(item => [`${item.sourcePath}#${item.entityName}`, item])).values()
        );

        return uniqueContexts;
    }


    /**
     * Process contexts in batches of three using Gemini task types
     */
    private async _processBatchContextAnalysis(
        contexts: RetrievedCodeContext[],
        originalQuery: string,
        model?: string
    ): Promise<{ analyzedContexts: RetrievedCodeContext[]; batchAnalysis: string[] }> {
        const batchSize = 3;
        const batches: RetrievedCodeContext[][] = [];
        const batchAnalysis: string[] = [];

        // Split contexts into batches of 3
        for (let i = 0; i < contexts.length; i += batchSize) {
            batches.push(contexts.slice(i, i + batchSize));
        }

        console.log(`[Batch Processing] Processing ${contexts.length} contexts in ${batches.length} batches of ${batchSize}`);

        const processedBatches = await Promise.allSettled(
            batches.map(async (batch, batchIndex) => {
                const batchAnalysisPrompt = `Analyze the following ${batch.length} code contexts for relevance to the query "${originalQuery}". \nFor each context, provide:\n1. Relevance score (0.0-1.0)\n2. Key insights\n3. How it relates to the query\n\nContexts:\n${batch.map((ctx, idx) => `Context ${idx + 1}:\nFile: ${ctx.sourcePath}\nEntity: ${ctx.entityName || 'N/A'}\nContent: ${ctx.content.substring(0, 300)}...\n`).join('\n')}\n\nReturn JSON: {"analyses": [{"contextIndex": 0, "relevanceScore": 0.0, "insights": "", "relationship": ""}, ...]}`;

                try {
                    const result = await this.multiModelOrchestrator.executeTask(
                        'simple_analysis',
                        batchAnalysisPrompt,
                        undefined,
                        { contextLength: batchAnalysisPrompt.length }
                    );

                    const analysisText = result.content || '{"analyses": []}';
                    batchAnalysis.push(`Batch ${batchIndex + 1}: ${analysisText}`);

                    // Parse analysis and update context relevance scores
                    let analyses: any[] = [];
                    try {
                        const parsed = JSON.parse(analysisText);
                        analyses = parsed.analyses || [];
                    } catch {
                        console.warn(`[Batch Processing] Failed to parse batch ${batchIndex + 1} analysis`);
                    }

                    // Update contexts with analysis results
                    return batch.map((context, idx) => {
                        const analysis = analyses.find(a => a.contextIndex === idx);
                        if (analysis) {
                            return {
                                ...context,
                                relevanceScore: Math.max(context.relevanceScore || 0.5, analysis.relevanceScore || 0.5),
                                metadata: {
                                    ...context.metadata,
                                    batchAnalysis: {
                                        insights: analysis.insights,
                                        relationship: analysis.relationship,
                                        batchIndex: batchIndex + 1
                                    }
                                }
                            };
                        }
                        return context;
                    });
                } catch (error) {
                    console.error(`[Batch Processing] Error processing batch ${batchIndex + 1}:`, error);
                    return batch; // Return original batch on error
                }
            })
        );

        // Combine all processed batches
        const analyzedContexts: RetrievedCodeContext[] = [];
        processedBatches.forEach((result) => {
            if (result.status === 'fulfilled') {
                analyzedContexts.push(...result.value);
            }
        });

        console.log(`[Batch Processing] Successfully analyzed ${analyzedContexts.length} contexts`);
        return { analyzedContexts, batchAnalysis };
    }

    /**
     * Consolidated batch analysis - process ALL context in one API call for free tier efficiency
     */
    private async _processConsolidatedBatchContextAnalysis(
        contexts: RetrievedCodeContext[],
        query: string,
        model?: string,
        turn?: number
    ): Promise<{ analyzedContexts: RetrievedCodeContext[], batchAnalysis: string[] }> {
        console.log(`[Consolidated Batch Analysis] Processing ALL ${contexts.length} contexts in single request for free tier efficiency`);
        
        // Create consolidated analysis prompt for ALL contexts at once
        const contextSummaries = contexts.map((ctx, idx) => 
            `Context ${idx + 1}:\n` +
            `File: ${ctx.sourcePath}\n` +
            `Entity: ${ctx.entityName || 'N/A'}\n` +
            `Type: ${ctx.type}\n` +
            `Content Preview: ${ctx.content.substring(0, 400)}...\n` +
            `Current Score: ${ctx.relevanceScore || 0.5}\n`
        ).join('\n---\n\n');
        
        const consolidatedPrompt = `
Analyze ALL ${contexts.length} code contexts for relevance to query: "${query}"${turn ? ` (Search turn ${turn})` : ''}

For EACH context, provide:
1. Relevance score (0.0-1.0) - how well it matches the query
2. Key insights - what important information it contains
3. Query relationship - how it specifically relates to the query
4. Confidence level - how confident you are in this assessment

Contexts to analyze:
${contextSummaries}

Return JSON format:
{
  "overallAnalysis": "Brief summary of all contexts and their collective relevance",
  "contextAnalyses": [
    {
      "contextIndex": 0,
      "relevanceScore": 0.85,
      "insights": "Key insights about this context",
      "queryRelationship": "How this relates to the query",
      "confidence": 0.9
    },
    // ... for each context
  ]
}`;
        
        try {
            const result = await this.multiModelOrchestrator.executeTask(
                'complex_analysis',
                consolidatedPrompt,
                undefined,
                { contextLength: consolidatedPrompt.length }
            );
            
            const responseText = result.content ?? '{}';
            console.log(`[Consolidated Batch Analysis] Received response for ${contexts.length} contexts`);
            
            // Parse the consolidated response using enhanced parser
            let analysisData: any = {};
            try {
                analysisData = await parseGeminiJsonResponse(responseText, {
                    expectedStructure: 'Batch analysis response with contextAnalyses array and overallAnalysis',
                    contextDescription: 'Consolidated batch context analysis',
                    memoryManager: this.memoryManagerInstance,
                    geminiService: this.geminiService,
                    enableAIRepair: true
                });
            } catch (parseError) {
                console.warn('[Consolidated Batch Analysis] Enhanced parsing failed, using fallback:', parseError);
                analysisData = { contextAnalyses: [], overallAnalysis: 'Parsing failed - enhanced recovery exhausted' };
            }
            
            const contextAnalyses = analysisData.contextAnalyses || [];
            const overallAnalysis = analysisData.overallAnalysis || 'Analysis completed';
            
            // Update contexts with analysis results
            const analyzedContexts = contexts.map((context, idx) => {
                const analysis = contextAnalyses.find((a: any) => a.contextIndex === idx);
                if (analysis && typeof analysis.relevanceScore === 'number') {
                    return {
                        ...context,
                        relevanceScore: Math.max(
                            context.relevanceScore || 0.5,
                            Math.min(1.0, Math.max(0.0, analysis.relevanceScore))
                        ),
                        metadata: {
                            ...context.metadata,
                            consolidatedAnalysis: {
                                insights: analysis.insights || 'No insights provided',
                                queryRelationship: analysis.queryRelationship || 'Relationship unclear',
                                confidence: analysis.confidence || 0.5,
                                analyzedAt: new Date().toISOString(),
                                turn: turn || 0
                            }
                        }
                    };
                }
                // Return context with minor boost if no analysis found (assume some relevance)
                return {
                    ...context,
                    relevanceScore: Math.max(context.relevanceScore || 0.5, 0.6),
                    metadata: {
                        ...context.metadata,
                        consolidatedAnalysis: {
                            insights: 'Analysis not available for this context',
                            queryRelationship: 'Assumed relevant based on retrieval',
                            confidence: 0.4,
                            analyzedAt: new Date().toISOString(),
                            turn: turn || 0
                        }
                    }
                };
            });
            
            console.log(`[Consolidated Batch Analysis] Successfully updated ${analyzedContexts.length} contexts with analysis results`);
            
            return {
                analyzedContexts,
                batchAnalysis: [
                    `Consolidated Analysis (${contexts.length} contexts): ${overallAnalysis}`,
                    `Successfully analyzed: ${contextAnalyses.length}/${contexts.length} contexts`,
                    `Average relevance: ${analyzedContexts.reduce((sum, ctx) => sum + (ctx.relevanceScore || 0), 0) / analyzedContexts.length}`
                ]
            };
            
        } catch (error: any) {
            console.error('[Consolidated Batch Analysis] Analysis failed:', error);
            // Fallback: return contexts with slight relevance boost
            const fallbackContexts = contexts.map(ctx => ({
                ...ctx,
                relevanceScore: Math.max(ctx.relevanceScore || 0.5, 0.6)
            }));
            
            return {
                analyzedContexts: fallbackContexts,
                batchAnalysis: [
                    `Consolidated analysis failed: ${error.message}`,
                    `Fallback: Applied default relevance scores to ${contexts.length} contexts`
                ]
            };
        }
    }

    /**
     * Enhanced batch processing with Gemini task type capabilities
     */
    private async _performGeminiBatchAnalysis(
        queries: string[],
        contexts: RetrievedCodeContext[],
        taskType: 'QUESTION_ANSWERING' | 'FACT_VERIFICATION' | 'CLASSIFICATION' = 'QUESTION_ANSWERING',
        model?: string
    ): Promise<{ results: string[]; confidence: number[] }> {
        if (queries.length === 0 || contexts.length === 0) {
            return { results: [], confidence: [] };
        }

        console.log(`[Gemini Batch Analysis] Processing ${queries.length} queries with ${contexts.length} contexts using task type: ${taskType}`);

        const contextSummary = contexts.map((ctx, idx) => 
            `Context ${idx + 1}: ${ctx.sourcePath} - ${ctx.content.substring(0, 200)}...`
        ).join('\n\n');

        const batchPrompts = queries.map(query => 
            `Task Type: ${taskType}\n\nQuery: ${query}\n\nRelevant Contexts:\n${contextSummary}\n\nProvide a comprehensive answer based on the provided contexts.`
        );

        try {
            const batchResults = await this.geminiService.batchAskGemini(
                batchPrompts,
                model || getCurrentModel(),
                `You are an expert code assistant. Use the ${taskType} task type to provide accurate responses based on the given contexts.`
            );

            const results = batchResults.map(result => result.content[0].text || 'No response generated');
            const confidence = batchResults.map(() => 0.85); // Placeholder confidence

            console.log(`[Gemini Batch Analysis] Successfully processed ${results.length} queries`);
            return { results, confidence };
        } catch (error) {
            console.error('[Gemini Batch Analysis] Batch processing failed:', error);
            return { results: queries.map(() => 'Analysis failed'), confidence: queries.map(() => 0.1) };
        }
    }

    async performIterativeSearch(args: IterativeRagArgs): Promise<IterativeRagResult> {
        const operationId = globalPerformanceTracker.startOperation('performIterativeSearch', { query: args.query });

        try {
            const {
                agent_id,
                query,
                model,
                max_iterations = 5,
                context_options,
                focus_area,
                analysis_focus_points,
                enable_web_search,
                google_search,
                continue_session,
                hallucination_check_threshold = 0.8,
                tavily_search_depth = 'basic',
                tavily_max_results = 5,
                tavily_include_raw_content = false,
                thinkingConfig,
                enable_dmqr,
                dmqr_query_count,
                enable_agentic_planning = false,  // Default to false for better context retrieval
                enable_reflection = true,  // More aggressive reflection
                enable_hybrid_search = true,
                enable_long_rag = true,
                enable_corrective_rag = true,
                citation_accuracy_threshold = 0.9,
                long_rag_chunk_size = 2000,
                reflection_frequency = 1  // More frequent reflection for aggressive mode
            } = args;

            const contextRetriever = this.memoryManagerInstance.getCodebaseContextRetrieverService();

        let accumulatedContext: RetrievedCodeContext[] = [];
        const webSearchSources: { title: string; url: string }[] = [];
        const decisionLog: RagAnalysisResponse[] = [];
        const citations: Citation[] = [];
        const reflectionResults: ReflectionResult[] = [];
        const queryHistory = new Set<string>();
        const sourceTracker = new Map<string, number>(); // Track source utilization
        let agenticPlan: AgenticRagPlan | undefined;

        const searchMetrics = {
            totalIterations: 0,
            contextItemsAdded: 0,
            webSearchesPerformed: 0,
            hallucinationChecksPerformed: 0,
            selfCorrectionLoops: 0,
            graphTraversals: 0,
            hybridSearches: 0,
            citationAccuracy: 0,
            citationCoverage: 0,
            totalCitationsGenerated: 0,
            totalCitationsUsed: 0,
            terminationReason: "In progress",
            dmqr: {
                enabled: !!enable_dmqr,
                queryCount: dmqr_query_count,
                generatedQueries: [] as string[],
                success: false,
                contextItemsGenerated: 0,
                error: undefined as string | undefined
            },
            turnLog: [] as Array<{
                turn: number;
                query: string;
                strategy: string;
                newContextCount: number;
                decision: string;
                reasoning: string;
                type: 'initial' | 'iterative' | 'self-correction' | 'agentic-plan' | 'reflection';
                quality: number;
                citations: number;
            }>
        };

        const focusString = this._generateFocusString(focus_area, analysis_focus_points);
        console.log(`[Enhanced RAG] Starting enhanced search for query: "${query}"`);

        // Enhanced Initial Context Gathering Strategy
        let baseQueries: string[] = [query];
        
        // Pre-analyze the query to determine optimal initial search strategy
        const initialStrategy = await this._planInitialSearchStrategy(query, context_options, model);
        console.log(`[Enhanced RAG] Initial search strategy: ${initialStrategy.strategy}, expected sources: ${initialStrategy.expectedSources}`);
        
        // Generate strategic initial queries based on analysis
        if (!enable_dmqr && initialStrategy.additionalQueries.length > 0) {
            baseQueries = [query, ...initialStrategy.additionalQueries.slice(0, 2)]; // Limit to prevent overwhelming
            console.log(`[Enhanced RAG] Enhanced initial queries (${baseQueries.length}): ${baseQueries.map(q => `"${q.substring(0, 40)}..."`).join(', ')}`);
        }
        
        if (enable_dmqr) {
            console.log('[Enhanced RAG] DMQR enabled – generating diverse queries for both embeddings and KG...');
            try {
                const dmqrResult = await this.diverseQueryRewriterService.rewriteAndRetrieve(query, { 
                    queryCount: dmqr_query_count,
                    kgQueryCount: Math.max(3, Math.floor((dmqr_query_count || 4) * 0.7))  // More aggressive KG query generation
                });
                
                baseQueries = dmqrResult.generatedQueries;
                searchMetrics.dmqr.generatedQueries = baseQueries;
                searchMetrics.dmqr.success = true;
                
                console.log(`[Enhanced RAG] DMQR produced ${baseQueries.length} embedding queries and ${dmqrResult.knowledgeGraphQueries?.length || 0} KG queries.`);

                // Pre-fetch context for all DMQR embedding queries to warm up the cache
                if (baseQueries.length > 1) {
                    console.log('[Enhanced RAG] Pre-fetching context for DMQR embedding queries...');
                    try {
                        const dmqrContexts = await this._retrieveContextWithCache(agent_id, baseQueries, context_options || {});
                        searchMetrics.dmqr.contextItemsGenerated = dmqrContexts.length;
                        console.log(`[Enhanced RAG] DMQR embedding context pre-fetching completed. Generated ${dmqrContexts.length} context items.`);
                    } catch (error) {
                        console.warn('[Enhanced RAG] DMQR embedding context pre-fetching failed:', error);
                        searchMetrics.dmqr.contextItemsGenerated = 0;
                    }
                }
                
                // Process KG queries if available and KG manager exists
                if (dmqrResult.knowledgeGraphQueries && dmqrResult.knowledgeGraphQueries.length > 0 && this.knowledgeGraphManager) {
                    console.log(`[Enhanced RAG] Processing ${dmqrResult.knowledgeGraphQueries.length} DMQR KG queries...`);
                    try {
                        const kgContexts: RetrievedCodeContext[] = [];
                        
                        for (const kgQuery of dmqrResult.knowledgeGraphQueries) {
                            try {
                                const graphResult = await this.knowledgeGraphManager.queryNaturalLanguage(agent_id, kgQuery.query);
                                const graphData = JSON.parse(graphResult);
                                
                                if (graphData.results && Array.isArray(graphData.results.nodes)) {
                                    const kgNodes = graphData.results.nodes.map((node: any) => ({
                                        type: 'kg_node_info' as const,
                                        sourcePath: `kg://${node.name}`,
                                        entityName: node.name,
                                        content: JSON.stringify(node.observations),
                                        relevanceScore: kgQuery.confidence || 0.85,
                                        metadata: { 
                                            nodeType: node.entityType,
                                            kgQueryType: kgQuery.searchStrategy,
                                            focusAreas: kgQuery.focusAreas
                                        }
                                    }));
                                    kgContexts.push(...kgNodes);
                                }
                            } catch (kgError) {
                                console.warn(`[Enhanced RAG] KG query failed for "${kgQuery.query}":`, kgError);
                            }
                        }
                        
                        if (kgContexts.length > 0) {
                            accumulatedContext = deduplicateContexts([...accumulatedContext, ...kgContexts]);
                            searchMetrics.dmqr.contextItemsGenerated += kgContexts.length;
                            searchMetrics.graphTraversals += dmqrResult.knowledgeGraphQueries.length;
                            console.log(`[Enhanced RAG] DMQR KG processing completed. Generated ${kgContexts.length} additional context items.`);
                        }
                    } catch (error) {
                        console.warn('[Enhanced RAG] DMQR KG processing failed:', error);
                    }
                }
            } catch (e: any) {
                searchMetrics.dmqr.success = false;
                searchMetrics.dmqr.error = e.message ?? 'unknown';
                baseQueries = [query];
            }
        }

        let currentQueries = [...baseQueries];
        let turn = 0;
        let stabilityCounter = 0; // Counts consecutive turns with no new context

        // Safety measures for infinite loop prevention
        let noNewContextCounter = 0;
        const maxNoNewContextIterations = 2;
        
        while (turn < max_iterations) {
            turn++;
            searchMetrics.totalIterations = turn;

            const turnQuery = currentQueries.shift();
            if (!turnQuery) {
                searchMetrics.terminationReason = "Exhausted all queries.";
                break;
            }

            // Safety check: Prevent infinite loops with duplicate queries
            if (queryHistory.has(turnQuery)) {
                console.log(`[Enhanced RAG] Skipping duplicate query: "${turnQuery}"`);
                noNewContextCounter++;
                if (noNewContextCounter >= maxNoNewContextIterations) {
                    searchMetrics.terminationReason = "No new context found in recent iterations - preventing infinite loop.";
                    console.log('[Enhanced RAG] Safety termination: No new context in recent iterations.');
                    break;
                }
                continue;
            }
            queryHistory.add(turnQuery);
            
            // Early termination for exceptional quality
            if (turn > 1 && accumulatedContext.length >= 15) {
                const estimatedCoverage = Math.min(accumulatedContext.length / 20, 1.0);
                if (estimatedCoverage > 0.9 && searchMetrics.citationAccuracy > 0.9) {
                    searchMetrics.terminationReason = "Exceptional quality achieved - early termination.";
                    console.log('[Enhanced RAG] Early termination: Exceptional quality and coverage achieved.');
                    break;
                }
            }

            const isInitialTurn = baseQueries.includes(turnQuery);
            console.log(`[Enhanced RAG] Turn ${turn} – Query: "${turnQuery}" (${isInitialTurn ? 'initial' : 'iterative'})`);

            // Agentic Planning Phase
            if (enable_agentic_planning && turn > 1) {
                agenticPlan = await this._performAgenticPlanning(query, turnQuery, accumulatedContext, turn, model);
                console.log(`[Enhanced RAG] Agentic plan: ${agenticPlan.strategy}`);
            }

            const contextBefore = accumulatedContext.length;
            let rawContext: RetrievedCodeContext[] = [];

            // Execute search based on agentic plan or default to hybrid
            if (enable_hybrid_search && agenticPlan?.strategy === 'hybrid_search') {
                rawContext = await this._performHybridSearch(agent_id, turnQuery, context_options || {}, agenticPlan);
                searchMetrics.hybridSearches++;
            } else if (agenticPlan?.strategy === 'graph_traversal' && this.knowledgeGraphManager) {
                try {
                    const graphResult = await this.knowledgeGraphManager.queryNaturalLanguage(agent_id, turnQuery);
                    const graphData = JSON.parse(graphResult);
                    if (graphData.results && Array.isArray(graphData.results.nodes)) {
                        rawContext = graphData.results.nodes.map((node: any) => ({
                            type: 'kg_node_info' as const,
                            sourcePath: `kg://${node.name}`,
                            entityName: node.name,
                            content: JSON.stringify(node.observations),
                            relevanceScore: 0.85
                        }));
                    }
                    searchMetrics.graphTraversals++;
                } catch (error) {
                    console.warn('[Enhanced RAG] Graph traversal failed, falling back to vector search');
                    rawContext = await this._retrieveContextWithCache(agent_id, [turnQuery], context_options || {});
                }
            } else {
                rawContext = await this._retrieveContextWithCache(agent_id, [turnQuery], context_options || {});
            }

            accumulatedContext = deduplicateContexts([...accumulatedContext, ...rawContext]);
            const addedNow = accumulatedContext.length - contextBefore;
            searchMetrics.contextItemsAdded += addedNow;

            // Track source utilization and apply diversification
            rawContext.forEach(context => {
                const sourceKey = context.sourcePath;
                const currentCount = sourceTracker.get(sourceKey) || 0;
                sourceTracker.set(sourceKey, currentCount + 1);
                
                const citation = this._generateCitation(
                    context,
                    context.content.substring(0, 200),
                    context.relevanceScore || 0.8
                );
                citations.push(citation);
            });
            
            // Apply source diversification if we have low source coverage
            const uniqueSources = sourceTracker.size;
            const totalContextItems = accumulatedContext.length;
            const sourceCoverage = uniqueSources > 0 ? uniqueSources / Math.min(totalContextItems, 24) : 0; // Assume max 24 potential sources
            
            console.log(`[Source Diversification] Turn ${turn}: ${uniqueSources} unique sources, ${totalContextItems} context items, coverage: ${(sourceCoverage * 100).toFixed(1)}%`);
            
            // If source coverage is low, modify search strategy for next iteration
            if (sourceCoverage < 0.4 && turn < max_iterations - 1) {
                console.log(`[Source Diversification] Low source coverage (${(sourceCoverage * 100).toFixed(1)}%) - applying diversification strategy`);
                
                // Generate diversified queries to explore different parts of the codebase
                const diversificationQueries = this._generateDiversificationQueries(query, sourceTracker, turn);
                currentQueries.unshift(...diversificationQueries); // Add to front of queue for priority
                
                console.log(`[Source Diversification] Added ${diversificationQueries.length} diversification queries: ${diversificationQueries.map(q => `"${q.substring(0, 50)}..."`).join(', ')}`);
            }

            // Continuation mode with web search: Automatically perform web search when enabled
            if (continue_session && (google_search || enable_web_search) && turn === 1) {
                console.log('[Enhanced RAG] Continuation mode with web search enabled - performing web search');
                searchMetrics.webSearchesPerformed++;
                try {
                    const webResults = await callTavilyApi(query, { 
                        search_depth: tavily_search_depth, 
                        max_results: tavily_max_results, 
                        include_raw_content: tavily_include_raw_content 
                    });
                    
                    webResults.forEach((r: WebSearchResult) => {
                        webSearchSources.push({ title: r.title, url: r.url });
                        accumulatedContext.push({ 
                            type: 'documentation', 
                            sourcePath: r.url, 
                            entityName: r.title, 
                            content: r.content, 
                            relevanceScore: 0.95 
                        });
                        
                        const webCitation = this._generateCitation({
                            type: 'documentation',
                            sourcePath: r.url,
                            entityName: r.title,
                            content: r.content,
                            relevanceScore: 0.95
                        }, r.content.substring(0, 200), 0.9);
                        webCitation.sourceType = 'web';
                        webCitation.url = r.url;
                        citations.push(webCitation);
                    });
                    
                    console.log(`[Enhanced RAG] Web search completed: added ${webResults.length} web sources to context`);
                } catch (e: any) {
                    console.error('[Enhanced RAG] Web search failed in continuation mode:', e);
                }
            }

            // Enhanced Corrective RAG: Self-correction logic with reflection and safety measures
            if (addedNow === 0 && !isInitialTurn && enable_corrective_rag) {
                stabilityCounter++;
                noNewContextCounter++; // Track no new context for safety
                
                if (stabilityCounter >= 2) {
                    searchMetrics.terminationReason = "Context stable, no new information found.";
                    console.log(`[Enhanced RAG] Context has been stable for ${stabilityCounter} turns. Terminating search.`);
                    break;
                }
                
                // Apply corrective search after no context found
                if (stabilityCounter === 1) {
                    const correctiveQuery = `Broaden search for: ${query}. Look for related concepts, alternative implementations, or background information.`;
                    currentQueries.push(correctiveQuery);
                    searchMetrics.selfCorrectionLoops++;
                    console.log('[Enhanced RAG] Applied corrective search due to no new context.');
                }
            } else {
                stabilityCounter = 0;
                noNewContextCounter = 0; // Reset safety counter when context is found
            }

            // Create enhanced context flow with Long RAG support
            const contextFlow = this._createContextFlow(
                accumulatedContext, 
                turnQuery, 
                addedNow,
                enable_long_rag,
                long_rag_chunk_size
            );

            // Enhanced batch processing - process ALL context in one go to minimize API calls
            let analyzedContextFlow = contextFlow;
            let batchAnalysisResults: string[] = [];
            
            // For free tier efficiency: batch ALL context at once instead of multiple calls
            if (contextFlow.length > 1) {
                console.log(`[Enhanced RAG] Applying consolidated batch context analysis to ALL ${contextFlow.length} contexts to minimize API usage`);
                try {
                    const batchResult = await this._processConsolidatedBatchContextAnalysis(
                        contextFlow,
                        query, // Use original query for consistency
                        model,
                        turn // Add turn context for better analysis
                    );
                    analyzedContextFlow = batchResult.analyzedContexts;
                    batchAnalysisResults = batchResult.batchAnalysis;
                    
                    // Sort by updated relevance scores
                    analyzedContextFlow.sort((a, b) => (b.relevanceScore || 0) - (a.relevanceScore || 0));
                    console.log(`[Enhanced RAG] Consolidated batch analysis completed, reordered ${analyzedContextFlow.length} contexts by relevance`);
                } catch (batchError: any) {
                    console.warn(`[Enhanced RAG] Batch analysis failed: ${batchError.message}. Using original context flow.`);
                    analyzedContextFlow = contextFlow; // Fallback to original context
                }
            }

            const formattedContext = formatContextForGemini(analyzedContextFlow)[0].text || '';
            const analysisPrompt = RAG_ANALYSIS_PROMPT
                .replace('{originalQuery}', query)
                .replace('{currentTurn}', String(turn))
                .replace('{maxIterations}', String(max_iterations))
                .replace('{accumulatedContext}', formattedContext)
                .replace('{focusString}', focusString);

            let analysisResult;
            try {
                analysisResult = await this.multiModelOrchestrator.executeTask(
                    'decision_making',
                    analysisPrompt,
                    RAG_ANALYSIS_SYSTEM_INSTRUCTION,
                    { contextLength: analysisPrompt.length }
                );
            } catch (e: any) {
                searchMetrics.terminationReason = `Gemini analysis error: ${e.message}`;
                break;
            }

            // Use enhanced parsing with AI repair capabilities
            let parsed: any;
            try {
                parsed = await RagResponseParser.parseAnalysisResponse(
                    analysisResult.content ?? '',
                    formattedContext.substring(0, 500) + '...',  // Context used
                    analysisPrompt.substring(0, 200) + '...',    // Prompt sent
                    this.memoryManagerInstance,
                    this.geminiService
                );
            } catch (enhancedParseError) {
                console.warn('[Enhanced RAG] Enhanced parsing failed, falling back to sync parser:', enhancedParseError);
                parsed = RagResponseParser.parseAnalysisResponseSync(
                    analysisResult.content ?? '',
                    formattedContext.substring(0, 500) + '...',
                    analysisPrompt.substring(0, 200) + '...'
                );
            }
            
            if (!parsed) {
                console.error('[Enhanced RAG] All parsing strategies failed - terminating search');
                searchMetrics.terminationReason = 'Complete parsing failure - enhanced and fallback parsers both failed';
                break;
            }
            
            // Log parsing success/failure for monitoring
            if (parsed._parsing_failed) {
                console.warn(`[Enhanced RAG] Parser used fallback: ${parsed._error_message || 'Unknown error'}`);
                searchMetrics.terminationReason += ' (Parser fallback used)';
            } else {
                console.log('[Enhanced RAG] Parsing successful');
            }
            decisionLog.push(parsed);

            // Reflection Phase (periodic)
            if (enable_reflection && turn % reflection_frequency === 0) {
                const tempAnswer = analysisResult.content || '';
                const reflection = await this._performReflection(query, contextFlow, tempAnswer, model);
                reflectionResults.push(reflection);
                searchMetrics.hallucinationChecksPerformed++;

                if (reflection.missingInfo.length > 0 || reflection.hasHallucinations) {
                    const correctiveContext = await this._performCorrectiveSearch(
                        agent_id, query, accumulatedContext, reflection, context_options || {}, model
                    );

                    if (correctiveContext.length > 0) {
                        accumulatedContext = deduplicateContexts([...accumulatedContext, ...correctiveContext]);
                        searchMetrics.selfCorrectionLoops++;
                        
                        searchMetrics.turnLog.push({
                            turn,
                            query: turnQuery,
                            strategy: 'corrective_search',
                            newContextCount: correctiveContext.length,
                            decision: "CORRECTIVE_SEARCH",
                            reasoning: `Applied corrective search based on reflection: ${reflection.suggestions.join(', ')}`,
                            type: 'self-correction',
                            quality: reflection.qualityScore,
                            citations: correctiveContext.length
                        });
                    }
                }
            }

            const strategy = agenticPlan?.strategy || 'vector_search';
            const quality = reflectionResults.length > 0 ? 
                reflectionResults[reflectionResults.length - 1].qualityScore : 0.7;

            searchMetrics.turnLog.push({
                turn,
                query: turnQuery,
                strategy,
                newContextCount: addedNow,
                decision: parsed.decision,
                reasoning: parsed.reasoning,
                type: isInitialTurn ? 'initial' : 'iterative',
                quality,
                citations: addedNow
            });

            if (parsed.decision === 'ANSWER') {
                // Quality Gate: Check if we meet minimum quality thresholds before allowing ANSWER
                let estimatedQuality = parsed.qualityScore;
                
                // If quality score is missing or undefined, calculate it based on context analysis
                if (estimatedQuality === undefined || estimatedQuality === null || isNaN(estimatedQuality)) {
                    console.warn(`[Enhanced RAG] Quality score missing from parsed response. Calculating fallback quality estimate...`);
                    estimatedQuality = this._calculateContextQuality(accumulatedContext, query);
                    console.log(`[Enhanced RAG] Calculated fallback quality score: ${estimatedQuality}`);
                    
                    // Update the parsed response with the calculated quality
                    parsed.qualityScore = estimatedQuality;
                }
                
                const contextSufficiency = Math.min(accumulatedContext.length / 10, 1.0); // Rough quality estimate
                const iterationProgress = turn / max_iterations;
                
                console.log(`[Enhanced RAG] Quality Gate Check: quality=${estimatedQuality}, context=${contextSufficiency}, iteration=${iterationProgress}`);
                
                // Apply quality gates unless we're at maximum iterations
                if (turn < max_iterations && (estimatedQuality < 0.8 || contextSufficiency < 0.6)) {
                    console.log(`[Enhanced RAG] Quality gate failed: quality=${estimatedQuality} < 0.8 or context=${contextSufficiency} < 0.6. Continuing search.`);
                    
                    // Force another search iteration with corrective query
                    const correctiveQuery = `Find additional comprehensive information about: ${query}. Focus on areas not yet covered in detail.`;
                    currentQueries.push(correctiveQuery);
                    searchMetrics.selfCorrectionLoops++;
                    
                    // Add to decision log
                    decisionLog.push({
                        decision: 'CORRECTIVE_SEARCH' as any,
                        reasoning: `Quality gate failed: quality=${estimatedQuality}, context=${contextSufficiency}. Continuing search.`,
                        nextCodebaseQuery: correctiveQuery,
                        qualityScore: estimatedQuality,
                        confidenceScore: 0.6,
                        contextUsed: formattedContext.substring(0, 500) + '...',
                        promptSent: analysisPrompt.substring(0, 200) + '...',
                        rawGeminiResponse: analysisResult.content?.substring(0, 300) + '...'
                    });
                    continue;
                }
                
                searchMetrics.terminationReason = turn >= max_iterations 
                    ? "Max iterations reached with forced answer" 
                    : "ANSWER decision reached with quality gates passed";
                console.log('[Enhanced RAG] Decision: ANSWER – generating final answer with citations.');
                
                const enhancedAnswerPrompt = RAG_ANSWER_PROMPT
                    .replace('{originalQuery}', query)
                    .replace('{contextString}', formattedContext)
                    .replace('{focusString}', focusString)
                    .replace('{totalSources}', analyzedContextFlow.length.toString())
                    .replace('{searchStrategy}', 'enhanced_hybrid_search')
                    .replace('{contextQuality}', '0.85')
                    .replace('{web_search_flags}', `Web Search: ${(google_search || enable_web_search) ? 'ENABLED' : 'DISABLED'}`)
                    .replace('{continuation_mode}', `Continuation Mode: ${continue_session ? 'ACTIVE - Building on conversation history' : 'DISABLED'}`) +
                    `\n\nIMPORTANT: You have ${analyzedContextFlow.length} context sources available. Include proper citations in your answer using the format [cite_N] where N is the citation number. Strive to utilize multiple sources and provide comprehensive coverage. Each claim should be supported by specific source references.`;
                
                const answerResult = await this.multiModelOrchestrator.executeTask(
                    'final_answer_generation',
                    enhancedAnswerPrompt,
                    'You are a helpful AI assistant providing accurate answers with proper citations based on the given context.',
                    { contextLength: enhancedAnswerPrompt.length }
                );
                
                // Calculate citation accuracy (actual usage vs availability)
                const finalAnswer = answerResult.content ?? '';
                const citationMatches = finalAnswer.match(/\[cite_\d+\]/g) || [];
                
                // Calculate actual citation accuracy: unique citations used / total citations in answer
                const uniqueCitationNumbers = new Set(
                    citationMatches.map(match => {
                        const num = match.match(/\d+/)?.[0];
                        return num ? parseInt(num) : null;
                    }).filter(num => num !== null)
                );
                
                // Citation accuracy is the ratio of valid citations to total citation attempts
                searchMetrics.citationAccuracy = citationMatches.length > 0 
                    ? uniqueCitationNumbers.size / citationMatches.length 
                    : (citations.length > 0 ? 0.0 : 1.0);
                
                // Calculate citation coverage: what percentage of available sources were cited
                const citationCoverage = citations.length > 0 
                    ? uniqueCitationNumbers.size / citations.length 
                    : 1.0;
                
                // Store additional metrics
                searchMetrics.citationCoverage = citationCoverage;
                searchMetrics.totalCitationsGenerated = citations.length;
                searchMetrics.totalCitationsUsed = uniqueCitationNumbers.size;
                
                console.log(`[Enhanced RAG] Citation metrics: accuracy=${(searchMetrics.citationAccuracy * 100).toFixed(1)}%, coverage=${(citationCoverage * 100).toFixed(1)}%, used=${uniqueCitationNumbers.size}/${citations.length}`);
                
                // Final quality gate: Check citation accuracy threshold
                if (searchMetrics.citationAccuracy < citation_accuracy_threshold && citationCoverage < 0.8) {
                    console.warn(`[Enhanced RAG] Quality warning: Citation accuracy ${(searchMetrics.citationAccuracy * 100).toFixed(1)}% and coverage ${(citationCoverage * 100).toFixed(1)}% below thresholds.`);
                    searchMetrics.terminationReason += " (Quality warning: Low citation accuracy/coverage)";
                }
                
                return { 
                    accumulatedContext, 
                    webSearchSources, 
                    finalAnswer, 
                    decisionLog, 
                    citations,
                    reflectionResults,
                    agenticPlan,
                    searchMetrics 
                };
            } else if (parsed.decision === 'SEARCH_AGAIN' && parsed.nextCodebaseQuery) {
                currentQueries.push(parsed.nextCodebaseQuery);
            } else if (parsed.decision === 'SEARCH_WEB' && enable_web_search && parsed.nextWebQuery) {
                searchMetrics.webSearchesPerformed++;
                try {
                    const webResults = await callTavilyApi(parsed.nextWebQuery, { search_depth: tavily_search_depth, max_results: tavily_max_results, include_raw_content: tavily_include_raw_content });
                    webResults.forEach((r: WebSearchResult) => {
                        webSearchSources.push({ title: r.title, url: r.url });
                        accumulatedContext.push({ type: 'documentation', sourcePath: r.url, entityName: r.title, content: r.content, relevanceScore: 0.95 });
                        
                        const webCitation = this._generateCitation({
                            type: 'documentation',
                            sourcePath: r.url,
                            entityName: r.title,
                            content: r.content,
                            relevanceScore: 0.95
                        }, r.content.substring(0, 200), 0.9);
                        webCitation.sourceType = 'web';
                        webCitation.url = r.url;
                        citations.push(webCitation);
                    });
                } catch (e: any) {
                    console.error('[Enhanced RAG] Web search failed:', e);
                }
            }
        }

        if (searchMetrics.terminationReason === "In progress") {
            searchMetrics.terminationReason = "Max iterations reached.";
        }

        console.log('[Enhanced RAG] Generating final answer from accumulated context with citations.');
        
        const finalContextFlow = this._createContextFlow(
            accumulatedContext, 
            query, 
            0, 
            enable_long_rag, 
            long_rag_chunk_size
        );
        const fallbackContext = formatContextForGemini(finalContextFlow)[0].text || '';
        const fallbackPrompt = RAG_ANSWER_PROMPT
            .replace('{originalQuery}', query)
            .replace('{contextString}', fallbackContext)
            .replace('{focusString}', focusString)
            .replace('{totalSources}', finalContextFlow.length.toString())
            .replace('{searchStrategy}', 'fallback_search')
            .replace('{contextQuality}', '0.70')
            .replace('{web_search_flags}', `Web Search: ${(google_search || enable_web_search) ? 'ENABLED' : 'DISABLED'}`)
            .replace('{continuation_mode}', `Continuation Mode: ${continue_session ? 'ACTIVE - Building on conversation history' : 'DISABLED'}`) +
            `\n\nIMPORTANT: You have ${finalContextFlow.length} context sources available. Include proper citations in your answer using the format [cite_N] where N is the citation number. Utilize multiple sources when possible for comprehensive coverage.`;
        
        const fallbackResult = await this.multiModelOrchestrator.executeTask(
            'final_answer_generation',
            fallbackPrompt,
            'You are a helpful AI assistant providing accurate answers with citations based on the given context.',
            { contextLength: fallbackPrompt.length }
        );

        const finalAnswer = fallbackResult.content ?? 'Unable to formulate an answer.';
        const citationMatches = finalAnswer.match(/\[cite_\d+\]/g) || [];
        
        // Apply same citation accuracy calculation as in main flow
        const uniqueCitationNumbers = new Set(
            citationMatches.map(match => {
                const num = match.match(/\d+/)?.[0];
                return num ? parseInt(num) : null;
            }).filter(num => num !== null)
        );
        
        searchMetrics.citationAccuracy = citationMatches.length > 0 
            ? uniqueCitationNumbers.size / citationMatches.length 
            : (citations.length > 0 ? 0.0 : 1.0);
        searchMetrics.citationCoverage = citations.length > 0 
            ? uniqueCitationNumbers.size / citations.length 
            : 1.0;
        searchMetrics.totalCitationsGenerated = citations.length;
        searchMetrics.totalCitationsUsed = uniqueCitationNumbers.size;
        
        // Add source diversity metrics
        const finalSourceCoverage = sourceTracker.size > 0 ? sourceTracker.size / Math.min(accumulatedContext.length, 24) : 0;
        (searchMetrics as any).sourceCoverage = finalSourceCoverage;
        (searchMetrics as any).uniqueSourcesUsed = sourceTracker.size;
        (searchMetrics as any).totalContextSources = accumulatedContext.length;
        
        console.log(`[Final Metrics] Source coverage: ${(finalSourceCoverage * 100).toFixed(1)}%, unique sources: ${sourceTracker.size}, total contexts: ${accumulatedContext.length}`);

        return { 
            accumulatedContext, 
            webSearchSources, 
            finalAnswer, 
            decisionLog, 
            citations,
            reflectionResults,
            agenticPlan,
            searchMetrics 
        };
        } catch (error: any) {
            globalPerformanceTracker.endOperation(operationId, false, error.message);
            throw error;
        }
    }

    /**
     * Get performance metrics summary for monitoring and optimization.
     */
    getPerformanceMetrics(): any {
        return globalPerformanceTracker.getSummary();
    }

    /**
     * Clear performance metrics (useful for testing or resetting metrics).
     */
    clearPerformanceMetrics(): void {
        globalPerformanceTracker.clear();
    }

    /**
     * Calculate quality score for accumulated context based on various metrics
     */
    private _calculateContextQuality(contexts: RetrievedCodeContext[], query: string): number {
        if (contexts.length === 0) return 0.1;
        
        let totalScore = 0;
        const queryLower = query.toLowerCase();
        const queryTerms = this._extractQueryTerms(query);
        
        for (const context of contexts) {
            let contextScore = 0;
            const contentLower = context.content.toLowerCase();
            
            // 1. Relevance score weight (40%)
            const relevanceScore = context.relevanceScore || 0.5;
            contextScore += relevanceScore * 0.4;
            
            // 2. Query term matching (30%)
            const matchingTerms = queryTerms.filter(term => 
                contentLower.includes(term.toLowerCase()) ||
                context.sourcePath.toLowerCase().includes(term.toLowerCase())
            );
            const termMatchScore = Math.min(matchingTerms.length / Math.max(queryTerms.length, 1), 1.0);
            contextScore += termMatchScore * 0.3;
            
            // 3. Content quality indicators (20%)
            let qualityIndicators = 0;
            if (context.content.length > 200) qualityIndicators += 0.3;
            if (context.content.includes('function') || context.content.includes('class')) qualityIndicators += 0.3;
            if (context.content.includes('export') || context.content.includes('import')) qualityIndicators += 0.2;
            if (context.entityName && context.entityName.length > 0) qualityIndicators += 0.2;
            contextScore += Math.min(qualityIndicators, 1.0) * 0.2;
            
            // 4. Source diversity bonus (10%)
            const sourceTypeBonus = context.type !== 'generic_code_chunk' ? 0.1 : 0.0;
            contextScore += sourceTypeBonus;
            
            totalScore += Math.min(contextScore, 1.0);
        }
        
        // Calculate average and apply context diversity bonus
        const averageScore = totalScore / contexts.length;
        const diversityBonus = Math.min(contexts.length / 10, 0.2); // Up to 20% bonus for more contexts
        const finalScore = Math.min(averageScore + diversityBonus, 1.0);
        
        return Math.max(finalScore, 0.1); // Minimum score of 0.1
    }
    
    /**
     * Extract meaningful terms from query for quality assessment
     */
    private _extractQueryTerms(query: string): string[] {
        // Remove common words and extract meaningful terms
        const commonWords = new Set(['how', 'what', 'when', 'where', 'why', 'who', 'which', 'does', 'do', 'is', 'are', 'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'from']);
        return query.toLowerCase()
            .split(/\W+/)
            .filter(word => word.length > 2 && !commonWords.has(word))
            .slice(0, 10); // Limit to top 10 terms
    }
    
    /**
     * Plan initial search strategy based on query analysis
     */
    private async _planInitialSearchStrategy(
        query: string, 
        contextOptions?: ContextRetrievalOptions,
        model?: string
    ): Promise<{
        strategy: string;
        expectedSources: number;
        additionalQueries: string[];
        confidence: number;
    }> {
        try {
            const queryAnalysisPrompt = `Analyze this code-related query and recommend an optimal initial search strategy:

Query: "${query}"

**ANALYSIS FRAMEWORK:**
1. **Query Classification**: Identify the type (explanation, debugging, implementation, configuration, etc.)
2. **Expected Sources**: Estimate how many different code files/components should be involved
3. **Search Breadth**: Determine if query needs broad exploration or focused search
4. **Additional Queries**: Suggest 1-2 strategic follow-up queries to gather comprehensive context

**RESPONSE FORMAT (JSON only):**
{
  "queryType": "explanation|debugging|implementation|configuration|general",
  "strategy": "focused|broad|hybrid",
  "expectedSources": 3-15,
  "searchBreadth": "narrow|moderate|wide",
  "additionalQueries": ["strategic query 1", "strategic query 2"],
  "reasoning": "brief explanation of strategy",
  "confidence": 0.0-1.0
}

Provide only the JSON response:`;
            
            const result = await this.multiModelOrchestrator.executeTask(
                'planning',
                queryAnalysisPrompt,
                undefined,
                { contextLength: queryAnalysisPrompt.length }
            );
            
            const response = result.content?.trim() || '{}';
            let analysis: any;
            
            try {
                analysis = await parseGeminiJsonResponse(response, {
                    expectedStructure: 'Initial search strategy with queryType, strategy, expectedSources, and additionalQueries',
                    contextDescription: 'Initial RAG search strategy planning',
                    memoryManager: this.memoryManagerInstance,
                    geminiService: this.geminiService,
                    enableAIRepair: true
                });
            } catch (parseError) {
                console.warn('[Initial Strategy Planning] Enhanced parsing failed, using fallback strategy:', parseError);
                return this._getFallbackInitialStrategy(query);
            }
            
            return {
                strategy: analysis.strategy || 'hybrid',
                expectedSources: Math.min(Math.max(analysis.expectedSources || 5, 3), 15),
                additionalQueries: Array.isArray(analysis.additionalQueries) ? analysis.additionalQueries.slice(0, 2) : [],
                confidence: Math.min(Math.max(analysis.confidence || 0.7, 0.1), 1.0)
            };
            
        } catch (error) {
            console.warn('[Initial Strategy Planning] Analysis failed, using fallback:', error);
            return this._getFallbackInitialStrategy(query);
        }
    }
    
    /**
     * Fallback strategy when initial planning fails
     */
    private _getFallbackInitialStrategy(query: string): {
        strategy: string;
        expectedSources: number;
        additionalQueries: string[];
        confidence: number;
    } {
        const queryLower = query.toLowerCase();
        const isExplanationQuery = /\b(how|explain|what|describe|tell|show)\b/.test(queryLower);
        const isImplementationQuery = /\b(implement|create|build|develop|code|write)\b/.test(queryLower);
        const isDebuggingQuery = /\b(error|bug|fix|issue|problem|fail|wrong)\b/.test(queryLower);
        
        // Extract main terms for additional query generation
        const mainTerms = this._extractQueryTerms(query).slice(0, 2);
        const additionalQueries: string[] = [];
        
        if (isExplanationQuery && mainTerms.length > 0) {
            additionalQueries.push(`${mainTerms[0]} usage examples and integration patterns`);
            if (mainTerms.length > 1) {
                additionalQueries.push(`${mainTerms[1]} related components and dependencies`);
            }
        } else if (isImplementationQuery && mainTerms.length > 0) {
            additionalQueries.push(`${mainTerms[0]} interfaces and base classes`);
            additionalQueries.push(`${mainTerms[0]} configuration and setup requirements`);
        } else if (isDebuggingQuery) {
            additionalQueries.push(`Common errors and troubleshooting for ${mainTerms[0] || 'this functionality'}`);
        }
        
        return {
            strategy: isExplanationQuery ? 'broad' : isDebuggingQuery ? 'focused' : 'hybrid',
            expectedSources: isExplanationQuery ? 8 : isDebuggingQuery ? 4 : 6,
            additionalQueries,
            confidence: 0.6
        };
    }
    
    /**
     * Generate diversified queries to explore different sources and improve coverage
     */
    private _generateDiversificationQueries(
        originalQuery: string, 
        sourceTracker: Map<string, number>, 
        currentTurn: number
    ): string[] {
        const queries: string[] = [];
        const queryTerms = this._extractQueryTerms(originalQuery);
        const mainTerm = queryTerms[0] || 'code';
        
        // Identify underrepresented source types
        const sourceTypes = new Map<string, number>();
        for (const [path] of sourceTracker) {
            const ext = path.split('.').pop()?.toLowerCase() || 'unknown';
            sourceTypes.set(ext, (sourceTypes.get(ext) || 0) + 1);
        }
        
        // Strategy 1: Target different file types that might have been missed
        const targetExtensions = ['ts', 'js', 'json', 'md', 'yaml', 'yml'];
        const underrepresentedExts = targetExtensions.filter(ext => 
            !sourceTypes.has(ext) || (sourceTypes.get(ext) || 0) < 2
        );
        
        if (underrepresentedExts.length > 0) {
            const ext = underrepresentedExts[0];
            queries.push(`Find ${mainTerm} related code or configuration in ${ext} files`);
        }
        
        // Strategy 2: Explore different architectural layers
        const architecturalLayers = [
            'services and business logic',
            'data models and schemas', 
            'utilities and helpers',
            'configuration and setup',
            'tests and examples',
            'interfaces and types'
        ];
        
        if (currentTurn <= 3) {
            const layer = architecturalLayers[Math.min(currentTurn - 1, architecturalLayers.length - 1)];
            queries.push(`${mainTerm} implementation in ${layer}`);
        }
        
        // Strategy 3: Semantic expansion for better coverage
        const semanticVariations = {
            'orchestrator': ['coordinator', 'manager', 'handler', 'processor'],
            'parse': ['decode', 'transform', 'convert', 'process'],
            'distribution': ['allocation', 'assignment', 'routing', 'dispatch'],
            'task': ['job', 'work', 'operation', 'process']
        };
        
        for (const [term, variations] of Object.entries(semanticVariations)) {
            if (originalQuery.toLowerCase().includes(term)) {
                const variation = variations[currentTurn % variations.length];
                queries.push(originalQuery.replace(new RegExp(term, 'gi'), variation));
                break; // Only add one variation per turn
            }
        }
        
        // Strategy 4: If still low coverage, try broader exploration
        if (sourceTracker.size < 5) {
            queries.push(`Related patterns and implementations for ${mainTerm}`);
        }
        
        // Limit to 2 diversification queries per turn to avoid overwhelming
        return queries.slice(0, 2);
    }
}
